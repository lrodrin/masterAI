ggplot(train) +
geom_bar(aes(x=target), fill = target) +
scale_x_continuous(breaks = c(0, 1))
ggplot(train) +
geom_bar(aes(x=target), fill = "blue") +
scale_x_continuous(breaks = c(0, 1))
library(tidyverse)
train <- read.csv("train.csv")
test <- read.csv("test.csv")
# not real disaster
train[train["target"] == 0, "text"][2]
# real disaster
train[train["target"] == 1, "text"][2]
# removing invalid targets
nrow(train)
train <- train %>% distinct(keyword, location, text, keep_all = TRUE)
nrow(train)
library(tidyverse)
train <- read.csv("train.csv")
test <- read.csv("test.csv")
ggplot(train) +
geom_bar(aes(x=target), fill = "blue") +
scale_x_continuous(breaks = c(0, 1))
ggplot(train) +
geom_bar(aes(x=target), fill = "blue") +
xlab("target") +
scale_x_continuous(breaks = c(0, 1))
ggplot(train) +
geom_bar(aes(x=target)) +
xlab("target") +
scale_x_continuous(breaks = c(0, 1))
ggplot(train) +
geom_bar(aes(x=target), fill="aqua") +
xlab("target") +
scale_x_continuous(breaks = c(0, 1))
ggplot(train, aes(target)) +
geom_bar(aes(fill = target))
ggplot(train, aes(target)) +
geom_bar(aes(fill = target))
ggplot(train) +
geom_bar(aes(x=target)) +
xlab("target") +
scale_x_continuous(breaks = c(0, 1))
ggplot(train, aes(x=target, fill=target)) +
geom_bar()
ggplot(train, aes(x=target, fill=target)) +
geom_bar() +
scale_x_continuous(breaks = c(0, 1))
ggplot(train) + geom_bar(aes(x = target))
library(tidyverse)
train <- read.csv("train.csv")
test <- read.csv("test.csv")
ggplot(train, aes(x = target))
ggplot(train, aes(x = target)) +
geom_bar(stat = "identity")
ggplot(train, aes(x = target)) +
geom_bar()
library(ggplot2)
ggplot(train, aes(x = target)) +
geom_bar(stat = "identity")
library(ggplot2)
ggplot(train, aes(x = target)) +
geom_bar(aes(fill = target))
library(ggplot2)
ggplot(train, aes(x = target)) +
geom_bar(aes(factor(target, levels = c(0, 1))))
ggplot(train, aes(x = target)) +
geom_bar(aes(fill = target))
train$target <- as.factor(train$target)
ggplot(train, aes(x = target)) +
geom_bar(aes(fill = target))
library(tidyverse)
train <- read.csv("train.csv")
test <- read.csv("test.csv")
# not real disaster
# train[train["target"] == 0, "text"][2]
# real disaster
# train[train["target"] == 1, "text"][2]
# removing invalid targets
# nrow(train)
# train <- train %>% distinct(keyword, location, text, keep_all = TRUE)
# nrow(train)
# distribution of the target variable
train$target <- as.factor(ifelse(train$target == 0, "No", "Yes"))
ggplot(train, aes(x=target)) +
geom_bar(aes(fill=target))
library(tidyverse)
train <- read.csv("train.csv")
test <- read.csv("test.csv")
# not real disaster
# train[train["target"] == 0, "text"][2]
# real disaster
# train[train["target"] == 1, "text"][2]
# removing invalid targets
# nrow(train)
# train <- train %>% distinct(keyword, location, text, keep_all = TRUE)
# nrow(train)
# distribution of the target variable
train$target <- as.factor(train$target)
ggplot(train, aes(x=target)) +
geom_bar(aes(fill=target))
summary(train)
summary(test)
colSums(sapply(train, is.na))
colSums(sapply(test, is.na))
table(train$target)
dim(train$target == "0") / dim(train) * 100
dim(train$target[0]) / dim(train) * 100
dim(train$target) / dim(train) * 100
dim(train$target)
train$target[, "0"]
train$target[, c("0")]
View(train)
table(train$target)[0]
table(train$target)
table(train$target)[0]
table(train$target)[, 1]
table(train$target)[:1]
train$target == "0"
sum(train$target == "0")
sum(train$target == "1")
sum(train$target == "0") / dim(train) * 100
sum(train$target == "1") / dim(train) * 100
dim(train)[0]
dim(train)
nrows(train)
nrows(train$target)
rows(train$target)
nrows(train)
dim(train)[1]
dim(train)[0]
dim(train)[1]
sum(train$target == "0") / dim(train)[1] * 100
sum(train$target == "1") / dim(train)[1] * 100
library(tidyverse)
train <- read.csv("train.csv", na.strings=c("","NA"))
test <- read.csv("test.csv", na.strings=c("","NA"))
num(any(is.na(train)))
num(any(is.na(test)))
# missing values
sum(any(is.na(train)))
sum(any(is.na(test)))
colSums(sapply(train, is.na))
colSums(sapply(test, is.na))
mean(train$target)
mean(train$target)*100
1-mean(train$target)*100
1-(mean(train$target)*100)
1-mean(train$target)*100
1-42.96598
100 - (mean(train$target)*100)
library(tidyverse)
train <- read.csv("train.csv", na.strings=c("","NA"))
test <- read.csv("test.csv", na.strings=c("","NA"))
train$target <- as.factor(train$target)
# distribution of the target variable
ggplot(train, aes(x=target)) +
geom_bar(aes(fill=target))
sum(train$target == "0") / dim(train)[1] * 100 # 57%
sum(train$target == "1") / dim(train)[1] * 100 # 43%
# missing values
colSums(sapply(train, is.na))
colSums(sapply(test, is.na))
# delete id variable
train$id <- NULL
test$id <- NULL
knitr::opts_chunk$set(echo = TRUE)
colSums(sapply(train, is.na))
colSums(sapply(test, is.na))
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(mlbench)
data(Sonar)
str(Sonar)
dim(Sonar)
set.seed(107)
inTrain <- createDataPartition(y=Sonar$Class, p=.75, list=FALSE)
training <- Sonar[inTrain, ]
testing <- Sonar[-inTrain, ]
dim(training)
dim(testing)
set.seed(107)
folds <- createFolds(y=Sonar$Class, k=10, list=TRUE,
returnTrain = TRUE)
lapply(folds, length)
fold <- folds[[1]]
training_folds <- Sonar[fold, ]
testing_folds <- Sonar[-fold, ]
dim(training_folds)
dim(testing_folds)
set.seed(107)
resample <- createResample(y=Sonar$Class, times=10, list=TRUE)
lapply(resample, length)
fold <- resample[[1]]
training_resample <- Sonar[fold, ]
testing_resample <- Sonar[-fold, ]
dim(training_resample)
dim(testing_resample)
ldaModel <- train (Class ~ ., data=training, method="lda",
preProc=c("center","scale"))
ldaModel
ctrl <- trainControl(method = "repeatedcv", repeats=3)
ldaModel3x10cv <- train (Class ~ ., data=training,method="lda",
trControl=ctrl,
preProc=c("center","scale"))
ldaModel3x10cv
ctrl <- trainControl(method = "repeatedcv", repeats=3,
classProbs=TRUE,
summaryFunction=twoClassSummary)
ldaModel3x10cv <- train (Class ~ ., data=training, method="lda",
trControl=ctrl,metric="ROC",
preProc=c("center","scale"))
ldaModel3x10cv
plsFit3x10cv <- train (Class ~ ., data=training,method="pls",
trControl=ctrl,metric="ROC",
preProc=c("center","scale"))
plsFit3x10cv
plot(plsFit3x10cv)
plsFit3x10cv <- train (Class ~ ., data=training,method="pls",
trControl=ctrl,
metric="ROC", tuneLength=15,
preProc=c("center","scale"))
plsFit3x10cv
plot(plsFit3x10cv)
plsProbs <- predict(plsFit3x10cv, newdata = testing, type = "prob")
plsClasses <- predict(plsFit3x10cv, newdata = testing, type = "raw")
confusionMatrix(data=plsClasses, testing$Class)
resamps = resamples(list(pls=plsFit3x10cv, lda=ldaModel3x10cv))
summary(resamps)
xyplot(resamps, what="BlandAltman")
diffs <- diff(resamps)
summary(diffs)
library(tidyverse)
train <- read.csv("train.csv", na.strings=c("","NA"))
dim(train)
test <- read.csv("test.csv", na.strings=c("","NA"))
dim(test)
str(train)
str(test)
str(train$target)
train$target <- as.factor(train$target)
str(train$target)
ggplot(train, aes(x=target)) +
geom_bar(aes(fill=target))
sum(train$target == "0") / dim(train)[1] * 100
sum(train$target == "1") / dim(train)[1] * 100
unique(train$location)
unique(test$location)
sum(unique(train$location))
sum(unique(test$location))
length(unique(train$location))
length(unique(test$location))
length(unique(train$keyword))
length(unique(test$keyword))
## keyword
length(unique(train$keyword))
length(unique(test$keyword))
## location
length(unique(train$location))
length(unique(test$location))
## text
length(unique(train$text))
length(unique(test$text))
length(unique(train$keyword))
length(unique(test$keyword))
# These are the same 222 unique values that are present in train. This makes it convenient to deal with this variable.
# Cnvert keyword to a categorical variable.
train$keyword <- as.factor(train$keyword)
test$keyword <- as.factor(test$keyword)
library(tidyverse)
train <- read.csv("train.csv", na.strings=c("","NA"))
test <- read.csv("test.csv", na.strings=c("","NA"))
train$target <- as.factor(train$target)
# distribution of the target variable
ggplot(train, aes(x=target)) +
geom_bar(aes(fill=target))
sum(train$target == "0") / dim(train)[1] * 100 # 57%
sum(train$target == "1") / dim(train)[1] * 100 # 43%
# missing values
colSums(sapply(train, is.na))
colSums(sapply(test, is.na))
# delete id variable
train$id <- NULL
test$id <- NULL
## keyword
length(unique(train$keyword))
length(unique(test$keyword))
# These are the same 222 unique values that are present in train. This makes it convenient to deal with this variable.
# Cnvert keyword to a categorical variable.
train$keyword <- as.factor(train$keyword)
test$keyword <- as.factor(test$keyword)
train$keyword <- as.factor(train$keyword)
test$keyword <- as.factor(test$keyword)
# Let’s verify that the factor levels of keyword in train and test match.
all.equal(levels(train$keyword), levels(test$keyword))
cor(train$keyword, train$location)
cor(as.numeric(train$keyword), as.numeric(train$location))
length(unique(train$location))
length(unique(test$location))
library(tidyverse)
train <- read.csv("train.csv", na.strings=c("","NA"))
test <- read.csv("test.csv", na.strings=c("","NA"))
train$target <- as.factor(train$target)
# distribution of the target variable
ggplot(train, aes(x=target)) +
geom_bar(aes(fill=target))
sum(train$target == "0") / dim(train)[1] * 100 # 57%
sum(train$target == "1") / dim(train)[1] * 100 # 43%
# missing values
colSums(sapply(train, is.na))
colSums(sapply(test, is.na))
# correlations
cor(as.numeric(train$keyword), as.numeric(train$location))
# delete id variable
train$id <- NULL
test$id <- NULL
## keyword
length(unique(train$keyword))
length(unique(test$keyword))
# These are the same 222 unique values that are present in train. This makes it convenient to deal with this variable.
# Cnvert keyword to a categorical variable.
train$keyword <- as.factor(train$keyword)
test$keyword <- as.factor(test$keyword)
# Let’s verify that the factor levels of keyword in train and test match.
all.equal(levels(train$keyword), levels(test$keyword))
## location
length(unique(train$location))
length(unique(test$location))
# We notice that the unique values of location in train and test aren’t the same. Hence, we cannot simply convert
# location to a categorical variable.
# Convert location to a bag of words.
# Let’s bind the rows of train and test (except the target variable) into a single data frame.
train_and_test <- rbind(train[, 1:4], test)
str(train_and_test)
# Let’s bind the rows of train and test (except the target variable) into a single data frame.
train_and_test <- rbind(train[, 1:3], test)
str(train_and_test)
View(train_and_test)
corpus_location <- Corpus(VectorSource(train_and_test$location))
corpus_location
?Corpus
??Corpus
# 1. Create a corpus
corpus_location <- Corpus(VectorSource(train_and_test$location))
corpus_location
library(tidyverse)
library(tm)
train <- read.csv("train.csv", na.strings=c("","NA"))
test <- read.csv("test.csv", na.strings=c("","NA"))
train$target <- as.factor(train$target)
# distribution of the target variable
ggplot(train, aes(x=target)) +
geom_bar(aes(fill=target))
sum(train$target == "0") / dim(train)[1] * 100 # 57%
sum(train$target == "1") / dim(train)[1] * 100 # 43%
# missing values
colSums(sapply(train, is.na))
colSums(sapply(test, is.na))
# correlations
cor(as.numeric(train$keyword), as.numeric(train$location))
# delete id variable
train$id <- NULL
test$id <- NULL
## keyword
length(unique(train$keyword))
length(unique(test$keyword))
# These are the same 222 unique values that are present in train. This makes it convenient to deal with this variable.
# Cnvert keyword to a categorical variable.
train$keyword <- as.factor(train$keyword)
test$keyword <- as.factor(test$keyword)
# Let’s verify that the factor levels of keyword in train and test match.
all.equal(levels(train$keyword), levels(test$keyword))
## location
length(unique(train$location))
length(unique(test$location))
# We notice that the unique values of location in train and test aren’t the same. Hence, we cannot simply convert
# location to a categorical variable.
# Convert location to a bag of words.
# Let’s bind the rows of train and test (except the target variable) into a single data frame.
train_and_test <- rbind(train[, 1:3], test)
str(train_and_test)
# 1. Create a corpus
corpus_location <- Corpus(VectorSource(train_and_test$location))
corpus_location
# 2. Convert to lowercase
corpus_location <- tm_map(corpus_location, tolower)
corpus_location <- tm_map(corpus_location, removePunctuation)
# 1. Create a corpus
corpus_location <- Corpus(VectorSource(train_and_test$location))
corpus_location
# 2. Convert to lowercase
corpus_location <- tm_map(corpus_location, tolower)
# 3. Remove punctuation
corpus_location <- tm_map(corpus_location, removePunctuation)
# 4. REmove stopwords
corpus_location <- tm_map(corpus_location, removeWords, stopwords("english"))
?tm_map
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
myCorpus <- tm_map(corpus_location, removeURL)
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
corpus_location <- tm_map(corpus_location, content_transformer(removeURL))
# 2. Convert to lowercase
corpus_location <- tm_map(corpus_location, content_transformer(stri_trans_tolower))
# 1. Create a corpus
corpus_location <- Corpus(VectorSource(train_and_test$location))
corpus_location
# 2. Convert to lowercase
corpus_location <- tm_map(corpus_location, tolower)
# 3. Remove punctuation
corpus_location <- tm_map(corpus_location, removePunctuation)
# 4. Remove stopwords
corpus_location <- tm_map(corpus_location, removeWords, stopwords("english"))
# 5. Remove links
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
corpus_location <- tm_map(corpus_location, content_transformer(removeURL))
View(corpus_location)
# 1. Create a corpus
corpus_location <- Corpus(VectorSource(train_and_test$location))
corpus_location
# 2. Convert to lowercase
corpus_location <- tm_map(corpus_location, tolower)
# 3. Remove punctuation
corpus_location <- tm_map(corpus_location, removePunctuation)
# 4. Remove stopwords
corpus_location <- tm_map(corpus_location, removeWords, stopwords("english"))
# 5. Remove links
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
corpus_location <- tm_map(corpus_location, content_transformer(removeURL))
# 6. Removing usernames
removeUsername <- function(x) gsub("@[^[:space:]]*", "", x)
corpus_location <- tm_map(corpus_location, content_transformer(removeUsername))
View(corpus_location)
library(tidyverse)
library(tm)
train <- read.csv("train.csv", na.strings=c("","NA"))
test <- read.csv("test.csv", na.strings=c("","NA"))
train$target <- as.factor(train$target)
# distribution of the target variable
ggplot(train, aes(x=target)) +
geom_bar(aes(fill=target))
sum(train$target == "0") / dim(train)[1] * 100 # 57%
sum(train$target == "1") / dim(train)[1] * 100 # 43%
# missing values
colSums(sapply(train, is.na))
colSums(sapply(test, is.na))
# correlations
cor(as.numeric(train$keyword), as.numeric(train$location))
# delete id variable
train$id <- NULL
test$id <- NULL
## keyword
length(unique(train$keyword))
length(unique(test$keyword))
# These are the same 222 unique values that are present in train. This makes it convenient to deal with this variable.
# Cnvert keyword to a categorical variable.
train$keyword <- as.factor(train$keyword)
test$keyword <- as.factor(test$keyword)
# Let’s verify that the factor levels of keyword in train and test match.
all.equal(levels(train$keyword), levels(test$keyword))
## location
length(unique(train$location))
length(unique(test$location))
# We notice that the unique values of location in train and test aren’t the same. Hence, we cannot simply convert
# location to a categorical variable.
# Convert location to a bag of words.
# Let’s bind the rows of train and test (except the target variable) into a single data frame.
train_and_test <- rbind(train[, 1:3], test)
str(train_and_test)
corpus_location <- Corpus(VectorSource(train_and_test$location))
corpus_location[[50]]$content
corpus_location <- tm_map(corpus_location, tolower)
corpus_location[[50]]$content
corpus_location <- tm_map(corpus_location, removePunctuation)
corpus_location[[50]]$content
# 1. Create a corpus
corpus_location <- Corpus(VectorSource(train_and_test$location))
corpus_location[[33]]$content
# 2. Convert to lowercase
corpus_location <- tm_map(corpus_location, tolower)
corpus_location[[33]]$content
# 3. Remove punctuation
corpus_location <- tm_map(corpus_location, removePunctuation)
corpus_location[[33]]$content
# 4. Remove stopwords
corpus_location <- tm_map(corpus_location, removeWords, stopwords("english"))
corpus_location[[50]]$content
# 3. Remove punctuation
corpus_location <- tm_map(corpus_location, removePunctuation)
corpus_location[[33]]$content
# 4. Remove stopwords
corpus_location <- tm_map(corpus_location, removeWords, stopwords("english"))
corpus_location[[33]]$content
corpus_location <- tm_map(corpus_location, stemDocument)
corpus_location[[33]]$content
# Let’s bind the rows of train and test (except the target variable) into a single data frame.
train_and_test <- rbind(train[, 1:3], test)
str(train_and_test)
# 1. Create a corpus
corpus_location <- Corpus(VectorSource(train_and_test$location))
corpus_location[[33]]$content
# 2. Convert to lowercase
corpus_location <- tm_map(corpus_location, tolower)
corpus_location[[33]]$content
# 3. Remove punctuation
corpus_location <- tm_map(corpus_location, removePunctuation)
corpus_location[[33]]$content
# 4. Remove stopwords
corpus_location <- tm_map(corpus_location, removeWords, stopwords("english"))
corpus_location[[33]]$content
# 5. Stemming (using Porter’s stemming algorithm)
corpus_location <- tm_map(corpus_location, stemDocument)
corpus_location[[33]]$content
