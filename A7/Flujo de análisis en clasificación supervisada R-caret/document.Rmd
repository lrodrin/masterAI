---
title: "Flujo de análisis en clasificación supervisada"
author: "Laura Rodríguez Navas"
date: "Septiembre 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Comenzamos cargando los paquetes y la base de datos:

```{r message=FALSE}
library(caret)
library(mlbench)
data(Sonar)
str(Sonar)
dim(Sonar)
```

La base de datos *Sonar*, con 208 instancias, contiene 60 variables explicativas numéricas y dos valores en la variable clase ("M" y "R"). 

Definimos las instancias de train y test que darán forma al modelo de clasificación. Fijamos una semilla para futuras generaciones de números aleatorios. Hacemos uso de la función **createDataPartition** para generar una partición train-test de las 208 instancias, que mantendremos durante todo el flujo de análisis.

Cross validation, split the data into train (75%) and test (30%).

```{r}
set.seed(107)
inTrain <- createDataPartition(y=Sonar$Class, p=.75, list=FALSE)
training <- Sonar[inTrain, ]
testing <- Sonar[-inTrain, ]
dim(training)
dim(testing)
```

K-Fold Cross Validation

Create 10 fold cross validation. This will create 10 folds, each with a training set(approx 187 records) and test set(approx 20 records).

```{r}
set.seed(107)
folds <- createFolds(y=Sonar$Class, k=10, list=TRUE, 
                     returnTrain = TRUE)
lapply(folds, length)

fold <- folds[[1]]
training_folds <- Sonar[fold, ]
testing_folds <- Sonar[-fold, ]
dim(training_folds)
dim(testing_folds)
```

Create 10 resamples (sampling with replacement) from the data. Each sample will have the 208 rows.

```{r}
set.seed(107)
resample <- createResample(y=Sonar$Class, times=10, list=TRUE)
lapply(resample, length)

fold <- resample[[1]]
training_resample <- Sonar[fold, ]
testing_resample <- Sonar[-fold, ]
dim(training_resample)
dim(testing_resample)
```


```{r}
ldaModel <- train (Class ~ ., data=training, method="lda", 
                   preProc=c("center","scale"))
ldaModel

ctrl <- trainControl(method = "repeatedcv", repeats=3)
ldaModel3x10cv <- train (Class ~ ., data=training,method="lda", 
                         trControl=ctrl, 
                         preProc=c("center","scale"))
ldaModel3x10cv
```


```{r}
ctrl <- trainControl(method = "repeatedcv", repeats=3, 
                     classProbs=TRUE, 
                     summaryFunction=twoClassSummary)
ldaModel3x10cv <- train (Class ~ ., data=training, method="lda", 
                         trControl=ctrl,metric="ROC", 
                         preProc=c("center","scale"))
ldaModel3x10cv
```


```{r fig.align='center'}
plsFit3x10cv <- train (Class ~ ., data=training,method="pls", 
                       trControl=ctrl,metric="ROC", 
                       preProc=c("center","scale"))
plsFit3x10cv
plot(plsFit3x10cv)

plsFit3x10cv <- train (Class ~ ., data=training,method="pls", 
                       trControl=ctrl, 
                       metric="ROC", tuneLength=15, 
                       preProc=c("center","scale"))
plsFit3x10cv
plot(plsFit3x10cv)
```

```{r}
plsProbs <- predict(plsFit3x10cv, newdata = testing, type = "prob")
plsClasses <- predict(plsFit3x10cv, newdata = testing, type = "raw")
confusionMatrix(data=plsClasses, testing$Class)
```

```{r fig.align='center'}
resamps = resamples(list(pls=plsFit3x10cv, lda=ldaModel3x10cv))
summary(resamps)
xyplot(resamps, what="BlandAltman")
diffs <- diff(resamps)
summary(diffs)
```
## Ejercicio propuesto

Cargamos las librerías necesarias:

```{r message=FALSE}
library(tidyverse)
library(tm)
library(SnowballC)
```

El dataset escogido se puede encontrar en (https://www.kaggle.com/c/nlp-getting-started/data). Este dataset, con 10.876 instancias, contiene 4 variables explicativas; *id*, *keyword*, *location* y *test*, y dos valores en la variable clase *target* (1 y 0). La variable clase es de tipo binaria así que vamos a aprender un modelo de clasificación binaria, y 
vamos a predecir si dado un tweet, este tweet trata sobre un desastre real o no. Si es un desastre real, se predice un 1. Si no, se predice un 0. 

La partición inicial train-test, no se tiene que realizar, ya que las instancias de train y test ya vienen definidas en los ficheros *train.csv* y *test.csv*, proporcionados por la competición en [Kaggle](https://www.kaggle.com/c/nlp-getting-started/overview) que se ha elegido. El conjunto de datos de train contiene 7613 instancias y el conjunto de datos de test contiene 3262 instancias.

Cargamos el dataset:

```{r}
train <- read.csv("train.csv", na.strings=c("","NA"))
dim(train)
test <- read.csv("test.csv", na.strings=c("","NA"))
dim(test)
```

Cada instancia en el conjunto de train y test contiene la siguiente información:

- **id**: un identificador único para cada tweet. 
- **keyword**: una palabra clave del tweet (puede estar en blanco).
- **location**: la ubicación desde la que se envió el tweet (puede estar en blanco).
- **text**: el texto del tweet. 
- **target**: solo en el conjunto de datos de train porqué es la variable clase a predecir. Indica si un tweet es sobre un desastre real (1) o no (0). 

```{r}
str(train)
str(test)
```

Factorización de la variable clase, que inicialmente es de tipo entero.

```{r}
str(train$target)
train$target <- as.factor(train$target)
str(train$target)
```

Distribución de la variable clase:

```{r fig.align='center'}
ggplot(train, aes(x=target)) + 
  geom_bar(aes(fill=target))

sum(train$target == "0") / dim(train)[1] * 100
sum(train$target == "1") / dim(train)[1] * 100
```

La distribución de la variable a predecir está relativamente equilibrada, donde el 57% de las instancias de los tweets son sobre un desastre no real y el 43% sobre un desastre real.

[//]: # (método de resampling)

### correlaciones entre variables explicativas

### mética de evaluación

### valores perdidos

```{r}
colSums(sapply(train, is.na))
colSums(sapply(test, is.na))
```

Las variables *keyword* y *location* tienen valores perdidos. Sobretodo hay una gran cantidad de tweets, para los cuales falta la ubicación. Potencialmente, esto podría ser una buena variable predictiva en sí misma. No faltan valores en las variables *target* y *text*.

Nos ocuparemos de los valores perdidos más adelante. 

Eliminamos la variable *id*.

```{r}
train$id <- NULL
test$id <- NULL
```

## keyword

```{r}
length(unique(train$keyword))
length(unique(test$keyword))
train$keyword <- as.factor(train$keyword)
all.equal(levels(train$keyword), levels(test$keyword))
```

## location

```{r}
length(unique(train$location))
length(unique(test$location))
train_and_test <- rbind(train[, 1:3], test)
str(train_and_test)
```

1. Create a corpus
2. Convert to lowercase
3. Remove punctuation
4. Remove stopwords
5. Stemming (using Porter’s stemming algorithm)
6. Create document term matrix

```{r warning=FALSE}
corpus_location <- Corpus(VectorSource(train_and_test$location))
corpus_location[[33]]$content

corpus_location <- tm_map(corpus_location, tolower)
corpus_location[[33]]$content

corpus_location <- tm_map(corpus_location, removePunctuation)
corpus_location[[33]]$content

corpus_location <- tm_map(corpus_location, removeWords, stopwords("english"))
corpus_location[[33]]$content
 
corpus_location <- tm_map(corpus_location, stemDocument)
corpus_location[[33]]$content
```

- Create document term matrix
- Reduce sparsity
- Convert to data frame

```{r}
dtm_location <- DocumentTermMatrix(corpus_location)
dtm_location

dtm_location <- removeSparseTerms(dtm_location, 0.9975)
dtm_location

bag_of_words_location <- as.data.frame(as.matrix(dtm_location))
colnames(bag_of_words_location) <- paste0(colnames(bag_of_words_location), "_location")
str(bag_of_words_location, list.len=10)
```


## text
