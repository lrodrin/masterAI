---
title: "Flujo de análisis en clasificación supervisada"
author: "Laura Rodríguez Navas"
date: "Septiembre 2020"
output:
  pdf_document: 
    toc: yes
    fig_caption: yes
    fig_crop: no
    keep_tex: yes
    includes:
      in_header: preamble.tex
  html_document: default
subtitle: Métodos supervisados
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Empezamos por cargar a nuestro espacio de trabajo los paquetes que usaremos:

- tidyverse
- stringi
- tm, específico para minería de textos.
- irlba
- RColorBrewer
- gridExtra
- gbm

```{r message=FALSE}
library(tidyverse)
library(stringi)
library(tm)
library(irlba)
library(RColorBrewer)
library(gridExtra)
library(caret)
library(doParallel)
library(syuzhet)
library(ggcorrplot)
library(gbm)
```

## Análisis Exploratorio de los Datos

Para la realización del ejercicio propuesto se ha elegido la competición en Kaggle: **Real or Not? NLP with Disaster Tweets**. El dataset de la competición se puede encontrar en el siguiente enlace: https://www.kaggle.com/c/nlp-getting-started/data. Este dataset, con 10.876 instancias, contiene 4 variables explicativas: **id**, **keyword**, **location** y **text**, y dos valores en la variable clase **target** (0 y 1). Como podemos observar la variable clase es binaria, así que, durante este ejercicio vamos a aprender un modelo de clasificación binaria. El objetivo de este modelo será predecir si dado un tweet, éste trata sobre un desastre real o no. Si un tweet trata sobre un desastre real, se predice un 1. Si no, se predice un 0.

La métrica de evaluación esperada por la competición es **F1 score**. Para ver como se calcula consultar el siguiente enlace: https://www.kaggle.com/c/nlp-getting-started/overview/evaluation.

La partición inicial train-test, no se tiene que realizar, ya que las instancias de train y test ya vienen definidas en el dataset de la competición (descargar a nuestro espacio de trabajo los ficheros **train.csv** y **test.csv** de https://www.kaggle.com/c/nlp-getting-started/data). 

Cargamos a nuestro espacio de trabajo los conjuntos de datos de train y test descargados, renombrando los valores perdidos como **NA** para que los podamos tratar más adelante. También mostramos las dimensiones de los conjuntos de datos usando la función **dim**. 

```{r}
train <- read.csv("train.csv", na.strings=c("", "NA"))
test <- read.csv("test.csv", na.strings=c("", "NA"))
dim(train)
dim(test)
```

Vemos que el conjunto de datos de train contiene 7613 instancias y el conjunto de datos de test contiene 3263 instancias. Cada instancia contiene las siguientes variables:

- **id**: un identificador único para cada tweet. 
- **keyword**: una palabra clave del tweet.
- **location**: la ubicación desde la que se envió el tweet.
- **text**: el texto del tweet. 
- **target**: solo en el conjunto de datos de train porqué es la variable clase a predecir. Indica si un tweet corresponde a un desastre real (1) o no (0). 

```{r echo=FALSE}
str(train, width = 85, strict.width = "cut")
str(test, width = 85, strict.width = "cut")
```

Analizamos las variables más detenidamente a continuación.

### Variable *target*

Como ya hemos comentado, la variable **target** es la variable a predecir. Primero la categorizamos, ya que inicialmente es de tipo entero, y observamos su distribución.

```{r fig.align='center', out.width='70%'}
train$target <- as.factor(ifelse(train$target == 0, "No", "Yes"))
ggplot(train, aes(x=target)) + geom_bar(aes(fill=target))
```

Su distribución no está muy sesgada y está relativamente equilibrada. Observamos que hay menos tweets que se refieren a desastres reales (clase minoritaria), donde el 43% de las observaciones son desastrosas y el 57% no. 

```{r}
sum(train$target == "Yes") / dim(train)[1] * 100
sum(train$target == "No") / dim(train)[1] * 100
```

Parece que no presenta un problema notable de *desbalanceo de clase*, porqué contamos con muchas muestras del caso minoritario.

### Variable *keyword*

La variable explicativa **keyword** representa una palabra clave de cada tweet y a continuación se muestran las 10 primeras del conjunto de datos de train.

```{r}
train %>% select(keyword) %>% unique() %>% head(10)
```

Nuestro interés ahora es ver si existen correlaciones entre la variable **keyword** con la variable a predecir. Para ello realizaremos un análisis de sentimientos. 

*El análisis de sentimientos es una técnica de [Machine Learning](https://en.wikipedia.org/wiki/Machine_learning), basada en el [procesado del lenguaje natural](https://www.kdnuggets.com/2017/02/natural-language-processing-key-terms-explained.html), que pretende obtener información subjetiva de una serie de textos. Su aplicación es este caso, consiste en resolver si un tweet es real o no en relación a un desastre.*

Para el análisis de sentimientos usamos los paquetes de R: **syuzhet**, **ggcorrplot** y **doParallel**.

- El paquete **syuzhet** cuenta con la función **get_nrc_sentiment** que calcula la presencia de los diferentes sentimientos dado un conjunto de textos. Los parámetros de esta función son:
  - **char_v**. Un vector de caracteres que en este caso contendrá todas las palabras clave.
  - **language**. Define el lenguaje. Los tweets están en inglés, así que el lenguaje será el inglés.
  - **cl**. Para el análisis en paralelo. Es opcional, pero en este caso lo usaremos porqué hay muchas palabras clave.
- **ggcorrplot** muestra una visualización gráfica de una matriz de correlación usando *ggplot2*.
- **doParallel** proporciona computación paralela. Los parámetros de esta función son:
  - **makePSOCKcluster**. Crea un clúster de sockets paralelos.
  - **registerDoParallel**. Registra el número de *cores* que usará el clúster creado. 
  - **stopCluster**. Detiene la computación paralela.
  
La computación paralela la usaremos en muchas de las ejecuciones de este ejercicio ya que nos encontramos delante de un problema de *alta dimensionalidad*. Eso es, que la dimensionalidad de nuestros datos es muy elevada y puede reducir drásticamente la eficiencia de los algoritmos de clasificación supervisada que entrenaremos. Una de las técnicas más ampliamente utilizada y conocida para la reducción de la dimensionalidad es Principal Component Analysis (PCA) Esta técnica lleva a cabo la transformación de los datos generando unas nuevas variables.

La reducción de la dimensionalidad que aplicaremos en este ejercicio se realiza más adelante y se calculará teniendo en cuenta las palabras más frecuentes de los tweets del conjunto de datos.

### Análisis de sentimientos entre *keyword* y *target*:

```{r fig.align='center', warning=FALSE, out.width='70%'}
cl <- makePSOCKcluster(4, setup_strategy="sequential")
registerDoParallel(cl)

emocion.df <- get_nrc_sentiment(char_v = gsub("_", " ", train$keyword), 
                                language = "english", cl=cl)

emocion.df <- emocion.df %>% data.frame(target = train$target)
emocion.df$target <- as.numeric(emocion.df$target)

cor(emocion.df) %>% 
  ggcorrplot(lab = TRUE, 
             title = "Matriz de correlación entre los \nsentimientos de keyword y target",
             legend.title = "correlation")

stopCluster(cl)
```

Al observar la matriz de correlaciones, se observa una correlación nula con cada uno de los sentimientos. Esto hace que esta variable explicativa no sea buena para hacer una predicción. 

### Variable *location*

La variable **location** representa la ubicación desde donde se generaron los tweets, se muestran las primeras 10.

```{r}
train %>% select(location) %>% unique() %>% head(10)
count(train %>% select(location) %>% unique())
```

En total hay 3342 ubicaciones. A continuación, mostramos las ubicaciones más frecuentes:

```{r fig.align='center', out.width='70%'}
location.freq <- table(unlist(train %>% select(location)))
location.freq[which(location.freq > 10)]
barplot(location.freq[which(location.freq>10)], las = 2,  
        ylab = "Frequency")
```

Del total de ubicaciones (3342), la mayoría de ellas cuenta con menos de 10 observaciones. Esto hace que esta variable explicativa tampoco sea buena para hacer una predicción. 

### Variable *text*
 
Hemos considerado que las variables explicativas **keyword** y **location** no son buenas para hacer una predicción, así que nos centraremos en la variable **text**. 

Llegados a este punto unimos los conjuntos de train y test (*7613 + 3263 observaciones*) para poder extraer los sentimientos más adelante.

```{r}
complete_df <- bind_rows(train, test)
dim(complete_df)
```

Echamos un vistazo más de cerca a las variables del nuevo conjunto de datos **complete_df**.

```{r}
summary(complete_df)
```

La variable **id** es solo un identificador único y la eliminaremos.

```{r}
complete_df$id <- NULL
```

Observamos si existen valores perdidos.

```{r}
colSums(sapply(complete_df, is.na))
```

Las variables explicativas **keyword** y **location** contienen valores perdidos. Sobretodo hay una gran cantidad de tweets, para los cuales falta su ubicación. No existen valores perdidos para la variable explicativa **text**, tampoco para la variable a predecir **target**. Los 3263 valores perdidos de la variable a predecir provienen del conjunto de datos de test. Nos ocuparemos de los valores perdidos más adelante.

Parece que la variable explicativa **text** es una buena elección para una buena predicción y basaremos los siguientes pasos en ella.

## Procesamiento de texto

Como en todo procesamiento de lenguaje natural, realizaremos el procesamiento de un conjunto de textos. En este caso realizaremos un procesamiento de los textos de los tweets y los prepararemos para el modelado. Comencemos por crear un corpus de los mensajes de texto de los tweets. Para ello usaremos la función **Corpus** del paquete **tm**, que creará nuestro corpus a partir de un vector de textos. La función **VectorSource** interpretará cada mensaje de texto de los tweets como un elemento del vector de textos.

*Un corpus lingüístico se define como “un conjunto de textos de un mismo origen” y que tiene por función recopilar un conjunto de textos. El uso de un corpus lingüístico nos permitirá obtener información de las palabras utilizadas con más o menor frecuencia.*

```{r}
myCorpus <- Corpus(VectorSource(complete_df$text))
```

Durante el procesamiento de texto seguiremos la transformación de un mensaje de tweet específico para ver como se modifica a medida que avanzamos en el procesamiento de texto. Este mensaje es:

```{r}
paste0(myCorpus[[400]])
```
Dividimos el procesamiento de texto en 7 pasos.

1. Eliminar enlaces.

```{r warning=FALSE}
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)  
myCorpus <- tm_map(myCorpus, content_transformer(removeURL))
paste0(myCorpus[[400]])
```
Hemos eliminado: *http://t.co/Wf8iTK2KVx*.

La función **gsub** busca y reemplaza desde la primera hasta todas las coincidencias de un patrón (que normalmente representa una *regular expression*). La función **tm_map** es la encargada de aplicar las diferentes transformaciones de los textos al corpus creado.

2. Convertir a minúsculas.

```{r warning=FALSE}
myCorpus <- tm_map(myCorpus, content_transformer(stri_trans_tolower))
paste0(myCorpus[[400]])
```

3. Eliminar los nombres de usuario.

```{r warning=FALSE}
removeUsername <- function(x) gsub("@[^[:space:]]*", "", x)  
myCorpus <- tm_map(myCorpus, content_transformer(removeUsername))
paste0(myCorpus[[400]])
```

Hemos eliminado: *@huffpostrelig*.

4. Eliminar todo excepto el idioma y el espacio en inglés.

```{r warning=FALSE}
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)   
myCorpus <- tm_map(myCorpus, content_transformer(removeNumPunct))
paste0(myCorpus[[400]])
```

No se observan cambios en en ejemplo.

5. Eliminar palabras irrelevantes (eliminación de redundancias).

```{r warning=FALSE}
myStopWords <- c((stopwords('english')), 
         c("really", "tweets", "saw", "just", "feel", "may", "us", "rt", "every", "one",
           "amp", "like", "will", "got", "new", "can", "still", "back", "top", "much",
           "near", "im", "see", "via", "get", "now", "come", "oil", "let", "god", "want",
           "pm", "last", "hope", "since", "everyone", "food", "content", "always", "th",
           "full", "found", "dont", "look", "cant", "mh", "lol", "set", "old", "service",
           "city", "home", "live", "night", "news", "say", "video", "people", "ill", 
           "way",  "please", "years", "take", "homes", "read", "man", "next", "cross", 
           "boy", "bad", "ass"))

myCorpus <- tm_map(myCorpus, removeWords, myStopWords) 
paste0(myCorpus[[400]])
```
Hemos eliminado: at the where a is being after via.

Las palabras irrelevantes que hemos eliminado se denominan *stop words o palabras vacías*. Cada idioma tiene sus propias palabras vacías. Como los textos están en inglés hemos eliminado los *stop words* que pertenecen al inglés usando la función **stopwords**, además hemos añadido aleatóriamente alguna de las palabras vacías más usadas en los mensajes de texto de los tweets (ver https://techland.time.com/2009/06/08/the-500-most-frequently-used-words-on-twitter/).

*Las stop words o palabras vacías son todas aquellas palabras que carecen de un significado por si solas. Suelen ser artículos, preposiciones, conjunciones, pronombres, etc.*

6. Eliminar palabras de una sola letra.

```{r warning=FALSE}
removeSingle <- function(x) gsub(" . ", " ", x)   
myCorpus <- tm_map(myCorpus, content_transformer(removeSingle))
paste0(myCorpus[[400]])
```
No se observan cambios en en ejemplo.

7. Eliminar espacios en blanco adicionales.

```{r warning=FALSE}
myCorpus <- tm_map(myCorpus, stripWhitespace)
paste0(myCorpus[[400]])
```

Terminamos con el procesamiento de texto. A continuación, crearemos dos *Term Document Matrix* (matriz que describe la frecuencia de las palabras que se producen en una colección de textos) para un análisis de sentimientos más detallado. Usaremos la función **TermDocumentMatrix** y dividiremos el corpus en dos, según el número de elementos de los conjuntos de datos train y test. Recordamos que el conjunto de datos de train contiene 7613 observaciones, y el conjunto de datos de test contiene 3263 observaciones. El parámetro **control** evalúa cada texto de la matriz, específicamente se evaluaran todas las palabras de cada texto (no aplicamos ningún filtro).

```{r}
train_tdm <- TermDocumentMatrix(myCorpus[1:7613], 
                                control= list(wordLengths= c(1, Inf)))
test_tdm <- TermDocumentMatrix(myCorpus[7614:10876], 
                               control= list(wordLengths= c(1, Inf)))
train_tdm
test_tdm
```
La matriz para los datos de train contiene 14825 palabras y la matriz para los datos de test contiene 8966 palabras. Utilizaremos las matrices para ver las palabras más utilizadas en los tweets y predecir a partir de ellas.

## Palabras más frecuentes

- Palabras más frecuentes en los datos de train.

```{r fig.align='center', out.width='70%'}
train.term.freq <- rowSums(as.matrix(train_tdm))
train.term.freq <- subset(train.term.freq, train.term.freq > 60)
freq_train_df <- data.frame(term = names(train.term.freq), freq= train.term.freq)
head(freq_train_df[order(-freq_train_df$freq), ])
ggplot(freq_train_df, aes(reorder(term, freq), freq)) + theme_bw() + 
  geom_bar(stat = "identity")  + 
  coord_flip() + 
  theme(axis.text.y = element_text(size=7))
```

- Palabras más frecuentes en los datos de test

```{r fig.align='center', out.width='50%'}
test.term.freq <- rowSums(as.matrix(test_tdm))
test.term.freq <- subset(test.term.freq, test.term.freq > 60)
freq_test_df <- data.frame(term = names(test.term.freq), freq= test.term.freq)
freq_test_df[order(-freq_test_df$freq), ]
ggplot(freq_test_df, aes(reorder(term, freq), freq)) + theme_bw() + 
  geom_bar(stat = "identity")  + 
  coord_flip() + 
  theme(axis.text.y = element_text(size=7))
```

Las palabras *"fire"*, *"attack"* y *"emergency"* aparecen con alta frecuencia tanto en el conjunto de train como en el conjunto de test. Estas palabras son muy útiles para predecir un desastre real.

## Modelado

Para la construcción de modelos, necesitamos construir una *Term Document Matrix* donde cada fila represente un texto y cada palabra única esté representada por una columna. Comencemos construyendo la matriz para nuestro corpus completo.

```{r}
complete.tdm <- TermDocumentMatrix(myCorpus, control= list(wordLengths= c(4, Inf)))
complete.term.matrix <- as.matrix(t(complete.tdm))
dim(complete.term.matrix)
```
Podemos ver que es una matriz dispersa con 10876 textos, es decir, tweets y 16880 palabras. Además, se generan algunos casos incompletos, que necesitaremos manejar antes de continuar con la construcción del modelo.

Sin embargo, si intentamos convertir esto para usar esta matriz para la construcción del modelo, es posible que no podamos entrenar nuestro modelo debido a restricciones computacionales. Necesitamos reducir la dimensión/características de la matriz.

Primero tratamos los casos incompletos.

```{r}
incomplete.cases <- which(!complete.cases(complete.term.matrix))
complete.term.matrix[incomplete.cases,] <- rep(0.0, ncol(complete.term.matrix))
```

```{r include=FALSE}
cl <- makePSOCKcluster(4, setup_strategy="sequential")
registerDoParallel(cl)
```


```{r}
complete_irlba <- irlba(t(complete.term.matrix), nv = 150, maxit = 600)
complete_irlba$v[1:10, 1:5]
```


```{r include=FALSE}
stopCluster(cl)
```


```{r}
complete.svd <- data.frame(target = complete_df$target, complete_irlba$v)
train.df <- complete.svd[1:7613, ]
test.df <- complete.svd[7614:10876, -1]
dim(train.df)
dim(test.df)
names(train.df) <- make.names(names(train.df))
names(test.df) <- make.names(names(test.df))
```

```{r}
set.seed(123)
cv.folds <- createMultiFolds(train.df$target, k=5, times=3)
cv.cntrl <- trainControl(method = "repeatecv", number = 5,
                         index = cv.folds, allowParallel = TRUE, returnResamp="final",
                         verboseIter=FALSE)
```

### Regresión Logística

```{r include=FALSE}
cl <- makePSOCKcluster(4, setup_strategy="sequential")
registerDoParallel(cl)
```


```{r}
model_glmnet <- train(target ~ ., data=train.df,
                      method="glmnet",
                      metric="Accuracy",
                      trControl=cv.cntrl,
                      tuneLenght=15)
model_glmnet
```
```{r include=FALSE}
stopCluster(cl)
```

### Random Forest

```{r include=FALSE}
cl <- makePSOCKcluster(4, setup_strategy="sequential")
registerDoParallel(cl)
```


```{r}
model_rf <- train(target ~ ., data=train.df,
                      method="rf",
                      metric="Accuracy",
                      trControl=cv.cntrl,
                      tuneGrid=expand.grid(mtry=c(3, 4, 5, 7)))
model_rf
```

```{r include=FALSE}
stopCluster(cl)
```

### Gradient Boosting

```{r include=FALSE}
cl <- makePSOCKcluster(4, setup_strategy="sequential")
registerDoParallel(cl)
```


```{r}
cv.grid <- expand.grid(interaction.depth=c(1, 2),
                       n.trees=100,
                       shrinkage=c(0.001, 0.01, 0.1),
                       n.minobsinnode=c(2, 5, 25))

model_gbm <- train(target ~ ., data=train.df,
                  method="gbm",
                  metric="Accuracy",
                  trControl=cv.cntrl,
                  tuneGrid=cv.grid,
                  distribution="adaboost",
                  verbose=FALSE)
model_gbm
```

```{r include=FALSE}
stopCluster(cl)
```

### K-Nearest Neighbor (kNN)

```{r include=FALSE}
cl <- makePSOCKcluster(4, setup_strategy="sequential")
registerDoParallel(cl)
```


```{r}
cv.grid <- expand.grid(k=1:3)

model_knn <- train(target ~ ., data=train.df,
                   method="knn",
                   metric="Accuracy",
                   trControl=cv.cntrl,
                   tuneGrid=cv.grid)
model_knn
```

```{r include=FALSE}
stopCluster(cl)
```


### SVM

```{r include=FALSE}
cl <- makePSOCKcluster(4, setup_strategy="sequential")
registerDoParallel(cl)
```


```{r}
cv.grid <- expand.grid(sigma=c(0.001, 0.01, 0.1, 0.5, 1),
                       C=c(1, 20, 50, 100))

model_svm <- train(target ~ ., data=train.df,
                      method="svmRadial",
                      metric="Accuracy",
                      trControl=cv.cntrl,
                      tuneLenght=15)
model_svm
```

```{r include=FALSE}
stopCluster(cl)
```


## Comparación de modelos

### Métrica de validación

### Evaluación de modelos mediante resampling

```{r}
models <- list(KNN=model_knn, logistic=model_glmnet,
               RF=model_rf, boosting=model_gbm, SVMRadial=model_svm)

resamps <- resamples(models)
summary(resamps)
```

## Predicción y resultados

```{r}
pred_svm <- predict(model_svm, test.df, type="raw")
```

```{r}
submission <- read.csv("sample_submission.csv")
submission$target <- ifelse(pred_svm=="No", 0, 1)
head(submission)
write.csv(submission, "submission.csv", row.names=FALSE)
```

## Conclusión

## Referencias

https://www.cienciadedatos.net/documentos/41_machine_learning_con_r_y_caret