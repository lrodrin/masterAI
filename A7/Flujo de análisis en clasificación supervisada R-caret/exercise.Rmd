---
title: "Flujo de análisis en clasificación supervisada"
author: "Laura Rodríguez Navas"
date: "Septiembre 2020"
output:
  html_document: default
  pdf_document: 
    toc: yes
    fig_caption: yes
    fig_crop: no
    keep_tex: yes
    number_sections: yes
subtitle: Métodos supervisados
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Comenzamos cargando los paquetes necesarios.

```{r message=FALSE}
library(caret)
library(dplyr)
library(doParallel)
```

## Descripción

Para la realización del ejercicio propuesto se ha elegido la competición en Kaggle: **Real or Not? NLP with Disaster Tweets**. El dataset de la competición se puede encontrar en el siguiente enlace: https://www.kaggle.com/c/nlp-getting-started/data. Este dataset, con 10.876 instancias, contiene 4 variables explicativas: **id**, **keyword**, **location** y **text**, y dos valores en la variable clase **target** (0 y 1). La variable clase es binaria, así que, vamos a aprender un modelo de clasificación binaria. El objetivo de este modelo será predecir si dado un tweet, este tweet trata sobre un desastre real o no. Si un tweet trata sobre un desastre real, se predice un 1. Si no, se predice un 0.

La métrica de evaluación esperada por la competición es [F1](https://www.kaggle.com/c/nlp-getting-started/overview/evaluation). Y se calcula de la siguiente manera:

```{r echo=FALSE, fig.align='center', out.width='30%'}
knitr::include_graphics('F1_score.png')
```

donde:

```{r echo=FALSE, fig.align='center', out.width='25%'}
knitr::include_graphics('F1_score_2.png')
```

La partición inicial train-test, no se tiene que realizar, ya que las instancias de train y test ya vienen definidas en el dataset de la competición (ficheros **train.csv** y **test.csv**). 

A continuación, cargaremos el conjunto de datos de train y test, nombrando los valores perdidos como **NA** para que los podamos tratar más adelante, y mostraremos sus dimensiones. 

```{r}
train <- read.csv("train.csv", na.strings=c("", "NA"))
test <- read.csv("test.csv", na.strings=c("", "NA"))
dim(train)
dim(test)
```

El conjunto de datos de train contiene 7613 instancias y el conjunto de datos de test contiene 3263 instancias. Cada instancia de estos conjuntos contiene la siguiente información:

* **id**: un identificador único para cada tweet. 
* **keyword**: una palabra clave del tweet.
* **location**: la ubicación desde la que se envió el tweet.
* **text**: el texto del tweet. 
* **target**: solo en el conjunto de datos de train porqué es la variable clase a predecir. Indica si un tweet es sobre un desastre real (1) o no (0). 

```{r}
str(train, width = 85, strict.width = "cut")
str(test, width = 85, strict.width = "cut")
```

Unimos los conjuntos de train y test (*7613 + 3263 observaciones*) para poder analizar y extraer los sentimientos más adelante.

```{r}
complete_df <- bind_rows(train, test)
str(complete_df, width = 85, strict.width = "cut")
```

El análisis de sentimientos es una técnica de *Machine Learning*, basada en el [procesado del lenguaje natural](https://www.kdnuggets.com/2017/02/natural-language-processing-key-terms-explained.html), que pretende obtener información subjetiva de una serie de textos. Su aplicación es este caso, consiste en resolver si un tweet es real o no real en relación a un desastre. 

Tenemos que categorizar la variable a predecir, ya que inicialmente es de tipo entero.

```{r}
train$target <- as.factor(train$target)
str(train, width = 85, strict.width = "cut")
```

En la siguiente figura vemos la distribución de la variable a predecir:

```{r fig.align='center', out.width='70%'}
ggplot(train, aes(x=target)) + geom_bar(aes(fill=target))
sum(train$target == "0") / dim(train)[1] * 100
sum(train$target == "1") / dim(train)[1] * 100
```

La distribución de la variable a predecir está relativamente equilibrada, donde el 57% de las instancias de los tweets son sobre un desastre no real y el 43% sobre un desastre real.

## Gráficas de visualización

## Preprocesamiento

Eliminamos la variable **id**, porqué no nos aporta información interesante. 

```{r}
train$id <- NULL
test$id <- NULL
```

Valores perdidos.

```{r}
colSums(sapply(train, is.na))
colSums(sapply(test, is.na))
```

Las variables explicativas **keyword** y **location** contienen valores perdidos. Sobretodo hay una gran cantidad de tweets, para los cuales falta su ubicación. No existen valores perdidos para **text** y la variable a predecir **target**.

Nos ocuparemos de los valores perdidos más adelante.

### Análisis de sentimientos.

- Examinemos los valores únicos de la variable **keyword**.

```{r}
length(unique(train$keyword))
length(unique(test$keyword))
```
Los mismos valores únicos se encuentran presentes en el conjunto de datos de train y test.

Convertimos la variable **keyword** en una variable categórica.

```{r}
train$keyword <- as.factor(train$keyword)
test$keyword <- as.factor(test$keyword)
```

- Examinemos los valores únicos de la variable **location**.

```{r}
length(unique(train$location))
length(unique(test$location))
```
Vemos que los valores únicos no son los mismos en los conjuntos de datos de train y test. Así que, no podemos simplemente convertir la variable **location** en una variable categórica. Tenemos que convertir la variable **location** en una **bag of words**. Una **bag of words** se usa comúnmente en los métodos de clasificación de textos donde la (frecuencia de) aparición de cada palabra se usa como una característica para entrenar a un modelo. 

Primero uniremos el conjunto de datos de train y test para extraer los sentimientos. Dejaremos al margen de esta union la variable a predecir.

```{r}
train_and_test <- rbind(train[, 1:3], test)
str(train_and_test,  width = 85, strict.width = "cut")
```

- Creamos un corpus lingüístico del texto contenido en la variable **location**.

```{r}
corpus_location <- Corpus(VectorSource(train_and_test$location))
corpus_location[[50]]$content
```


- Convertimos los textos a minúsculas.

```{r warning=FALSE}
corpus_location <- tm_map(corpus_location, tolower)
corpus_location[[50]]$content
```

- Eliminamos signos de puntuación de los textos.

```{r warning=FALSE}
corpus_location <- tm_map(corpus_location, removePunctuation)
corpus_location[[50]]$content
```

- Eliminamos los *stop words* de los textos.

```{r warning=FALSE}
corpus_location <- tm_map(corpus_location, removeWords, stopwords("english"))
corpus_location[[50]]$content
```

- *Stemming* (usando el algoritmo stemming de Porter).

```{r warning=FALSE}
corpus_location <- tm_map(corpus_location, stemDocument)
corpus_location[[50]]$content
```

- Creamos una matriz de términos. 

Una matriz de términos es una matriz matemática que describe la frecuencia de los términos (columnas) que ocurren en un conjunto de textos (filas).

```{r}
dtm_location <- DocumentTermMatrix(corpus_location)
dtm_location
```
La matriz contiene 3839 términos. Pero la mayoría de los elementos de la matriz son cero, ya que el valor *Sparsity* es 100%. 

- Reduciremos la *Sparsity* conservando sólo los términos que aparecen al menos un 0.25% en las instancias.

```{r}
dtm_location <- removeSparseTerms(dtm_location, 0.9975)
dtm_location
```
La *Sparsity* se ha reducido al 99%. Como resultado, el número de términos a bajado a 55.

- Convertimos la matriz de términos en un data frame.

```{r}
bag_of_words_location <- as.data.frame(as.matrix(dtm_location))
```

Finalmente nos aseguraremos que el data frame contiene columnas válidas, que no se repiten, y les añadiremos "_location" para evitar duplicaciones con la **bag of words** que tendremos que crear para la variable **text**.

```{r}
colnames(bag_of_words_location) <- paste0(colnames(bag_of_words_location), "_location")
bag_of_words_location <- bag_of_words_location[, !duplicated(colnames(bag_of_words_location))]
str(bag_of_words_location, list.len=10)
```

- Examinemos los valores únicos de la variable **text**.

```{r}
length(unique(train$text))
length(unique(test$text))
```
Vemos que los valores únicos no son los mismos en los conjuntos de datos de train y test. Hacemos lo mismo que con la variable **location**.

- Creamos un corpus lingüístico del texto contenido en la variable **text**.

```{r}
corpus_text <- Corpus(VectorSource(train_and_test$text))
corpus_text[[50]]$content
```

- Convertimos los textos a minúsculas.

```{r warning=FALSE}
corpus_text <- tm_map(corpus_text, tolower)
corpus_text[[50]]$content
```

- Eliminamos signos de puntuación de los textos.

```{r warning=FALSE}
corpus_text <- tm_map(corpus_text, removePunctuation)
corpus_text[[50]]$content
```

- Eliminamos los *stop words* de los textos.

```{r warning=FALSE}
corpus_text <- tm_map(corpus_text, removeWords, stopwords("english"))
corpus_text[[50]]$content
```

- *Stemming* (usando el algoritmo stemming de Porter).

```{r warning=FALSE}
corpus_text <- tm_map(corpus_text, stemDocument)
corpus_text[[50]]$content
```

- Creamos una matriz de términos. 

Una matriz de términos es una matriz matemática que describe la frecuencia de los términos (columnas) que ocurren en un conjunto de textos (filas).

```{r}
dtm_text <- DocumentTermMatrix(corpus_text)
dtm_text
```

La matriz contiene 24938 términos. Pero la mayoría de los elementos de la matriz son cero, ya que el valor *Sparsity* es 100%. 

- Reduciremos la *Sparsity* conservando sólo los términos que aparecen al menos un 0.25% en las instancias.

```{r}
dtm_text <- removeSparseTerms(dtm_text, 0.9975)
dtm_text
```

La *Sparsity* se ha reducido al 99%. Como resultado, el número de términos a bajado a 720.

- Convertimos la matriz de términos en un data frame.

```{r}
bag_of_words_text <- as.data.frame(as.matrix(dtm_text))
```

Finalmente nos aseguraremos que el data frame contiene columnas válidas, que no se repiten, y les añadiremos "_text" para evitar duplicaciones con la **bag of words** de **location**.

```{r}
colnames(bag_of_words_text) <- paste0(colnames(bag_of_words_text), "_test")
bag_of_words_text <- bag_of_words_text[, !duplicated(colnames(bag_of_words_text))]
str(bag_of_words_text, list.len=10)
```

Jutamos *bag_of_words_location* con *bag_of_words_text* y separamos los datos en un nuevo conjunto de datos de train y test.

```{r}
bag_of_words <- cbind(bag_of_words_location, bag_of_words_text)

train_processed <- bag_of_words[1:7613, ] # filas obtenidas por train
test_processed <- bag_of_words[7614:10876, ] # filas obtenidas por test
```

Añadimos *keyword* y *target* los nuevos conjuntos *train_processed* y *test_processed*.

```{r}
train_processed$keyword <- train$keyword
train_processed$target <- train$target
test_processed$keyword <- test$keyword
test_processed$target <- test$target
```

## Modelos de clasificación

## Métrica de evaluación

## Selección de variables

## Predicción

## Comparativa entre modelos

## Conclusiones

## Bibliografía
