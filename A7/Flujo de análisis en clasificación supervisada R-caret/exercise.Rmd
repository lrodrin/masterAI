---
title: "Flujo de análisis en clasificación supervisada"
author: "Laura Rodríguez Navas"
date: "Septiembre 2020"
output:
  html_document: default
  pdf_document: 
    toc: yes
    fig_caption: yes
    fig_crop: no
    keep_tex: yes
    number_sections: yes
subtitle: Métodos supervisados
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Comenzamos cargando los paquetes necesarios.

```{r message=FALSE}
library(caret)
library(mlbench)
library(tidyverse)
library(tm)
library(SnowballC)
```

## Descripción

El dataset escogido para realizar el ejercicio propuesto se puede encontrar en (https://www.kaggle.com/c/nlp-getting-started/data). Este dataset, con 10.876 instancias, contiene 4 variables explicativas; id, keyword, location y test; y dos valores en la variable clase target (0 y 1). La variable clase es binaria, así que, vamos a aprender un modelo de clasificación binaria.

El objetivo del modelo será predecir si dado un tweet, este tweet trata sobre un desastre real o no. Si un tweet trata sobre un desastre real, se predice un 1. Si no, se predice un 0. 

La partición inicial train-test, no se tiene que realizar, ya que las instancias de train y test ya vienen definidas en los ficheros *train.csv* y *test.csv*, proporcionados por la competición en [Kaggle](https://www.kaggle.com/c/nlp-getting-started/overview) que se ha elegido. El conjunto de datos de train contiene 7613 instancias y el conjunto de datos de test contiene 3262 instancias.

Cargamos el dataset:

```{r}
train <- read.csv("train.csv", na.strings=c("","NA"))
dim(train)
test <- read.csv("test.csv", na.strings=c("","NA"))
dim(test)
```

Cada instancia en el conjunto de train y test contiene la siguiente información:

- **id**: un identificador único para cada tweet. 
- **keyword**: una palabra clave del tweet (puede estar en blanco).
- **location**: la ubicación desde la que se envió el tweet (puede estar en blanco).
- **text**: el texto del tweet. 
- **target**: solo en el conjunto de datos de train porqué es la variable clase a predecir. Indica si un tweet es sobre un desastre real (1) o no (0). 

```{r}
str(train, width = 85, strict.width = "cut")
str(test, width = 85, strict.width = "cut")
```

## Gráficas de visualización

## Preprocesamiento

## Modelos de clasificación

## Métrica de evaluación

## Selección de variables

## Predicción

## Comparativa entre modelos

## Bibliografía



Factorización de la variable clase, que inicialmente es de tipo entero.

```{r}
str(train$target)
train$target <- as.factor(train$target)
str(train$target)
```

Distribución de la variable clase:

```{r fig.align='center'}
ggplot(train, aes(x=target)) + 
  geom_bar(aes(fill=target))

sum(train$target == "0") / dim(train)[1] * 100
sum(train$target == "1") / dim(train)[1] * 100
```

La distribución de la variable a predecir está relativamente equilibrada, donde el 57% de las instancias de los tweets son sobre un desastre no real y el 43% sobre un desastre real.

[//]: # (método de resampling)

### correlaciones entre variables explicativas

### mética de evaluación

### valores perdidos

```{r}
colSums(sapply(train, is.na))
colSums(sapply(test, is.na))
```

Las variables *keyword* y *location* tienen valores perdidos. Sobretodo hay una gran cantidad de tweets, para los cuales falta la ubicación. Potencialmente, esto podría ser una buena variable predictiva en sí misma. No faltan valores en las variables *target* y *text*.

Nos ocuparemos de los valores perdidos más adelante. 

Eliminamos la variable *id*.

```{r}
train$id <- NULL
test$id <- NULL
```

## keyword

```{r}
length(unique(train$keyword))
length(unique(test$keyword))
train$keyword <- as.factor(train$keyword)
all.equal(levels(train$keyword), levels(test$keyword))
```

## location

```{r}
length(unique(train$location))
length(unique(test$location))
train_and_test <- rbind(train[, 1:3], test)
str(train_and_test)
```

1. Create a corpus
2. Convert to lowercase
3. Remove punctuation
4. Remove stopwords
5. Stemming (using Porter’s stemming algorithm)
6. Create document term matrix

```{r warning=FALSE}
corpus_location <- Corpus(VectorSource(train_and_test$location))
corpus_location[[33]]$content

corpus_location <- tm_map(corpus_location, tolower)
corpus_location[[33]]$content

corpus_location <- tm_map(corpus_location, removePunctuation)
corpus_location[[33]]$content

corpus_location <- tm_map(corpus_location, removeWords, stopwords("english"))
corpus_location[[33]]$content
 
corpus_location <- tm_map(corpus_location, stemDocument)
corpus_location[[33]]$content
```

- Create document term matrix
- Reduce sparsity
- Convert to data frame

```{r}
dtm_location <- DocumentTermMatrix(corpus_location)
dtm_location

dtm_location <- removeSparseTerms(dtm_location, 0.9975)
dtm_location

bag_of_words_location <- as.data.frame(as.matrix(dtm_location))
colnames(bag_of_words_location) <- paste0(colnames(bag_of_words_location), "_location")
str(bag_of_words_location, list.len=10)
```


## text
