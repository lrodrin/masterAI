\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdftitle={Flujo de análisis en clasificación supervisada},
            pdfauthor={Laura Rodríguez Navas},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{tcolorbox}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother

\title{Flujo de análisis en clasificación supervisada}
\providecommand{\subtitle}[1]{}
\subtitle{Métodos supervisados}
\author{Laura Rodríguez Navas}
\date{Septiembre 2020}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{3}
\renewcommand{\contentsname}{Contenido}
\tableofcontents
}
\newpage

Empezamos por cargar a nuestro espacio de trabajo los paquetes que
usaremos:

\begin{itemize}
\tightlist
\item
  \textbf{tidyverse}, engloba otros paquetes (\textbf{dplyr},
  \textbf{tidyr}, \textbf{ggplot}, etc.) que facilitan en gran medida el
  análisis exploratorio de los datos.
\item
  \textbf{tm}, específico para minería de textos.
\item
  \textbf{irlba}, específico para la \emph{Descomposición de Valores
  Singulares (SVD)} de matrices muy grandes.
\item
  \textbf{caret}, para realizar tareas de clasificación y regresión.
\item
  \textbf{doParallel}, proporciona computación paralela.
\item
  \textbf{syuzhet}, específico para la extracción de sentimientos (información subjetiva) de
  textos.
\item
  \textbf{ggcorrplot}, muestra visualizaciones gráficas de matrices de
  correlación usando \textbf{ggplot2}.
\end{itemize}

\vspace{3mm}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(tm)}
\KeywordTok{library}\NormalTok{(irlba)}
\KeywordTok{library}\NormalTok{(caret)}
\KeywordTok{library}\NormalTok{(doParallel)}
\KeywordTok{library}\NormalTok{(syuzhet)}
\KeywordTok{library}\NormalTok{(ggcorrplot)}
\end{Highlighting}
\end{Shaded}

\hypertarget{anuxe1lisis-exploratorio-de-los-datos}{%
\section{Análisis exploratorio de los
datos}\label{anuxe1lisis-exploratorio-de-los-datos}}

Antes de entrenar un modelo predictivo, o incluso antes de realizar
cualquier cálculo con un nuevo conjunto de datos, es muy importante
realizar una exploración descriptiva de los datos. Este proceso nos
permite entender mejor que información contienen cada variable, detectar
posibles errores, etc. además, puede dar pistas sobre qué variables no
son adecuadas para predecir un modelo.

Acorde a la realización del ejercicio propuesto se ha elegido la
competición en Kaggle: \emph{Real or Not? NLP with Disaster Tweets}.
El dataset de la competición se puede encontrar en el siguiente \href{https://www.kaggle.com/c/nlp-getting-started/data}{\color{blue}{enlace}}. Este dataset,
con 10.876 instancias, contiene 4 variables explicativas: \textbf{id},
\textbf{keyword}, \textbf{location} y \textbf{text}, y dos valores en la
variable clase \textbf{target} (0 y 1). Como observaremos la
variable clase es binaria, así que, durante este ejercicio vamos a
aprender un modelo de \emph{clasificación binaria}. El objetivo de este
modelo será predecir si dado un tweet, éste trata sobre un desastre real
o no. Si un tweet trata sobre un desastre real, se predice un 1. Si no,
se predice un 0.

\begin{tcolorbox}
La clasificación binaria es un tipo de clasificación en el que tan
solo se pueden asignar dos clases diferentes (0 o 1).	
\end{tcolorbox}

La métrica de evaluación esperada por la competición es \textbf{F1
score}. 

Se calcula de la siguiente manera:

\begin{center}
	F1 = 2 * $\dfrac{precision * recall}{precision + recall}$
\end{center}

donde:

\begin{center}	
	precision = $\dfrac{TP}{TP + FP}$
	
	recall = $\dfrac{TP}{TP + FN}$
\end{center}

\begin{itemize}
	\item True Positive (TP)
	\item False Positive (FP)
	\item False Negative (FN)
\end{itemize}

La partición inicial train-test, no se tiene que realizar, ya que las
instancias de train y test ya vienen definidas en el dataset de la
competición (descargar a nuestro espacio de trabajo los ficheros
\textbf{train.csv} y \textbf{test.csv} de
\url{https://www.kaggle.com/c/nlp-getting-started/data}).

Cargamos a nuestro espacio de trabajo los conjuntos de datos de train y
test descargados, re-nombrando los valores perdidos como \textbf{NA} para
que los podamos tratar más adelante. También mostramos las dimensiones
de los conjuntos de datos usando la función \textbf{dim}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"train.csv"}\NormalTok{, }\DataTypeTok{na.strings=}\KeywordTok{c}\NormalTok{(}\StringTok{""}\NormalTok{, }\StringTok{"NA"}\NormalTok{))}
\NormalTok{test <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"test.csv"}\NormalTok{, }\DataTypeTok{na.strings=}\KeywordTok{c}\NormalTok{(}\StringTok{""}\NormalTok{, }\StringTok{"NA"}\NormalTok{))}
\KeywordTok{dim}\NormalTok{(train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7613    5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3263    4
\end{verbatim}

Vemos que el conjunto de datos de train contiene 7613 instancias y el
conjunto de datos de test contiene 3263 instancias. Cada instancia
contiene las siguientes variables:

\begin{itemize}
\tightlist
\item
  \textbf{id}: un identificador único para cada tweet.
\item
  \textbf{keyword}: una palabra clave del tweet.
\item
  \textbf{location}: la ubicación desde la que se envió el tweet.
\item
  \textbf{text}: el texto del tweet.
\item
  \textbf{target}: solo en el conjunto de datos de train porqué es la
  variable clase a predecir. Indica si un tweet corresponde a un
  desastre real (1) o no (0).
\end{itemize}

\begin{verbatim}
## 'data.frame':    7613 obs. of  5 variables:
##  $ id      : int  1 4 5 6 7 8 10 13 14 15 ...
##  $ keyword : chr  NA NA NA NA ...
##  $ location: chr  NA NA NA NA ...
##  $ text    : chr  "Our Deeds are the Reason of this #earthquake May ALLAH Forgive "..
##  $ target  : int  1 1 1 1 1 1 1 1 1 1 ...
\end{verbatim}

\begin{verbatim}
## 'data.frame':    3263 obs. of  4 variables:
##  $ id      : int  0 2 3 9 11 12 21 22 27 29 ...
##  $ keyword : chr  NA NA NA NA ...
##  $ location: chr  NA NA NA NA ...
##  $ text    : chr  "Just happened a terrible car crash" "Heard about #earthquake is"..
\end{verbatim}

\hypertarget{variable-target}{%
\subsection{\texorpdfstring{Variable
\emph{target}}{Variable target}}\label{variable-target}}

Como ya hemos comentado, la variable \textbf{target} es la variable a
predecir. Es de tipo cuantitativa (de tipo entero) y conviene
convertirla a variable cualitativa, almacenarla con el tipo
\emph{factor}. Para evitar errores, se recodifica para que sus dos
posibles valores sean ``Yes''-``No'' y se convierte a \emph{factor}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train}\OperatorTok{$}\NormalTok{target <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(}\KeywordTok{ifelse}\NormalTok{(train}\OperatorTok{$}\NormalTok{target }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{, }\StringTok{"No"}\NormalTok{, }\StringTok{"Yes"}\NormalTok{))}
\KeywordTok{ggplot}\NormalTok{(train, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{target)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill=}\NormalTok{target))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{document_files/figure-latex/unnamed-chunk-4-1} \end{center}

Cuando se crea un modelo, es muy importante estudiar la distribución de
la variable clase, ya que, a fin de cuentas, es lo que nos interesa
predecir.

Gráficamente observamos que la distribución de la variable a predecir no
está muy sesgada y está relativamente equilibrada. Hay menos tweets que
se refieren a desastres reales. Además, parece que no presenta un
problema notable de \emph{desbalanceo de clase}, porqué contamos con
muchas observaciones del caso minoritario.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(train}\OperatorTok{$}\NormalTok{target }\OperatorTok{==}\StringTok{ "Yes"}\NormalTok{) }\OperatorTok{/}\StringTok{ }\KeywordTok{dim}\NormalTok{(train)[}\DecValTok{1}\NormalTok{] }\OperatorTok{*}\StringTok{ }\DecValTok{100}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 42.96598
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(train}\OperatorTok{$}\NormalTok{target }\OperatorTok{==}\StringTok{ "No"}\NormalTok{) }\OperatorTok{/}\StringTok{ }\KeywordTok{dim}\NormalTok{(train)[}\DecValTok{1}\NormalTok{] }\OperatorTok{*}\StringTok{ }\DecValTok{100}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 57.03402
\end{verbatim}

Para que un modelo predictivo nos sea útil tendremos que intentar
superar el porcentaje mínimo dado que aproximadamente el 57\% de los
tweets no representan un desastre real (este porcentaje se recalculará
únicamente con el conjunto de datos de train).

Como el objetivo del ejercicio es predecir que tweets pertenecen o no a
un desastre real, el análisis que haremos a continuación se hace realiza
de cada variable explicativa con relación a la variable a predecir
\textbf{target}. Analizando de esta forma, se pueden extraer ideas sobre
que variables están más relacionadas con los desastres reales.

\hypertarget{variable-keyword}{%
\subsection{\texorpdfstring{Variable
\emph{keyword}}{Variable keyword}}\label{variable-keyword}}

La variable explicativa \textbf{keyword} representa una palabra clave en
cada tweet. Vemos las 10 primeras del conjunto de datos de train.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(keyword) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unique}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 keyword
## 1                  <NA>
## 32               ablaze
## 68             accident
## 103          aftershock
## 137 airplane%20accident
## 172           ambulance
## 210         annihilated
## 244        annihilation
## 273          apocalypse
## 305          armageddon
\end{verbatim}

Nuestro interés en la variable \textbf{keyword} dentro del análisis
exploratorio de los datos es ver si existen correlaciones entre esta y
la variable a predecir \textbf{target}. Para ello, y como estamos
delante un ejercicio de \emph{Procesamiento del Lenguaje Natural}
realizaremos un análisis de sentimientos.

\emph{El análisis de sentimientos es una técnica de
\href{https://en.wikipedia.org/wiki/Machine_learning}{Machine Learning},
basada en el
\href{https://www.kdnuggets.com/2017/02/natural-language-processing-key-terms-explained.html}{Procesado
del Lenguaje Natural}, que pretende obtener información subjetiva de una
serie de textos. Su aplicación es este caso, consiste en resolver si un
tweet es real o no en relación a un desastre.}

En el análisis de sentimientos usamos los paquetes de R:
\textbf{syuzhet}, \textbf{ggcorrplot} y \textbf{doParallel}.

\begin{itemize}
\tightlist
\item
  El paquete \textbf{syuzhet} cuenta con la función
  \textbf{get\_nrc\_sentiment} que calculará la presencia de los
  diferentes sentimientos dado un conjunto de palabras clave. Los
  argumentos de esta función son:

  \begin{itemize}
  \tightlist
  \item
    \textbf{char\_v}. Un vector de caracteres que en este caso contendrá
    todas las palabras clave.
  \item
    \textbf{language}. Define el lenguaje. Como los tweets están en
    inglés, el lenguaje será el inglés.
  \item
    \textbf{cl}. Para el análisis en paralelo. Es opcional, pero en este
    caso lo usaremos porqué hay muchas palabras clave.
  \end{itemize}
\item
  El paquete \textbf{doParallel} cuenta con las funciones:

  \begin{itemize}
  \tightlist
  \item
    \textbf{makePSOCKcluster}. Crea un clúster de sockets paralelos.
  \item
    \textbf{registerDoParallel}. Registra el número de \emph{cores} que
    usará el clúster creado.
  \item
    \textbf{stopCluster}. Detiene la computación paralela.
  \end{itemize}
\end{itemize}

La computación paralela la usaremos en muchas de las ejecuciones de este
ejercicio ya que nos encontramos delante de un problema de \emph{alta
dimensionalidad}. Eso es, que la dimensionalidad de nuestros datos es
muy elevada y puede reducir drásticamente la eficiencia de los
algoritmos de clasificación supervisada que entrenaremos.

La reducción de la dimensionalidad que aplicaremos en este ejercicio se
realiza más adelante y se calculará teniendo en cuenta las palabras más
frecuentes de los tweets en conjunto de datos.

El análisis de sentimientos de cada palabra clave, usando la función
\textbf{get\_nrc\_sentiment}, consiste en extraer los sentimientos de
cada palabra clave, guardarlos en un nuevo conjunto de datos
(\emph{emotion.df}), con el que calcularemos (paquete \textbf{cor}) y
visualizaremos la matriz de correlaciones (paquete \textbf{ggcorrplot})
entre las palabras clave con relación a la variable a predecir. Es
importante volver a transformar la variable a predecir para realizar los
cálculos, cuando la variable es cualitativa.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cl <-}\StringTok{ }\KeywordTok{makePSOCKcluster}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DataTypeTok{setup_strategy=}\StringTok{"sequential"}\NormalTok{)}
\KeywordTok{registerDoParallel}\NormalTok{(cl)}

\NormalTok{emotion.df <-}\StringTok{ }\KeywordTok{get_nrc_sentiment}\NormalTok{(}\DataTypeTok{char_v =} \KeywordTok{gsub}\NormalTok{(}\StringTok{"_"}\NormalTok{, }\StringTok{" "}\NormalTok{, train}\OperatorTok{$}\NormalTok{keyword), }
                                \DataTypeTok{language =} \StringTok{"english"}\NormalTok{, }\DataTypeTok{cl=}\NormalTok{cl)}

\NormalTok{emotion.df <-}\StringTok{ }\NormalTok{emotion.df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{target =}\NormalTok{ train}\OperatorTok{$}\NormalTok{target)}

\NormalTok{emotion.df}\OperatorTok{$}\NormalTok{target <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(emotion.df}\OperatorTok{$}\NormalTok{target)}

\KeywordTok{cor}\NormalTok{(emotion.df) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggcorrplot}\NormalTok{(}\DataTypeTok{lab =} \OtherTok{TRUE}\NormalTok{, }
             \DataTypeTok{title =} \StringTok{"Matriz de correlación entre }\CharTok{\textbackslash{}n}\StringTok{keyword y target"}\NormalTok{,}
             \DataTypeTok{legend.title =} \StringTok{"correlation"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{document_files/figure-latex/unnamed-chunk-7-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{stopCluster}\NormalTok{(cl)}
\end{Highlighting}
\end{Shaded}

Parece que, al observar la matriz de correlaciones, existe una
correlación nula entre las variables \textbf{keyword} y \textbf{target}.
Al revisarlo con mayor detalle, podemos observar que la mayoría de las
palabras clave no tienen un sentimiento positivo asociado. Las palabras
clave asociadas a un sentimiento se asocian negativamente (miedo o
tristeza), lo cual es bastante consistente con el problema, ya que
intentemos predecir el desastre.

Acorde a nuestro criterio esta variable explicativa no es buena para
hacer una predicción ya que no está realmente asociada con la variable a
predecir. Así que la excluiremos del procesamiento de texto.

\hypertarget{variable-location}{%
\subsection{\texorpdfstring{Variable
\emph{location}}{Variable location}}\label{variable-location}}

La variable explicativa \textbf{location} representa las ubicaciones
desde donde se generaron los tweets. Vemos las 10 primeras y el número
total de ubicaciones diferentes del conjunto de datos de train (3342
ubicaciones).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(location) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unique}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                         location
## 1                           <NA>
## 32                    Birmingham
## 33 Est. September 2012 - Bristol
## 34                        AFRICA
## 35              Philadelphia, PA
## 36                    London, UK
## 37                      Pretoria
## 38                  World Wide!!
## 40                Paranaque City
## 41                Live On Webcam
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{count}\NormalTok{(train }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(location) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unique}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      n
## 1 3342
\end{verbatim}

A continuación, veremos las ubicaciones que se repiten más de 10 veces
en el conjunto de datos de train.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{location.freq <-}\StringTok{ }\KeywordTok{table}\NormalTok{(}\KeywordTok{unlist}\NormalTok{(train }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(location)))}
\NormalTok{location.freq[}\KeywordTok{which}\NormalTok{(location.freq }\OperatorTok{>}\StringTok{ }\DecValTok{10}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##         Australia        California   California, USA            Canada 
##                18                17                15                29 
##           Chicago       Chicago, IL             Earth        Everywhere 
##                11                18                11                15 
##           Florida             India         Indonesia           Ireland 
##                14                24                13                12 
##             Kenya            London       Los Angeles   Los Angeles, CA 
##                20                45                13                26 
##            Mumbai          New York      New York, NY           Nigeria 
##                22                71                15                28 
##               NYC     San Francisco San Francisco, CA           Seattle 
##                12                14                11                11 
##           Toronto                UK    United Kingdom     United States 
##                12                27                14                50 
##               USA  Washington, D.C.    Washington, DC         Worldwide 
##               104                13                21                19
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{barplot}\NormalTok{(location.freq[}\KeywordTok{which}\NormalTok{(location.freq}\OperatorTok{>}\DecValTok{10}\NormalTok{)], }\DataTypeTok{las =} \DecValTok{2}\NormalTok{,  }
        \DataTypeTok{ylab =} \StringTok{"frequency"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{document_files/figure-latex/unnamed-chunk-9-1} \end{center}

En el total de ubicaciones, 3342, la mayoría de ellas cuenta con menos
de 10 observaciones. Acorde a nuestro criterio esta variable explicativa
no es buena para hacer una predicción, ya que la variable tiene muy
pocas observaciones, y puede ocurrir que, durante la validación cruzada
o \emph{bootstrapping}, algunas de las particiones no contengan ninguna
observación de dicha variable, lo que puede dar lugar a errores.

\emph{Una muestra bootstrap es una muestra obtenida a partir de la
muestra original por muestreo aleatorio con reposición, y del mismo
tamaño que la muestra original. Muestreo aleatorio con reposición
(resampling with replacement) significa que, después de que una
observación sea extraída, se vuelve a poner a disposición para las
siguientes extracciones. Como resultado de este tipo de muestreo,
algunas observaciones aparecerán múltiples veces en la muestra bootstrap
y otras ninguna.}

\hypertarget{variable-id}{%
\subsection{\texorpdfstring{Variable
\emph{id}}{Variable id}}\label{variable-id}}

La variable \textbf{id} es solo un identificador único, así que, no la
analizaremos y procederemos a eliminarla de los conjuntos de datos de
train y test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train}\OperatorTok{$}\NormalTok{id <-}\StringTok{ }\OtherTok{NULL}
\NormalTok{test}\OperatorTok{$}\NormalTok{id <-}\StringTok{ }\OtherTok{NULL}
\end{Highlighting}
\end{Shaded}

\hypertarget{conclusiuxf3n-anuxe1lisis-exploratorio}{%
\subsection{Conclusión análisis
exploratorio}\label{conclusiuxf3n-anuxe1lisis-exploratorio}}

Llegados a este punto, parece que nuestro criterio en la exploración de
los datos, el estudio de su distribución y sus posibles relaciones con
la variable a predecir nos indica que las variables explicativas
\textbf{keyword}, \textbf{location} y \textbf{id} no son buenas para
hacer una predicción, así que nos centraremos en la variable
\textbf{text} para hacer la predicción.

\hypertarget{procesamiento-de-texto}{%
\section{Procesamiento de texto}\label{procesamiento-de-texto}}

Combinamos los conjuntos de datos de train y test para ahorrar esfuerzos
en el preprocesado de datos. Para ello, usamos la función
\textbf{bind\_rows}, que nos permitirá enlazar de forma eficiente los
conjuntos de datos por fila y columna. Podremos comprobar que la
combinación se hace correctamente, sumando los elementos de train (7613)
y de test (3263), el nuevo conjunto de datos (\textbf{complete\_df})
tendrá 10876 observaciones, 3 variables explicativas (\textbf{keyword},
\textbf{location}, \textbf{text}) y la variable de clase
\textbf{target}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{complete_df <-}\StringTok{ }\KeywordTok{bind_rows}\NormalTok{(train, test)}
\KeywordTok{str}\NormalTok{(complete_df, }\DataTypeTok{width =} \DecValTok{85}\NormalTok{, }\DataTypeTok{strict.width =} \StringTok{"cut"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    10876 obs. of  4 variables:
##  $ keyword : chr  NA NA NA NA ...
##  $ location: chr  NA NA NA NA ...
##  $ text    : chr  "Our Deeds are the Reason of this #earthquake May ALLAH Forgive "..
##  $ target  : Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2 ...
\end{verbatim}

El preprocesado de datos englobará las transformaciones de los textos,
como, por ejemplo, la imputación de valores ausentes o la reducción de
dimensionalidad.

Primero, miramos cuantos valores perdidos tiene nuestro conjunto de
datos \textbf{complete\_df}. La función \textbf{colSums} sumará los
valores que la función \textbf{sapply} encuentre, en este caso, los
valores perdidos.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{colSums}\NormalTok{(}\KeywordTok{sapply}\NormalTok{(complete_df, is.na))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  keyword location     text   target 
##       87     3638        0     3263
\end{verbatim}

Identificamos que las variables explicativas \textbf{keyword} y
\textbf{location} tienen valores perdidos. La variable explicativa
\textbf{text} no tiene valores perdidos. Sobretodo hay una gran cantidad
de tweets, para los cuales falta su ubicación. Los 3263 valores perdidos
de la variable a predecir provienen del conjunto de datos de test. Nos
ocuparemos de los valores perdidos más adelante.

\hypertarget{corpus}{%
\subsection{Corpus}\label{corpus}}

Con nuestro nuevo conjunto de datos preparado (\textbf{complete\_df}),
procedemos a crear nuestro Corpus, es decir, el conjunto de textos de la
variable \textbf{text} a analizar. En este caso, nuestro Corpus se
compone de todos los textos de los tweets y los asignaremos al objeto
\emph{myCorpus} usando las funciones \textbf{VectorSource} y
\textbf{Corpus}. La función \textbf{Corpus} creará el corpus a partir de
un vector de textos. La función \textbf{VectorSource} interpretará cada
mensaje de texto de los tweets como un elemento de ese vector de textos.

\emph{Un corpus lingüístico se define como ``un conjunto de textos de un
mismo origen'' y que tiene por función recopilar un conjunto de textos.
El uso de un corpus lingüístico nos permitirá obtener información de las
palabras utilizadas con más o menor frecuencia.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myCorpus <-}\StringTok{ }\KeywordTok{Corpus}\NormalTok{(}\KeywordTok{VectorSource}\NormalTok{(complete_df}\OperatorTok{$}\NormalTok{text))}
\NormalTok{myCorpus}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## <<SimpleCorpus>>
## Metadata:  corpus specific: 1, document level (indexed): 0
## Content:  documents: 10876
\end{verbatim}

Como podemos ver, nuestro Corpus está compuesto por 10876 textos.

\hypertarget{limpieza-del-texto}{%
\subsection{Limpieza del texto}\label{limpieza-del-texto}}

Necesitamos limpiar de los 10876 textos caracteres que son de poca
utilidad. Empezamos por aseguramos de que no queden enlaces, con un poco
de ayuda de las \emph{regular expressions}. Para ello usaremos las
funciones \textbf{gsub} y \textbf{tm\_map}. La función \textbf{gsub}
buscará y reemplazará desde la primera hasta la última de las
coincidencias de un patrón (representado por una \emph{regular
expression}). La función \textbf{tm\_map} será la encargada de aplicar
las diferentes transformaciones de los textos a nuestro corpus.

\emph{Una expresión regular (o en inglés regular expression) es una
representación, según unas reglas sintácticas de un lenguaje formal, de
una porción de texto genérico a buscar dentro de otro texto, como por
ejemplo caracteres, palabras o patrones de texto concretos.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{removeURL <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{gsub}\NormalTok{(}\StringTok{"http[^[:space:]]*"}\NormalTok{, }\StringTok{""}\NormalTok{, x)  }
\NormalTok{myCorpus <-}\StringTok{ }\KeywordTok{tm_map}\NormalTok{(myCorpus, }\KeywordTok{content_transformer}\NormalTok{(removeURL))}
\end{Highlighting}
\end{Shaded}

Convertimos todo a minúsculas.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myCorpus <-}\StringTok{ }\KeywordTok{tm_map}\NormalTok{(myCorpus, }\KeywordTok{content_transformer}\NormalTok{(tolower))}
\end{Highlighting}
\end{Shaded}

Eliminamos los nombres de usuario.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{removeUsername <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{gsub}\NormalTok{(}\StringTok{"@[^[:space:]]*"}\NormalTok{, }\StringTok{""}\NormalTok{, x)  }
\NormalTok{myCorpus <-}\StringTok{ }\KeywordTok{tm_map}\NormalTok{(myCorpus, }\KeywordTok{content_transformer}\NormalTok{(removeUsername))}
\end{Highlighting}
\end{Shaded}

Nos deshacemos de la puntuación, puesto que por ejemplo ``fin'' y
``fin.'' son identificadas como palabras diferentes, lo cual no
deseamos.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{removeNumPunct <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{gsub}\NormalTok{(}\StringTok{"[^[:alpha:][:space:]]*"}\NormalTok{, }\StringTok{""}\NormalTok{, x)   }
\NormalTok{myCorpus <-}\StringTok{ }\KeywordTok{tm_map}\NormalTok{(myCorpus, }\KeywordTok{content_transformer}\NormalTok{(removeNumPunct))}
\end{Highlighting}
\end{Shaded}

Usamos \textbf{removeWords} con \textbf{stopwords(``english'')},
recordemos que los textos de los tweets están en inglés y cada idioma
tiene sus propias palabras vacías; para eliminar palabras vacías, es
decir, aquellas con poco valor para el análisis, que carecen de un
significado por si solas, tales como artículos, preposiciones,
conjunciones, pronombres, etc.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myStopWords <-}\StringTok{ }\KeywordTok{c}\NormalTok{((}\KeywordTok{stopwords}\NormalTok{(}\StringTok{'english'}\NormalTok{)), }
    \KeywordTok{c}\NormalTok{(}\StringTok{"really"}\NormalTok{, }\StringTok{"tweets"}\NormalTok{, }\StringTok{"saw"}\NormalTok{, }\StringTok{"just"}\NormalTok{, }\StringTok{"feel"}\NormalTok{, }\StringTok{"may"}\NormalTok{, }\StringTok{"us"}\NormalTok{, }\StringTok{"rt"}\NormalTok{, }\StringTok{"every"}\NormalTok{, }\StringTok{"one"}\NormalTok{,}
     \StringTok{"amp"}\NormalTok{, }\StringTok{"like"}\NormalTok{, }\StringTok{"will"}\NormalTok{, }\StringTok{"got"}\NormalTok{, }\StringTok{"new"}\NormalTok{, }\StringTok{"can"}\NormalTok{, }\StringTok{"still"}\NormalTok{, }\StringTok{"back"}\NormalTok{, }\StringTok{"top"}\NormalTok{, }\StringTok{"much"}\NormalTok{,}
     \StringTok{"near"}\NormalTok{, }\StringTok{"im"}\NormalTok{, }\StringTok{"see"}\NormalTok{, }\StringTok{"via"}\NormalTok{, }\StringTok{"get"}\NormalTok{, }\StringTok{"now"}\NormalTok{, }\StringTok{"come"}\NormalTok{, }\StringTok{"oil"}\NormalTok{, }\StringTok{"let"}\NormalTok{, }\StringTok{"god"}\NormalTok{, }\StringTok{"want"}\NormalTok{,}
     \StringTok{"pm"}\NormalTok{, }\StringTok{"last"}\NormalTok{, }\StringTok{"hope"}\NormalTok{, }\StringTok{"since"}\NormalTok{, }\StringTok{"everyone"}\NormalTok{, }\StringTok{"food"}\NormalTok{, }\StringTok{"content"}\NormalTok{, }\StringTok{"always"}\NormalTok{, }\StringTok{"th"}\NormalTok{,}
     \StringTok{"full"}\NormalTok{, }\StringTok{"found"}\NormalTok{, }\StringTok{"dont"}\NormalTok{, }\StringTok{"look"}\NormalTok{, }\StringTok{"cant"}\NormalTok{, }\StringTok{"mh"}\NormalTok{, }\StringTok{"lol"}\NormalTok{, }\StringTok{"set"}\NormalTok{, }\StringTok{"old"}\NormalTok{, }\StringTok{"service"}\NormalTok{,}
     \StringTok{"city"}\NormalTok{, }\StringTok{"home"}\NormalTok{, }\StringTok{"live"}\NormalTok{, }\StringTok{"night"}\NormalTok{, }\StringTok{"news"}\NormalTok{, }\StringTok{"say"}\NormalTok{, }\StringTok{"video"}\NormalTok{, }\StringTok{"people"}\NormalTok{, }\StringTok{"ill"}\NormalTok{, }
     \StringTok{"way"}\NormalTok{,  }\StringTok{"please"}\NormalTok{, }\StringTok{"years"}\NormalTok{, }\StringTok{"take"}\NormalTok{, }\StringTok{"homes"}\NormalTok{, }\StringTok{"read"}\NormalTok{, }\StringTok{"man"}\NormalTok{, }\StringTok{"next"}\NormalTok{, }\StringTok{"cross"}\NormalTok{, }
     \StringTok{"boy"}\NormalTok{, }\StringTok{"bad"}\NormalTok{, }\StringTok{"ass"}\NormalTok{))}

\KeywordTok{head}\NormalTok{(myStopWords, }\DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "i"          "me"         "my"         "myself"     "we"        
##  [6] "our"        "ours"       "ourselves"  "you"        "your"      
## [11] "yours"      "yourself"   "yourselves" "he"         "him"       
## [16] "his"        "himself"    "she"        "her"        "hers"      
## [21] "herself"    "it"         "its"        "itself"     "they"      
## [26] "them"       "their"      "theirs"     "themselves" "what"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myCorpus <-}\StringTok{ }\KeywordTok{tm_map}\NormalTok{(myCorpus, removeWords, myStopWords) }
\end{Highlighting}
\end{Shaded}

Además, podemos ver que se han añadido (aleatoriamente) más palabras
vacías (``really'', ``tweets'', ``saw'', etc.). Estas palabras vacías
son de las más usadas en los mensajes de texto de los tweets (ver
\url{https://techland.time.com/2009/06/08/the-500-most-frequently-used-words-on-twitter/}).

En este caso, removemos las palabras de una sola letra.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{removeSingle <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{gsub}\NormalTok{(}\StringTok{" . "}\NormalTok{, }\StringTok{" "}\NormalTok{, x)   }
\NormalTok{myCorpus <-}\StringTok{ }\KeywordTok{tm_map}\NormalTok{(myCorpus, }\KeywordTok{content_transformer}\NormalTok{(removeSingle))}
\end{Highlighting}
\end{Shaded}

Por último eliminamos los espacios vacíos excesivos, muchos de ellos
introducidos por las transformaciones anteriores.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myCorpus <-}\StringTok{ }\KeywordTok{tm_map}\NormalTok{(myCorpus, stripWhitespace)}
\end{Highlighting}
\end{Shaded}

\hypertarget{creaciuxf3n-de-un-modelo-predictivo}{%
\section{Creación de un modelo
predictivo}\label{creaciuxf3n-de-un-modelo-predictivo}}

\hypertarget{preprocesado-de-los-datos}{%
\subsection{Preprocesado de los datos}\label{preprocesado-de-los-datos}}

Para la creación de un modelo predictivo, necesitamos construir una
\textbf{Term Document Matrix} del conjunto de textos de la variable
\textbf{text}, donde cada fila representará un texto y cada palabra
única estará representada per una columna.

\emph{Una Term Document Matrix es una matriz matemática que describe la
frecuencia con la que se repiten una serie de palabras en una colección
de documentos.}

Comenzaremos mapeando nuestro Corpus indicando que es una \textbf{Term
Document Matrix}, de esta manera podremos realizar el preprocesado de
datos. Sabemos que el preprocesado de datos engloba aquellas
transformaciones de los datos con la finalidad de mejorar los resultados
de la clasificación supervisada. Todo preprocesado de datos debe
aprenderse de las observaciones de train y luego aplicarse al conjunto
de train y de test. Esto es muy importante para no violar la condición
de que ninguna información procedente de las observaciones de test
influya en el ajuste del modelo.

Utilizaremos la función \textbf{TermDocumentMatrix} en nuestro Corpus y
asignaremos el resultado al objeto \emph{complete.tdm}. Con el parámetro
\textbf{control} indicaremos que evaluaremos todos los textos de la
matriz, con las características escogidas se evaluarán todas las
palabras de los textos. Por defecto la función
\textbf{TermDocumentMatrix} usa \emph{tf-id}, que mide la importancia
relativa de cada palabra en el conjunto de textos.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{complete.tdm <-}\StringTok{ }\KeywordTok{TermDocumentMatrix}\NormalTok{(myCorpus, }\DataTypeTok{control=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{wordLengths=} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\OtherTok{Inf}\NormalTok{)))}
\NormalTok{complete.tdm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## <<TermDocumentMatrix (terms: 16880, documents: 10876)>>
## Non-/sparse entries: 76219/183510661
## Sparsity           : 100%
## Maximal term length: 49
## Weighting          : term frequency (tf)
\end{verbatim}

Podemos observar que tenemos 16880 \emph{terms}, esto quiere decir que
tenemos 16880 palabras diferentes en nuestro Corpus. Lo cual es una
cantidad considerable de vocabulario, pero no esperaríamos otra cosa de
una red social como \href{https://twitter.com}{Twitter}. La palabra más
larga contiene 49 caracteres.

Usaremos la función \textbf{removeSparseItems} para depurar nuestra
\textbf{Term Document Matrix} de aquellas palabras que aparecen con muy
poca frecuencia, es decir, son dispersas. Porqué 16880 palabras son
demasiadas palabras y es posible que no podamos entrenar nuestro modelo
debido a restricciones computacionales.

Esta función requiere que especifiquemos el argumento \textbf{sparse},
que puede asumir valores de 0 a 1. Este valor representa la dispersión
de las palabras que queremos conservar. Si lo fijamos muy alto (cerca de
1, pero no 1), conservaremos muchas palabras, casi todas, pues estamos
indicando que queremos conservar palabras, aunque sean muy dispersas.
Naturalmente, ocurre lo opuesto si fijamos este valor muy bajo (cerca de
0, pero no 0), pudiendo incluso quedarnos sin ninguna palabra, si las
palabras en nuestros textos son dispersas en general.

En este caso, se decide fijarlo en \emph{.9975}, conservando las
palabras que aparecen en al menos el 0.25\% de las observaciones.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{complete.tdm <-}\StringTok{ }\KeywordTok{removeSparseTerms}\NormalTok{(complete.tdm, }\DataTypeTok{sparse =} \FloatTok{.9975}\NormalTok{)}
\NormalTok{complete.tdm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## <<TermDocumentMatrix (terms: 582, documents: 10876)>>
## Non-/sparse entries: 31214/6298618
## Sparsity           : 100%
## Maximal term length: 17
## Weighting          : term frequency (tf)
\end{verbatim}

De 16880 palabras que teníamos, nos hemos quedado con 582, lo cual
reduce en gran medida la dificultad y complejidad del problema de
\emph{alta dimensionalidad}, lo cual es deseable. La palabra más larga
contiene 17 caracteres.

\hypertarget{feature-extraction-mediante-singular-value-decomposition}{%
\subsubsection{Feature Extraction mediante Singular Value
Decomposition}\label{feature-extraction-mediante-singular-value-decomposition}}

La descomposición de los datos originales en un nuevo conjunto, sin
necesidad de pérdida de información relevante y sacando a la luz la
información latente, es un proceso de vital importancia para implementar
la parte más computacionalmente intensa del ejercicio. Buscando una
intuitiva separabilidad de las clases de los datos aplicaremos la
técnica de \emph{Descomposición en Valores Singulares (SVD)}.

\emph{La Descomposición de Valores Singulares (en inglés Singular Value
Decomposition ({[}SVD{]}
(\url{https://en.wikipedia.org/wiki/Singular-value_decomposition})) es
una técnica de reducción de la dimensionalidad, en minería de textos,
que puede utilizarse para descubrir las dimensiones latentes (o
componentes) que determinan similitudes semánticas entre las palabras
(es decir, unidades léxicas) o entre los textos (es decir, unidades de
contexto).}

Para aplicar la técnica de \emph{Descomposición en Valores Singulares
(SVD)}, primero transformamos nuestra \textbf{Term Document Matrix} a un
objeto de tipo \textbf{matrix} para así poder comprobar si nuestros
datos aún contienen valores perdidos con la función \textbf{which}.

\begin{verbatim}
## integer(0)
\end{verbatim}

Los datos no contienen valores perdidos, podemos proceder con la
\emph{Descomposición de Valores Singulares (SVD)}. Para ello utilizamos
la función \textbf{irlba}, que se encargará de la descomposición de
nuestra \textbf{Term Document Matrix} y extraerá sus 150 vectores
singulares más importantes, después de un máximo de 600 iteraciones, y
que guardaremos en el objeto \textbf{complete\_irlba}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cl <-}\StringTok{ }\KeywordTok{makePSOCKcluster}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DataTypeTok{setup_strategy=}\StringTok{"sequential"}\NormalTok{)}
\KeywordTok{registerDoParallel}\NormalTok{(cl)}

\NormalTok{complete_irlba <-}\StringTok{ }\KeywordTok{irlba}\NormalTok{(}\KeywordTok{t}\NormalTok{(complete.term.matrix), }\DataTypeTok{nv =} \DecValTok{150}\NormalTok{, }\DataTypeTok{maxit =} \DecValTok{600}\NormalTok{)}
\NormalTok{complete_irlba}\OperatorTok{$}\NormalTok{v[}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{, }\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                [,1]          [,2]          [,3]          [,4]          [,5]
##  [1,] -0.0003162281 -2.109638e-04 -3.318231e-04 -2.035137e-05  0.0008660149
##  [2,] -0.0431207327  1.408993e-02  5.124787e-03  3.922969e-03 -0.0021251369
##  [3,] -0.0020297768  2.205792e-04 -5.231801e-05  1.014223e-04  0.0008899277
##  [4,] -0.0054444920  1.259299e-04 -3.441743e-03  1.669137e-04  0.0094345444
##  [5,] -0.0021975777  8.533917e-05  7.910354e-05 -7.809264e-05  0.0017043646
##  [6,] -0.0449020384  1.303972e-02  1.677561e-03  3.883599e-03 -0.0005116573
##  [7,] -0.0060579030 -8.521515e-03 -3.239198e-02  6.490016e-04 -0.0023784289
##  [8,] -0.0387247287  1.297783e-02  5.140001e-03  3.764856e-03 -0.0112714576
##  [9,] -0.0079142623 -5.649745e-04 -6.691751e-04 -4.606357e-04  0.0135358450
## [10,] -0.0014005942 -2.762898e-04 -3.440679e-04 -4.573951e-05  0.0016280077
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{stopCluster}\NormalTok{(cl)}
\end{Highlighting}
\end{Shaded}

Lo que vemos arriba es una pequeña parte del modelo de espacio vectorial
de los 150 vectores singulares más importantes, que usaremos como
características para la clasificación supervisada.

\hypertarget{divisiuxf3n-de-los-datos-en-train-y-test}{%
\subsection{División de los datos en train y
test}\label{divisiuxf3n-de-los-datos-en-train-y-test}}

Evaluar la capacidad predictiva de un modelo consiste en comprobar cómo
de próximas son sus predicciones a los verdaderos valores de la variable
a predecir. Para poder cuantificar de forma correcta este error, se
necesita disponer de un conjunto de observaciones, de las que se conozca
la variable a predecir, pero que el modelo no haya ``visto'', es decir,
que no hayan participado en su ajuste. Con esta finalidad, se dividen
los datos disponibles en un conjunto de train y un conjunto de test.

Con el conjunto de datos, del que se conoce la variable a predecir
(\textbf{complete\_df}) y las características que hemos creado en la
sección anterior (\textbf{complete\_irlba}) creamos un nuevo conjunto de
datos que a continuación dividiremos en un conjunto de datos de train
(\textbf{train.df}) y de test (\textbf{test.df}), con el mismo tamaño de
la partición inicial proporcionada por la competición de Kaggle (7613
instancias para el conjunto de datos de train y 3263 instancias para el
conjunto de datos de test).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{complete.svd <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{target=}\NormalTok{complete_df}\OperatorTok{$}\NormalTok{target, complete_irlba}\OperatorTok{$}\NormalTok{v)}
\NormalTok{train.df <-}\StringTok{ }\NormalTok{complete.svd[}\DecValTok{1}\OperatorTok{:}\DecValTok{7613}\NormalTok{, ]}
\NormalTok{test.df <-}\StringTok{ }\NormalTok{complete.svd[}\DecValTok{7614}\OperatorTok{:}\DecValTok{10876}\NormalTok{, }\DecValTok{-1}\NormalTok{]}
\KeywordTok{dim}\NormalTok{(train.df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7613  151
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(test.df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3263  150
\end{verbatim}

Un paso importante es verificar que la distribución de la variable a
predecir del conjunto datos de train no ha cambiado respecto a la
partición inicial (\textbf{complete\_df}).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{prop.table}\NormalTok{(}\KeywordTok{table}\NormalTok{(complete_df}\OperatorTok{$}\NormalTok{target))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##        No       Yes 
## 0.5703402 0.4296598
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{prop.table}\NormalTok{(}\KeywordTok{table}\NormalTok{(train.df}\OperatorTok{$}\NormalTok{target))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##        No       Yes 
## 0.5703402 0.4296598
\end{verbatim}

\hypertarget{selecciuxf3n-de-variables}{%
\subsection{Selección de variables}\label{selecciuxf3n-de-variables}}

Cuando se entrena un modelo, es importante incluir como variables para
la predicción únicamente aquellas variables que están realmente
relacionadas con la variable a predecir, ya que son estas las que
contienen información útil para el modelo. Incluir un exceso de
variables suele conllevar una reducción de la capacidad de predicción
del modelo. La selección de variables para la predicción puede suponer
la diferencia entre un modelo normal y uno muy bueno, por lo tanto,
conviene conocer las herramientas internas de *caret** para la selección
de variables.

Muchos modelos a los que se puede acceder mediante la función
\textbf{train} de \textbf{caret} producen ecuaciones de predicción que
no necesariamente utilizan todas las variables. Estos modelos tienen una
selección de variables incorporada. El uso de estos modelos con
selección de variables incorporada será más eficiente que otras
estrategias, de wrapper y filtrado.

Para este ejercicio, escogemos algoritmos de clasificación supervisada
de \textbf{caret} que tienen una selección de variables incorporada (ver
\url{http://topepo.github.io/caret/feature-selection-overview.html})..

\hypertarget{entrenamiento-de-modelos}{%
\subsection{Entrenamiento de modelos}\label{entrenamiento-de-modelos}}

En esta sección se entrenan diferentes modelos de \emph{clasificación
supervisada} con el objetivo de compararlos e identificar el que mejor
resultado obtiene prediciendo. Todos estos modelos incorporados en el
paquete \textbf{caret} se entrenan con la función \textbf{train}. Entre
los argumentos de esta función destacan:

\begin{itemize}
\item
  \textbf{method}. El nombre del algoritmo que se desea emplear
  (\href{http://topepo.github.io/caret/available-models.html}{modelos}.
\item
  \textbf{metric}. La métrica empleada para evaluar la capacidad
  predictiva del modelo. Aunque la competición de Kaggle en la que se
  basa nuestro ejercicio usa \textbf{F1 score} como métrica de
  evaluación, para cuantificar como de bueno son los modelos
  utilizaremos la métrica de evaluación \emph{Accuracy}. Porqué la
  distribución de la clase no presenta un problema notable de
  desbalanceo de clases y cuando la distribución de la variable clase
  está bastante equilibrada es una buena medida de evaluación.
\end{itemize}

\emph{Accuracy es el porcentaje de observaciones correctamente
clasificadas respecto al total de predicciones.}

\begin{itemize}
\tightlist
\item
  \textbf{trControl}. Especificaciones adicionales sobre la forma de
  llevar a cabo el entrenamiento del modelo.
\end{itemize}

La función \textbf{train} de \textbf{caret} siempre estima un porcentaje
de bien clasificados sobre el conjunto de datos de train. La función
\textbf{trainControl}, que se pasa al argumento \textbf{trControl} de la
función \textbf{train}, controla la estimación del error: en este caso
realizaremos una \emph{K-Fold Cross-Validation} usando la función
\textbf{createMultiFolds}, de 5 hojas (\emph{k}) y repitiéndola 3 veces
(\emph{times}). Una validación cruzada con 5 hojas y 3 repeticiones,
implica ajustar y evaluar el modelo 5 * 3 = 15 veces, más un último
ajuste con todos los datos de entrenamiento para crear el modelo final.

\emph{k-Fold-Cross-Validation (CV). Las observaciones de entrenamiento
se reparten en k folds (conjuntos) del mismo tamaño. El modelo se ajusta
con todas las observaciones excepto las del primer fold y se evalúa
prediciendo las observaciones del fold que ha quedado excluido,
obteniendo así la primera métrica. El proceso se repite k veces,
excluyendo un fold distinto en cada iteración. Al final, se generan k
valores de la métrica, que se agregan (normalmente con la media y la
desviación típica) generando la estimación final de validación.}

\emph{Repeated k-Fold-Cross-Validation (repeated CV). Es exactamente
igual al método k-Fold-Cross-Validation pero repitiendo el proceso
completo n veces. Por ejemplo, 10-Fold-Cross-Validation con 5
repeticiones implica a un total de 50 iteraciones ajuste-validación,
pero no equivale a un 50-Fold-Cross-Validation.}

Las semillas son necesarias si se quiere asegurar la reproducibilidad de
los resultados, ya que una validación cruzada implica una selección
aleatoria.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{cv.folds <-}\StringTok{ }\KeywordTok{createMultiFolds}\NormalTok{(train.df}\OperatorTok{$}\NormalTok{target, }\DataTypeTok{k=}\DecValTok{5}\NormalTok{, }\DataTypeTok{times=}\DecValTok{3}\NormalTok{)}
\NormalTok{cv.cntrl <-}\StringTok{ }\KeywordTok{trainControl}\NormalTok{(}\DataTypeTok{method=}\StringTok{"repeatecv"}\NormalTok{, }\DataTypeTok{number=}\DecValTok{5}\NormalTok{,}
                         \DataTypeTok{index=}\NormalTok{cv.folds, }\DataTypeTok{allowParallel=}\OtherTok{TRUE}\NormalTok{, }
                         \DataTypeTok{returnResamp=}\StringTok{"final"}\NormalTok{,}
                         \DataTypeTok{verboseIter=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

El argumento \textbf{method} de la función \textbf{trainControl} hace
posible utilizar distintos tipos de validación. En este caso es
\emph{repeatecv} (para entrenamiento repetido/división de test). Además
de fijar el tipo de validación, la función \textbf{trainControl} permite
fijar multitud de argumentos. A continuación, describimos los que se han
fijado:

\begin{itemize}
\tightlist
\item
  \textbf{number}. El número de hojas (\emph{5}).
\item
  \textbf{index}. Lista con los elementos para cada iteración
  (\textbf{cv.folds}). Cada elemento de la lista es un vector de números
  enteros correspondientes a las filas utilizadas para el entrenamiento
  en esa iteración.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{str}\NormalTok{(cv.folds)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## List of 15
##  $ Fold1.Rep1: int [1:6090] 1 2 3 4 5 6 7 8 9 11 ...
##  $ Fold2.Rep1: int [1:6090] 1 2 3 4 5 7 8 9 10 11 ...
##  $ Fold3.Rep1: int [1:6090] 1 2 3 5 6 7 8 9 10 11 ...
##  $ Fold4.Rep1: int [1:6091] 2 3 4 6 10 12 13 14 15 16 ...
##  $ Fold5.Rep1: int [1:6091] 1 4 5 6 7 8 9 10 11 12 ...
##  $ Fold1.Rep2: int [1:6090] 1 4 5 6 8 9 10 11 12 13 ...
##  $ Fold2.Rep2: int [1:6090] 2 3 4 5 6 7 8 9 11 12 ...
##  $ Fold3.Rep2: int [1:6090] 1 2 3 5 6 7 10 11 12 14 ...
##  $ Fold4.Rep2: int [1:6091] 1 2 3 4 5 6 7 8 9 10 ...
##  $ Fold5.Rep2: int [1:6091] 1 2 3 4 7 8 9 10 11 12 ...
##  $ Fold1.Rep3: int [1:6091] 1 2 3 6 7 8 9 10 11 12 ...
##  $ Fold2.Rep3: int [1:6090] 1 2 4 5 6 7 9 10 11 13 ...
##  $ Fold3.Rep3: int [1:6090] 1 3 4 5 8 9 10 11 12 13 ...
##  $ Fold4.Rep3: int [1:6090] 2 3 4 5 6 7 8 12 13 14 ...
##  $ Fold5.Rep3: int [1:6091] 1 2 3 4 5 6 7 8 9 10 ...
\end{verbatim}

\begin{itemize}
\tightlist
\item
  \textbf{allowParallel}. Habilita la computación paralela
  (\emph{TRUE}). \textbf{caret} permite paralelizar el proceso para que
  sea más rápido.
\item
  \textbf{returnResamp}. Indica la cantidad de métricas de evaluación
  que se deben guardar. Solo los valores finales (\emph{``final''}).
\item
  \textbf{verboseIter}. Para imprimir o no el registro de entrenamiento.
  No se imprime (\emph{FALSE}).
\end{itemize}

Muchos modelos contienen parámetros que no pueden aprenderse a partir de
los datos de entrenamiento y, por lo tanto, deben de ser establecidos
por el analista. A estos se les conoce como \emph{hiperparámetros},
argumento \textbf{tunning} de \textbf{caret}. Con la función
\textbf{expand.grid} definiremos los valores de los argumentos a tunear.

Los resultados de un modelo pueden depender en gran medida del valor que
tomen sus \emph{hiperparámetros}, sin embargo, no se puede conocer de
antemano cuáles son los adecuados. La forma más común de encontrar los
valores óptimos es probando diferentes posibilidades. Para ello se
utiliza el argumento de \textbf{caret}: \textbf{tuneGrid} en la función
\textbf{train}. Si no se tiene ninguna idea de qué valores de
\emph{hiperparámetros} pueden ser los adecuados, lo mejor es utilizar la
aleatoriedad. \textbf{caret} también incorpora esta opción mediante el
argumento \textbf{tuneLength}.

En el entrenamiento de los modelos realizaremos pruebas tanto con
\textbf{tuneGrid} y \textbf{tuneLength}. Más con \textbf{tuneGrid}, ya
que, de esta forma, se evita que se generen automáticamente valores que
no tienen sentido o que disparan el tiempo de computación necesario.
Además, con \emph{target \textasciitilde{}.} denotamos la variable que
se quiere predecir e indicando que el resto de las variables del
conjunto de datos de \textbf{train} son predictoras.

A lo largo del proceso posterior es donde más destacarán las
funcionalidades ofrecidas por \textbf{caret}, permitiendo emplear la
misma sintaxis para ajustar, optimizar, evaluar y predecir un amplio
abanico de modelos variando únicamente el nombre del algoritmo. Aunque
\textbf{caret} permite todo esto con apenas unas pocas líneas de código
son muchos los argumentos que pueden ser adaptados, cada uno con
múltiples posibilidades. Con el objetivo de exponer mejor cada una de
las opciones, en lugar de crear directamente un modelo final, se
muestran ejemplos de menor a mayor complejidad de la lista mostrada
anteriormente:
\url{http://topepo.github.io/caret/available-models.html}.

\hypertarget{regresiuxf3n-loguxedstica}{%
\subsubsection{Regresión Logística}\label{regresiuxf3n-loguxedstica}}

Información detallada sobre regresión logística en
\href{https://www.cienciadedatos.net/documentos/27_regresion_logistica_simple_y_multiple}{Regresión
logística simple y múltiple}.

\textbf{caret} emplea el método \textbf{glmnet}. Este algoritmo no tiene
ningún \emph{hiperparámetro}, por lo tanto, usamos por ejemplo
\textbf{tuneLength} igual a 15.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cl <-}\StringTok{ }\KeywordTok{makePSOCKcluster}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DataTypeTok{setup_strategy=}\StringTok{"sequential"}\NormalTok{)}
\KeywordTok{registerDoParallel}\NormalTok{(cl)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{model_glmnet <-}\StringTok{ }\KeywordTok{train}\NormalTok{(target }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data=}\NormalTok{train.df,}
                      \DataTypeTok{method=}\StringTok{"glmnet"}\NormalTok{,}
                      \DataTypeTok{metric=}\StringTok{"Accuracy"}\NormalTok{,}
                      \DataTypeTok{trControl=}\NormalTok{cv.cntrl,}
                      \DataTypeTok{tuneLenght=}\DecValTok{15}\NormalTok{)}
\NormalTok{model_glmnet}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## glmnet 
## 
## 7613 samples
##  150 predictor
##    2 classes: 'No', 'Yes' 
## 
## No pre-processing
## Resampling: 
## Summary of sample sizes: 6090, 6090, 6090, 6091, 6091, 6090, ... 
## Resampling results across tuning parameters:
## 
##   alpha  lambda        Accuracy   Kappa    
##   0.10   0.0001850059  0.7648316  0.5085381
##   0.10   0.0018500586  0.7650941  0.5087571
##   0.10   0.0185005864  0.7635180  0.5023833
##   0.55   0.0001850059  0.7648316  0.5084863
##   0.55   0.0018500586  0.7650943  0.5081484
##   0.55   0.0185005864  0.7487187  0.4642323
##   1.00   0.0001850059  0.7649630  0.5087688
##   1.00   0.0018500586  0.7639123  0.5051295
##   1.00   0.0185005864  0.7211778  0.3970376
## 
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were alpha = 0.55 and lambda = 0.001850059.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{stopCluster}\NormalTok{(cl)}
\end{Highlighting}
\end{Shaded}

El \emph{Accuracy} promedio estimado mediante validación cruzada
repetida es de 0.7648316, el modelo predice correctamente un 76.5\% de
las veces.

\hypertarget{random-forest}{%
\subsubsection{Random Forest}\label{random-forest}}

Información detallada sobre Random Forest en
\href{https://www.cienciadedatos.net/documentos/33_arboles_de_prediccion_bagging_random_forest_boosting}{Árboles
de predicción: bagging, random forest, boosting y C5.0}.

\textbf{caret} emplea el método **rf\emph{. Este algoritmo tiene un
}hiperparámetro*:

\begin{itemize}
\tightlist
\item
  \textbf{mtry}. Número de valores seleccionados aleatoriamente en cada
  árbol. En este caso hemos escogido: 3, 4, 5 y 7.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cl <-}\StringTok{ }\KeywordTok{makePSOCKcluster}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DataTypeTok{setup_strategy=}\StringTok{"sequential"}\NormalTok{)}
\KeywordTok{registerDoParallel}\NormalTok{(cl)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{cv.grid <-}\StringTok{ }\KeywordTok{expand.grid}\NormalTok{(}\DataTypeTok{mtry=}\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{))}
\NormalTok{model_rf <-}\StringTok{ }\KeywordTok{train}\NormalTok{(target }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data=}\NormalTok{train.df,}
                      \DataTypeTok{method=}\StringTok{"rf"}\NormalTok{,}
                      \DataTypeTok{metric=}\StringTok{"Accuracy"}\NormalTok{,}
                      \DataTypeTok{trControl=}\NormalTok{cv.cntrl,}
                      \DataTypeTok{tuneGrid=}\NormalTok{cv.grid)}
\NormalTok{model_rf}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Random Forest 
## 
## 7613 samples
##  150 predictor
##    2 classes: 'No', 'Yes' 
## 
## No pre-processing
## Resampling: 
## Summary of sample sizes: 6090, 6090, 6090, 6091, 6091, 6090, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##   3     0.7618968  0.5068252
##   4     0.7623348  0.5078468
##   5     0.7608022  0.5051518
##   7     0.7587883  0.5010024
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 4.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{stopCluster}\NormalTok{(cl)}
\end{Highlighting}
\end{Shaded}

Empleando un modelo Random Forest con mtry = 5 se consigue un
\emph{Accuracy} promedio de validación igual a 0.7632101, el modelo
predice correctamente un 76.3\% de las veces.

\hypertarget{gradient-boosting}{%
\subsubsection{Gradient Boosting}\label{gradient-boosting}}

Información detallada sobre boosting
\href{https://www.cienciadedatos.net/documentos/33_arboles_de_prediccion_bagging_random_forest_boosting}{Árboles
de predicción: bagging, random forest, boosting y C5.0}.

El método \textbf{gbm} de \textbf{caret} emplea el paquete gbm. Este
algoritmo tiene 4 \emph{hiperparámetros}:

\begin{itemize}
\item
  \textbf{n.trees}. Número de iteraciones del algoritmo de boosting.
  Cuanto mayor es este valor, más se reduce el error de entrenamiento.
\item
  \textbf{interaction.depth}. El número total de divisiones que tiene el
  árbol. Emplear árboles con ente 1 y 6 nodos suele dar buenos
  resultados.
\item
  \textbf{shrinkage}. Controla la complejidad que tiene el modelo. Es
  preferible mejorar un modelo mediante muchos pasos pequeños que
  mediante unos pocos grandes. Por esta razón, se emplea un valor de
  \textbf{shrinkage} tan pequeño como sea posible, teniendo en cuenta
  que, cuanto menor sea, mayor el número de iteraciones necesarias. Por
  defecto es de 0.001.
\item
  \textbf{n.minobsinnode}. Número mínimo de observaciones que debe tener
  cada nodo del árbol para poder ser dividido. Al igual que
  \textbf{interaction.depth}, permite controlar la complejidad que tiene
  el modelo.
\end{itemize}

Además de los hiperparámetros que permite controlar \textbf{caret},
tiene otros dos más que hay que tener en cuenta:

\begin{itemize}
\item
  \textbf{distribution}. Determina la función de coste (\emph{loss
  function}). Algunas de las más utilizadas son: \emph{gaussian}
  (squared loss) para regresión, \emph{bernoulli} para clasificaciones
  binarias, multinomial para clasificaciones con más de dos clases y
  \emph{adaboost} para clasificaciones binarias y que emplea la función
  exponencial del algoritmo original
  \href{https://en.wikipedia.org/wiki/AdaBoost}{AdaBoost}.
\item
  \textbf{bag.fraction} (subsampling fraction): fracción de
  observaciones del conjunto de train seleccionadas de forma aleatoria.
  Si su valor es de 1, se emplea el algoritmo de \emph{Gradient
  Boosting}, si es menor que 1, se emplea \emph{Stochastic Gradient
  Boosting}. Por defecto su valor es de 0.5.
\end{itemize}

En este caso solo añadimos el argumento \textbf{distribution} y como el
ejercicio se basa en un problema de clasificación binaria usamos
\emph{adaboost}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(gbm)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cl <-}\StringTok{ }\KeywordTok{makePSOCKcluster}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DataTypeTok{setup_strategy=}\StringTok{"sequential"}\NormalTok{)}
\KeywordTok{registerDoParallel}\NormalTok{(cl)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{cv.grid <-}\StringTok{ }\KeywordTok{expand.grid}\NormalTok{(}\DataTypeTok{interaction.depth=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{),}
                       \DataTypeTok{n.trees=}\DecValTok{100}\NormalTok{,}
                       \DataTypeTok{shrinkage=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.001}\NormalTok{, }\FloatTok{0.01}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                       \DataTypeTok{n.minobsinnode=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{15}\NormalTok{))}

\NormalTok{model_gbm <-}\StringTok{ }\KeywordTok{train}\NormalTok{(target }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data=}\NormalTok{train.df,}
                  \DataTypeTok{method=}\StringTok{"gbm"}\NormalTok{,}
                  \DataTypeTok{metric=}\StringTok{"Accuracy"}\NormalTok{,}
                  \DataTypeTok{trControl=}\NormalTok{cv.cntrl,}
                  \DataTypeTok{tuneGrid=}\NormalTok{cv.grid,}
                  \DataTypeTok{distribution=}\StringTok{"adaboost"}\NormalTok{,}
                  \DataTypeTok{verbose=}\OtherTok{FALSE}\NormalTok{)}
\NormalTok{model_gbm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Stochastic Gradient Boosting 
## 
## 7613 samples
##  150 predictor
##    2 classes: 'No', 'Yes' 
## 
## No pre-processing
## Resampling: 
## Summary of sample sizes: 6090, 6090, 6090, 6091, 6091, 6090, ... 
## Resampling results across tuning parameters:
## 
##   shrinkage  interaction.depth  n.minobsinnode  Accuracy   Kappa    
##   0.001      1                   2              0.5703402  0.0000000
##   0.001      1                   5              0.5703402  0.0000000
##   0.001      1                  15              0.5703402  0.0000000
##   0.001      2                   2              0.5703402  0.0000000
##   0.001      2                   5              0.5703402  0.0000000
##   0.001      2                  15              0.5703402  0.0000000
##   0.010      1                   2              0.6553692  0.2397333
##   0.010      1                   5              0.6548878  0.2383772
##   0.010      1                  15              0.6544059  0.2374328
##   0.010      2                   2              0.6946872  0.3400736
##   0.010      2                   5              0.6931547  0.3366365
##   0.010      2                  15              0.6932867  0.3367455
##   0.100      1                   2              0.7244616  0.4220042
##   0.100      1                   5              0.7230157  0.4197413
##   0.100      1                  15              0.7235418  0.4199881
##   0.100      2                   2              0.7446022  0.4675017
##   0.100      2                   5              0.7438146  0.4658317
##   0.100      2                  15              0.7421065  0.4621889
## 
## Tuning parameter 'n.trees' was held constant at a value of 100
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were n.trees = 100, interaction.depth =
##  2, shrinkage = 0.1 and n.minobsinnode = 2.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{stopCluster}\NormalTok{(cl)}
\end{Highlighting}
\end{Shaded}

Empleando un modelo Boosting con n.trees = 100, interaction.depth = 2,
shrinkage = 0.1 and n.minobsinnode = 2 se consigue un \emph{Accuracy}
promedio de validación igual a 0.7444716, el modelo predice
correctamente un 74.4\% de las veces.

\hypertarget{svm}{%
\subsubsection{SVM}\label{svm}}

Información detallada sobre SVM en
\href{https://www.cienciadedatos.net/documentos/34_maquinas_de_vector_soporte_support_vector_machines}{Máquinas
de Vector Soporte (Support Vector Machines, SVMs)}.

\textbf{caret} emplea el método \textbf{svmRadial}. Este algoritmo tiene
2 hiperparámetros:

\begin{itemize}
\item
  \textbf{sigma}. Coeficiente del kernel radial.
\item
  \textbf{C}. Penalización por violaciones del margen del hiperplano.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cl <-}\StringTok{ }\KeywordTok{makePSOCKcluster}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DataTypeTok{setup_strategy=}\StringTok{"sequential"}\NormalTok{)}
\KeywordTok{registerDoParallel}\NormalTok{(cl)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{cv.grid <-}\StringTok{ }\KeywordTok{expand.grid}\NormalTok{(}\DataTypeTok{sigma=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.001}\NormalTok{, }\FloatTok{0.01}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{),}
                       \DataTypeTok{C=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{))}

\NormalTok{model_svm <-}\StringTok{ }\KeywordTok{train}\NormalTok{(target }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data=}\NormalTok{train.df,}
                      \DataTypeTok{method=}\StringTok{"svmRadial"}\NormalTok{,}
                      \DataTypeTok{metric=}\StringTok{"Accuracy"}\NormalTok{,}
                      \DataTypeTok{trControl=}\NormalTok{cv.cntrl,}
                      \DataTypeTok{tuneLenght=}\NormalTok{cv.grid)}
\NormalTok{model_svm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Support Vector Machines with Radial Basis Function Kernel 
## 
## 7613 samples
##  150 predictor
##    2 classes: 'No', 'Yes' 
## 
## No pre-processing
## Resampling: 
## Summary of sample sizes: 6090, 6090, 6090, 6091, 6091, 6090, ... 
## Resampling results across tuning parameters:
## 
##   C     Accuracy   Kappa    
##   0.25  0.7615472  0.5008012
##   0.50  0.7678960  0.5139026
##   1.00  0.7701726  0.5185027
## 
## Tuning parameter 'sigma' was held constant at a value of 0.006839611
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were sigma = 0.006839611 and C = 1.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{stopCluster}\NormalTok{(cl)}
\end{Highlighting}
\end{Shaded}

Empleando un modelo SVM Radial con sigma = 0.006839608 y C = 1, se
consigue un \emph{Accuracy} promedio de validación igual a 0.7701726, el
modelo predice correctamente un 77\% de las veces.

\hypertarget{evaluaciuxf3n-de-modelos-mediante-resampling}{%
\subsection{Evaluación de modelos mediante
resampling}\label{evaluaciuxf3n-de-modelos-mediante-resampling}}

Una vez que se han entrenado los distintos modelos, se tiene que
identificar cuál de ellos consigue mejores resultados para el problema
en cuestión. Con los datos disponibles, existen dos formas de comparar
los modelos. Si bien las dos no tienen por qué dar los mismos
resultados, son complementarias a la hora de tomar una decisión final.
Las dos formas de comparar y evaluar los distintos modelos entrenados
son: usando las métricas de evaluación obtenidas y/o según el error de
test empleando la función \textbf{extractPrediction} de \textbf{caret}.

La forma que usaremos se basará en las métricas obtenidas. Estas
mediante la validación cruzada son estimaciones de la capacidad que
tienen los modelos al predecir nuevas observaciones. Como toda
estimación, tiene asociada un promedio. Para poder determinar si un
método es superior a otro, no es suficiente con comparar los mínimos (o
máximos dependiendo de la métrica) que ha conseguido cada uno, sino que
hay que tener en cuenta sus promedios para determinar si existen
evidencias suficientes de superioridad.

La función \textbf{resamples} permite extraer, dado los modelos creados
con \textbf{train}, las métricas obtenidas para cada repetición del
proceso de validación. Es importante tener en cuenta que esta función
recupera todos los resultados, por lo que, si no se especifica en el
control de entrenamiento \emph{returnResamp = ``final''}, se devuelven
los valores para todos los \emph{hiperparámetros}, no solo los del
modelo final.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{models <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{logistic=}\NormalTok{model_glmnet,}
               \DataTypeTok{RF=}\NormalTok{model_rf, }
               \DataTypeTok{boosting=}\NormalTok{model_gbm, }
               \DataTypeTok{SVMRadial=}\NormalTok{model_svm)}

\NormalTok{resamps <-}\StringTok{ }\KeywordTok{resamples}\NormalTok{(models)}
\KeywordTok{summary}\NormalTok{(resamps)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## summary.resamples(object = resamps)
## 
## Models: logistic, RF, boosting, SVMRadial 
## Number of resamples: 15 
## 
## Accuracy 
##                Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's
## logistic  0.7424442 0.7592784 0.7667543 0.7650943 0.7728168 0.7820092    0
## RF        0.7399869 0.7545992 0.7608410 0.7623348 0.7669074 0.7944846    0
## boosting  0.7170059 0.7398160 0.7439265 0.7446022 0.7488510 0.7754432    0
## SVMRadial 0.7491793 0.7641261 0.7667543 0.7701726 0.7731451 0.7990808    0
## 
## Kappa 
##                Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's
## logistic  0.4573146 0.4949223 0.5129929 0.5081484 0.5257726 0.5456174    0
## RF        0.4637190 0.4919726 0.5020328 0.5078468 0.5179187 0.5780024    0
## boosting  0.4089761 0.4589374 0.4640576 0.4675017 0.4759897 0.5330039    0
## SVMRadial 0.4748475 0.5041853 0.5092062 0.5185027 0.5261318 0.5834342    0
\end{verbatim}

Observamos que junto con la estimación del porcentaje de bien
clasificados (\textbf{Accuracy}), se nos muestra el valor de la métrica
\textbf{Kappa}, el cual es una medida que compara el \textbf{Accuracy}
observado respecto al \textbf{Accuracy} esperado (de una predicción al
azar). Esto es, cuanto mejor estima un clasificador respecto a otro que
predice al azar. Un ameno ejemplo para entenderla mejor se encuentra en
este
\href{https://stats.stackexchange.com/questions/82162/cohens-kappa-in-plain-english}{enlace}.

\emph{Kappa o Cohen's Kappa es el valor de Accuracy normalizado respecto
del porcentaje de acierto esperado por azar. A diferencia de Accuracy,
cuyo rango de valores puede ser {[}0, 1{]}, el de kappa es {[}-1, 1{]}.
En problemas con clases desbalanceadas, donde el grupo mayoritario
supera por mucho a los otros, Kappa es más útil porque evita caer en la
ilusión de creer que un modelo es bueno cuando realmente solo supera por
poco lo esperado por azar. }

Todos los modelos tienen un promedio de acierto en la predicción
superior al nivel basal, Accuracy** superior a 0.57. El modelo
\emph{SVMRadial} consigue el \textbf{Accuracy} promedio más alto,
seguido muy de cerca por el modelo \emph{logistic}. Para determinar si
las diferencias entre ellos son significativas, se recurre a un
\emph{test estadístico}. Al compartir las ``folds''-hojas, un \emph{test
estadístico} calculará la significancia de las diferencias entre los
promedios de error de ambos modelos. Se trata de chequear las
diferencias, para cada métrica, comparando entre los pares de
clasificadores y de interpretar, mediante el \emph{p-value} asociado, si
estas diferencias son estadísticamente significativas o no,
\url{https://en.wikipedia.org/wiki/Statistical_significance}. Usamos un
umbral de \emph{0.05}.

El \emph{test estadístico} que aplicamos es
\href{https://www.cienciadedatos.net/documentos/18_prueba_de_los_rangos_con_signo_de_wilcoxon}{\emph{Wilcoxon
signed-rank test}}, con correcciones por comparaciones múltiples. Este
test usa la función \textbf{pairwise.wilcox.test} que nos da mucha
flexibilidad en cuanto a las comparaciones múltiples.

\hypertarget{wilcoxon-signed-rank-test}{%
\subsubsection{Wilcoxon signed-rank
test}\label{wilcoxon-signed-rank-test}}

Primeo se trasforma el dataframe devuelto por \textbf{resamples} para
separar el nombre del modelo y las métricas en columnas distintas. Se
usan las funciones \textbf{gather} (junta las columnas en pares
clave-valor) y \textbf{separate} (separa una columna de caracteres en
varias columnas). Para una mejor visualización también se usan las
funciones \textbf{group\_by}. para agrupar los resultados
modelo-métrica, \textbf{summarise}, \textbf{spread}, para distribuir los
pares clave-valor en varias columnas, y \textbf{arrange} para ordenar
los resultados de forma descendente. Todas estas funciones se pueden
encontrar en los paquetes \textbf{tidyr} y \textbf{dplyr} del paquete
\textbf{tidyverse}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{metricas_resamples <-}\StringTok{ }\NormalTok{resamps}\OperatorTok{$}\NormalTok{values }\OperatorTok{%>%}
\StringTok{                         }\KeywordTok{gather}\NormalTok{(}\DataTypeTok{key =} \StringTok{"modelo"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"valor"}\NormalTok{, }\OperatorTok{-}\NormalTok{Resample) }\OperatorTok{%>%}
\StringTok{                         }\KeywordTok{separate}\NormalTok{(}\DataTypeTok{col =} \StringTok{"modelo"}\NormalTok{, }\DataTypeTok{into =} \KeywordTok{c}\NormalTok{(}\StringTok{"modelo"}\NormalTok{, }\StringTok{"metrica"}\NormalTok{),}
                                  \DataTypeTok{sep =} \StringTok{"~"}\NormalTok{, }\DataTypeTok{remove =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{metricas_resamples }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(modelo, metrica) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{media =} \KeywordTok{mean}\NormalTok{(valor)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{spread}\NormalTok{(}\DataTypeTok{key =}\NormalTok{ metrica, }\DataTypeTok{value =}\NormalTok{ media) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(Accuracy))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'modelo' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 4 x 3
## # Groups:   modelo [4]
##   modelo    Accuracy Kappa
##   <chr>        <dbl> <dbl>
## 1 SVMRadial    0.770 0.519
## 2 logistic     0.765 0.508
## 3 RF           0.762 0.508
## 4 boosting     0.745 0.468
\end{verbatim}

Comparaciones múltiples con el test suma de rangos de \emph{Wilcoxon}
usando la función \textbf{pairwise.wilcox.test}. Este test es una
alternativa al \emph{t-test} de observaciones dependientes cuando las
observaciones no siguen una distribución normal. LA función contiene los
siguientes argumentos:

\begin{itemize}
\tightlist
\item
  \textbf{x}. Vector que contiene todos los valores de \textbf{Accuracy}
  de los modelos entrenados (\emph{metricas\_accuracy\$valor}).
\item
  \textbf{g}. El vector \emph{metricas\_accuracy\$valor} agrupado por
  modelo.
\item
  \textbf{paired}. Indicador de si el test es paredado o no. En este
  caso sí que lo es.
\item
  \textbf{p.adjust.method}. Método para ajustar los \emph{p-values}. En
  este se ajusta con el método de
  \href{https://en.wikipedia.org/wiki/Holm\%E2\%80\%93Bonferroni_method}{\emph{Holm's}},
  que es de los más utilizados para las comparaciones múltiples.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{metricas_accuracy <-}\StringTok{ }\NormalTok{metricas_resamples }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(metrica }\OperatorTok{==}\StringTok{ "Accuracy"}\NormalTok{)}
\NormalTok{comparaciones  <-}\StringTok{ }\KeywordTok{pairwise.wilcox.test}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ metricas_accuracy}\OperatorTok{$}\NormalTok{valor, }
                                        \DataTypeTok{g =}\NormalTok{ metricas_accuracy}\OperatorTok{$}\NormalTok{modelo,}
                                        \DataTypeTok{paired =} \OtherTok{TRUE}\NormalTok{,}
                                        \DataTypeTok{p.adjust.method =} \StringTok{"holm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Finalmente se almacenan los \emph{p-values} en forma de dataframe.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comparaciones <-}\StringTok{ }\NormalTok{comparaciones}\OperatorTok{$}\NormalTok{p.value }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{as.data.frame}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rownames_to_column}\NormalTok{(}\DataTypeTok{var =} \StringTok{"modeloA"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather}\NormalTok{(}\DataTypeTok{key =} \StringTok{"modeloB"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"p_value"}\NormalTok{, }\OperatorTok{-}\NormalTok{modeloA) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{na.omit}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(modeloA) }

\NormalTok{comparaciones}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     modeloA  modeloB      p_value
## 1  logistic boosting 0.0007324219
## 2        RF boosting 0.0036056278
## 3        RF logistic 0.3894042969
## 4 SVMRadial boosting 0.0036056278
## 5 SVMRadial logistic 0.1801641152
## 6 SVMRadial       RF 0.0036056278
\end{verbatim}

\hypertarget{conclusiuxf3n-evaluaciuxf3n-de-modelos}{%
\subsubsection{Conclusión evaluación de
modelos}\label{conclusiuxf3n-evaluaciuxf3n-de-modelos}}

Hemos visto que el modelo basado en \emph{SVM} es el que mejores
resultados obtiene (acorde a la métrica \textbf{Accuracy}) en el
conjunto de train con la validación cruzada (``repeatedcv''). Los
modelos basados \emph{random forest} y \emph{regresión logística}
consiguen valores un poco similares, sin embargo, acorde a los
contrastes de hipótesis con los resultados de la validación, los modelos
de \emph{random forest} y \emph{regresión logistica} son inferiores a
\emph{SVM}.

Concretamente en la comparación por pares entre los modelos
\emph{SVMRadial} y \emph{logistic} existen evidencias suficientes para
considerar que la capacidad predictiva de los modelos es distinta,
\emph{p-value} \textgreater{} 0.05 (0.1801641152).

Antes de la predicción, calcularemos el valor \textbf{F1 score}, la
métrica que usa la competición de Kaggle escogida para nuestro
ejercicio, porqué queremos ver si nos dará buenos resultados en la
competición el modelo que acabamos de seleccionado (\emph{SVMRadial}).
Para ello tendremos que predecir sobre el conjunto de train, calcular la
matriz de confusión y calcular el valor de \textbf{F1 score}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pre_pred <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(model_svm, train.df, }\DataTypeTok{type=}\StringTok{"raw"}\NormalTok{)}
\KeywordTok{confusionMatrix}\NormalTok{(pre_pred, train.df}\OperatorTok{$}\NormalTok{target)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   No  Yes
##        No  4092  963
##        Yes  250 2308
##                                           
##                Accuracy : 0.8407          
##                  95% CI : (0.8323, 0.8488)
##     No Information Rate : 0.5703          
##     P-Value [Acc > NIR] : < 2.2e-16       
##                                           
##                   Kappa : 0.6659          
##                                           
##  Mcnemar's Test P-Value : < 2.2e-16       
##                                           
##             Sensitivity : 0.9424          
##             Specificity : 0.7056          
##          Pos Pred Value : 0.8095          
##          Neg Pred Value : 0.9023          
##              Prevalence : 0.5703          
##          Detection Rate : 0.5375          
##    Detection Prevalence : 0.6640          
##       Balanced Accuracy : 0.8240          
##                                           
##        'Positive' Class : No              
## 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{true_positives <-}\StringTok{ }\DecValTok{2308}
\NormalTok{false_positives <-}\StringTok{ }\DecValTok{250}
\NormalTok{false_negatives <-}\StringTok{ }\DecValTok{963}

\NormalTok{precision <-}\StringTok{ }\NormalTok{true_positives }\OperatorTok{/}\StringTok{ }\NormalTok{(true_positives }\OperatorTok{+}\StringTok{ }\NormalTok{false_positives)}
\NormalTok{recall <-}\StringTok{ }\NormalTok{true_positives }\OperatorTok{/}\StringTok{ }\NormalTok{(true_positives }\OperatorTok{+}\StringTok{ }\NormalTok{false_negatives)}

\NormalTok{F1 <-}\StringTok{ }\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{(precision }\OperatorTok{*}\StringTok{ }\NormalTok{recall) }\OperatorTok{/}\StringTok{ }\NormalTok{(precision }\OperatorTok{+}\StringTok{ }\NormalTok{recall)}
\NormalTok{F1 <-}\StringTok{ }\KeywordTok{round}\NormalTok{(F1, }\DataTypeTok{digits =} \DecValTok{4}\NormalTok{)}

\NormalTok{F1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7919
\end{verbatim}

Teniendo en cuenta toda esta información, para predecir la clase de
casos futuros vamos a usar el clasificador \emph{SVMRadial} que es el
modelo que ha dado mejores resultados durante el entrenamiento. Con este
modelo obtenemos un \textbf{Accuracy} de 0.8407 y un valor de
\textbf{F1\_score} no muy bueno de 0.7919 que intentaremos mejorar.

\hypertarget{predicciuxf3n}{%
\section{Predicción}\label{predicciuxf3n}}

En la predicción se usa la función \textbf{predict} de \textbf{caret}.
La opción elegida es \emph{raw}. Porqué con ella nos quedamos con el
valor de la variable clase con mayor probabilidad a-posteriori y podemos
calcular la matriz de confusión y la colección de métricas de evaluación
asociadas.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred_svm <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(model_svm, test.df, }\DataTypeTok{type=}\StringTok{"raw"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Finalmente preparamos el archivo que subiremos a Kaggle con los
resultados de nuestra predicción. Vemos las 10 primeras líneas.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{submission <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"sample_submission.csv"}\NormalTok{)}
\NormalTok{submission}\OperatorTok{$}\NormalTok{target <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(pred_svm}\OperatorTok{==}\StringTok{"No"}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\KeywordTok{write.csv}\NormalTok{(submission, }\StringTok{"submission.csv"}\NormalTok{, }\DataTypeTok{row.names=}\OtherTok{FALSE}\NormalTok{)}
\KeywordTok{head}\NormalTok{(submission, }\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    id target
## 1   0      0
## 2   2      1
## 3   3      1
## 4   9      0
## 5  11      1
## 6  12      1
## 7  21      0
## 8  22      0
## 9  27      0
## 10 29      0
\end{verbatim}

\hypertarget{resultado-en-kaggle}{%
\section{Resultado en Kaggle}\label{resultado-en-kaggle}}

\includegraphics[width=0.8\textwidth,height=\textheight]{submission.png}

\hypertarget{conclusiones}{%
\section{Conclusiones}\label{conclusiones}}

En este documento se revisa cómo importar y preparar documentos de texto
para realizar distintas operaciones de mineria de textos con ellos,
tales como obtener palabras frecuentes, asociaciones de palabras y
análisis de sentimientos.

Si comparamos nuestro resultado con los de los otros usuarios de la
compatición de Kaggle, vemos que el modelo creado no es muy bueno. La
predicción a sido peor de la esperada. Aunque no era la finalidad de
este ejercicio, esto nos demuestra que el ejercicio se podría mejorar en
algunos expectos.

El problema más importante para la realización de este ejercicio ha sido
el coste computacional. Llegado el punto en que la ejecución de todo el
flujo tardaba unas cuantas horas en finalizar, se pensó en utilizar la
computación paralela. Fue una buena idea, se redujo drásticamente el
coste computacional y además aprendí a hacerlo en \textbf{R}.

Personalmente escogí esta competición ya que nunca habia combinado la
clasificación supervisada con Procesamiento del Lenguaje Natural (PLN).
El Procesamiento del Lenguaje Natural dentro de la inteligencia
artificial es un campo que encuentro muy interesante.

Durante la asignatura de Procesamiento del Lenguaje Natural del Máster
no se realiza ninguna pràctica de programación, y me apreció una buena
oportunidad de aprender como aplicar los conocimientos de adquiridos del
Procesamiento del Lenguaje Natural con los conocimientos adquiridos
durante de esta asignatura.

Por supuesto la minería de textos es un área de análisis extensa. Las
siguientes referencias han sido de gran ayuda para realizar este
documento y amplían lo aquí presentado.

\hypertarget{referencias}{%
\section{Referencias}\label{referencias}}

\begin{itemize}
\item
  Machine Learning con R y caret
  \url{https://www.cienciadedatos.net/documentos/41_machine_learning_con_r_y_caret}
\item
  Notebook en Kaggle de barun2104
  \url{https://www.kaggle.com/barun2104/nlp-with-disaster-eda-dfm-svd-ensemble}
\item
  Notebook en Kaggle de sambitmukherjee
  \url{https://www.kaggle.com/sambitmukherjee/bag-of-words-stack-knn-tree-lasso\#test-set-predictions-submission}
\end{itemize}

\end{document}
