---
title: "Practical 2: Model Evaluation"
author: "Laura Rodriguez Navas"
date: "January 2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Question 1
Load the data into R. Name the columns to better identify the board, as visited from left to right and from top to down.

```{r}
data <- read.table("tic-tac-toe.data.txt", header=FALSE, sep=",")
names(data) <- c("top-left-square", 
                 "top-middle-square", 
                 "top-right-square", 
                 "middle-left-square", 
                 "middle-middle-square", 
                 "middle-right-square", 
                 "bottom-left-square", 
                 "bottom-middle-square",
                 "bottom-right-square", 
                 "Class")
str(data)
```

```{r echo=FALSE}
colnames(data) <- make.names(colnames(data))
```

Check for missing values.

```{r}
any(is.na(data))
```

### Question 2
Read the "data splitting" section at the web page of caret. Then split the data into 70% training and 30% test by keeping the original proportion of classes.

```{r include=FALSE}
library(lattice)
library(ggplot2)
library(caret)
```

```{r}
set.seed(825)
inTraining <- createDataPartition(data$Class, p=.7, list=FALSE)
data_training <- data[ inTraining,]
data_testing  <- data[-inTraining,]
str(data_training)
str(data_testing)
```

### Question 3
Specifiy the type of resampling.

```{r}
fitControl <- trainControl(method="repeatedcv", 
                           number=10, 
                           repeats=1,
                           classProbs=TRUE)
```

Apply the models: Naive Bayes, Decision Tree, Neural Networks, Nearest Neighbour and SVM (linear kernel) to the data training dataset using the same seed.

1. Model Naive Bayes

```{r include=FALSE}
library(e1071)
library(naivebayes)
```

```{r}
set.seed(825)
nb <- train(Class ~ ., 
            data=data_training, 
            method="naive_bayes",
            trControl=fitControl)
nb
```

2. Model Decision Tree

```{r include=FALSE}
library(rpart)
```

```{r}
set.seed(825)
dt <- train(Class ~ ., 
            data=data_training, 
            method="rpart2",
            trControl=fitControl)
dt
```

3. Model Neural Network

```{r include=FALSE}
library(nnet)
```

```{r}
set.seed(825)
nn <- train(Class ~ ., 
            data=data_training, 
            method="nnet",
            trControl=fitControl)
nn
```

4. Model Nearest Neighbour

```{r}
set.seed(825)
knn <- train(Class ~ ., 
             data=data_training, 
             method="knn",
             trControl=fitControl)
knn
```

5. Model SVM (linear kernel)

```{r include=FALSE}
library(kernlab)
```

```{r}
set.seed(825)
svm <- train(Class ~ ., 
             data=data_training, 
             method="svmLinear",
             trControl=fitControl)
svm
```

Collect the results for all the models.

```{r}
resamps <- resamples(list("Naive Bayes"=nb,
                          "Decision Tree"=dt,
                          "Neural Network"=nn,
                          "Nearest Neighbour"=knn,
                          "SVM (linear kernel)"=svm))
summary(resamps)
```

Complete the following table with the final values of accuracy and kappa for the training data:

### Question 4
Apply the models: Naive Bayes, Decision Tree, Neural Networks, Nearest Neighbour and SVM (linear kernel) to the data testing dataset. Print the confusion matrix of each model.

1. Model Naive Bayes

```{r}
nbPredict <- predict(nb, newdata=data_testing)
confusionMatrix(nbPredict, data_testing$Class)
```

2. Model Decision Tree

```{r}
dtPredict <- predict(dt, newdata=data_testing)
confusionMatrix(dtPredict, data_testing$Class)
```

3. Model Neural Network

```{r}
nnPredict <- predict(nn, newdata=data_testing)
confusionMatrix(nnPredict, data_testing$Class)
```

4. Model Nearest Neighbour

```{r}
knnPredict <- predict(knn, newdata=data_testing)
confusionMatrix(knnPredict, data_testing$Class)
```

5. Model SVM (linear kernel)

```{r}
svmPredict <- predict(svm, newdata=data_testing)
confusionMatrix(svmPredict, data_testing$Class)
```

Calculate the AUC value for all the models.

```{r include=FALSE}
library(AUC)
```

```{r}
auc(roc(nbPredict, data_testing$Class))
auc(roc(dtPredict, data_testing$Class))
auc(roc(nnPredict, data_testing$Class))
auc(roc(knnPredict, data_testing$Class))
auc(roc(svmPredict, data_testing$Class))
```

Complete the following table with the final values of accuracy, kappa and AUC for the testing data. 

### Question 5
Plot the ROC curves of the models.
```{r include=FALSE}
library(ROCR)
```

a) Calculate again the predictions on the test set but now setting the type parameter of the predict function to "prob".

1. Model Naive Bayes

```{r}
nbPredictProb <- predict(nb, newdata=data_testing, type = "prob")
head(nbPredictProb)
```

2. Model Decision Tree

```{r}
dtPredictProb <- predict(dt, newdata=data_testing, type = "prob")
head(dtPredictProb)
```

3. Model Neural Network

```{r}
nnPredictProb <- predict(nn, newdata=data_testing, type = "prob")
head(nnPredictProb)
```

4. Model Nearest Neighbour

```{r}
knnPredictProb <- predict(knn, newdata=data_testing, type = "prob")
head(knnPredictProb)
```

5. Model SVM (linear kernel)

```{r}
svmPredictProb <- predict(svm, newdata=data_testing, type = "prob")
head(svmPredictProb)
```

b) Construct a "prediction" object for each classifier using the vector of estimated probabilities for the positive class as the first parameter, and the vector of actual class labels as the second parameter.

1. Model Naive Bayes

```{r}
nbPred <- prediction(nbPredictProb$positive, data_testing$Class)   
```

2. Model Decision Tree

```{r}
dtPred <- prediction(dtPredictProb$positive, data_testing$Class)   
```

3. Model Neural Network

```{r}
nnPred <- prediction(nnPredictProb$positive, data_testing$Class)   
```

4. Model Nearest Neighbour

```{r}
knnPred <- prediction(knnPredictProb$positive, data_testing$Class)   
```

5. Model SVM (linear kernel)

```{r}
svmPred <- prediction(svmPredictProb$positive, data_testing$Class)   
```

c) Calculate the measures we want to plot on the y-axis (TPR) and on the x-axis (FPR) by using the performance function.

1. Model Naive Bayes

```{r}
nbPerf <- performance(nbPred, "tpr", "fpr")
```

2. Model Decision Tree

```{r}
dtPerf <- performance(dtPred, "tpr", "fpr")
```

3. Model Neural Network

```{r}
nnPerf <- performance(nnPred, "tpr", "fpr")
```

4. Model Nearest Neighbour
```{r}
knnPerf <- performance(knnPred, "tpr", "fpr")
```

5. Model SVM (linear kernel)
```{r}
svmPerf <- performance(svmPred, "tpr", "fpr")
```

d) Draw all the curves in the same plot.

```{r}
plot(nbPerf, col="orange", add=FALSE, main="Curvas ROC")
plot(dtPerf, col="blue", add=TRUE, main="Curvas ROC")
plot(nnPerf, col="red", add=TRUE, main="Curvas ROC")
plot(knnPerf, col="green", add=TRUE, main="Curvas ROC")
plot(svmPerf, col="magenta", add=TRUE, main="Curvas ROC")
legend("bottomright", 
       legend = c("NB","DT", "NN", "kNN", "SVM"), 
       col = c("orange", "blue", "red", "green", "magenta"), 
       lty = 1, lwd = 1)
```