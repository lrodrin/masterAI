# 1.
data <- read.table("tic-tac-toe.data.txt", header=FALSE, sep=",")
names(data) <- c("top-left-square",
"top-middle-square",
"top-right-square",
"middle-left-square",
"middle-middle-square",
"middle-right-square",
"bottom-left-square",
"bottom-middle-square",
"bottom-right-square",
"Class")
# Make valid column names
colnames(data) <- make.names(colnames(data))
# Check for missing values
any(is.na(data))
# 2.
library(lattice)
library(ggplot2)
library(caret)
set.seed(123)
inTraining <- createDataPartition(data$Class, p=.7, list=FALSE)
data_training <- data[ inTraining,]
data_testing  <- data[-inTraining,]
#3.
# Specifiy the type of resampling
fitControl <- trainControl(method="repeatedcv",
number=10,
repeats=1,
classProbs=TRUE)
# Model Naive Bayes
library(e1071)
library(naivebayes)
set.seed(123)
nb <- train(Class ~ .,
data=data_training,
method="naive_bayes",
trControl=fitControl)
nb
# Model Decision Tree
library(rpart)
set.seed(123)
dt <- train(Class ~ .,
data=data_training,
method="rpart2",
trControl=fitControl)
dt
# Model Neural Network
library(nnet)
set.seed(123)
nn <- train(Class ~ .,
data=data_training,
method="nnet",
trControl=fitControl)
nn
# Model Nearest Neighbour
set.seed(123)
knn <- train(Class ~ .,
data=data_training,
method="knn",
trControl=fitControl)
knn
# Model SVM (linear kernel)
library(kernlab)
set.seed(123)
svm <- train(Class ~ .,
data=data_training,
method="svmLinear",
trControl=fitControl)
svm
# Collecting the training resampling results
resamps <- resamples(list("Naive Bayes"=nb,
"Decision Tree"=dt,
"Neural Network"=nn,
"Nearest Neighbour"=knn,
"SVM (linear kernel)"=svm))
summary(resamps)
setwd("~/masterAI/A3/PrÃ¡cticas en R/Unidad 2")
# 1.
data <- read.table("tic-tac-toe.data.txt", header=FALSE, sep=",")
names(data) <- c("top-left-square",
"top-middle-square",
"top-right-square",
"middle-left-square",
"middle-middle-square",
"middle-right-square",
"bottom-left-square",
"bottom-middle-square",
"bottom-right-square",
"Class")
# Make valid column names
colnames(data) <- make.names(colnames(data))
# Check for missing values
any(is.na(data))
# 2.
library(lattice)
library(ggplot2)
library(caret)
set.seed(123)
inTraining <- createDataPartition(data$Class, p=.7, list=FALSE)
data_training <- data[ inTraining,]
data_testing  <- data[-inTraining,]
#3.
# Specifiy the type of resampling
fitControl <- trainControl(method="repeatedcv",
number=10,
repeats=1,
classProbs=TRUE)
# Model Naive Bayes
library(e1071)
library(naivebayes)
set.seed(123)
nb <- train(Class ~ .,
data=data_training,
method="naive_bayes",
trControl=fitControl)
nb
# Model Decision Tree
library(rpart)
set.seed(123)
dt <- train(Class ~ .,
data=data_training,
method="rpart2",
trControl=fitControl)
dt
# Model Neural Network
library(nnet)
set.seed(123)
nn <- train(Class ~ .,
data=data_training,
method="nnet",
trControl=fitControl)
nn
# Model Nearest Neighbour
set.seed(123)
knn <- train(Class ~ .,
data=data_training,
method="knn",
trControl=fitControl)
knn
# Model SVM (linear kernel)
library(kernlab)
set.seed(123)
svm <- train(Class ~ .,
data=data_training,
method="svmLinear",
trControl=fitControl)
svm
# Collecting the training resampling results
resamps <- resamples(list("Naive Bayes"=nb,
"Decision Tree"=dt,
"Neural Network"=nn,
"Nearest Neighbour"=knn,
"SVM (linear kernel)"=svm))
summary(resamps)
