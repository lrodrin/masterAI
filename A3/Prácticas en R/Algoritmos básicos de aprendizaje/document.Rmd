---
title: 'Entregable D: Algoritmos básicos de aprendizaje'
author: "Laura Rodriguez Navas"
date: "Febrero 2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Los Datos

El fichero glass.data incluye el estudio de la clasificación de los tipos de vidrio con 6 variables explicativas. El estudio fue motivado por una investigación criminológica. En la escena de un crimen, el vidrio que queda puede usarse como evidencia ... ¡si se identifica correctamente!

Las variables que se guardaron son:

1. Id number: 1 to 214 
2. RI: refractive index 
3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10) 
4. Mg: Magnesium 
5. Al: Aluminum 
6. Si: Silicon 
7. K: Potassium 
8. Ca: Calcium 
9. Ba: Barium 
10. Fe: Iron 
11. Type of glass: (class attribute) 
- 1 building_windows_float_processed 
- 2 building_windows_non_float_processed 
- 3 vehicle_windows_float_processed 
- 4 vehicle_windows_non_float_processed (none in this database) 
- 5 containers 
- 6 tableware 
- 7 headlamps

Primero debemos cargar los datos como un data frame, nombrado glass, y le damos nombres a las columnas.

```{r}
library(caret)
library(rJava)
library(RWeka)
library(ggplot2)
library(ROCR)

glass <- read.table("glass.data", header = FALSE, sep = ",")
names(glass) <- c("Id number", "RI", "Na", "Mg", "Al", "Si", "K", "Ca", "Ba", "Fe",
                 "Type of glass")
colnames(glass) <- make.names(colnames(glass))
str(glass)
```

Observamos que la primera columna (cuyo nombre es "Id number") es redundante (denota el identidficador de cada instancia), por lo que se borrará. También le cambiaremos el nombre a la última columna (cuyo nombre es "Type of glass") para que se entienda mejor que respresenta a la variable clase. El resto son las variables predictoras.

```{r}
glass <- subset(glass, select = -Id.number)
colnames(glass)[10] <- "Class"
head(glass, 10)
```

Aunque a primera vista los datos parecen que estan ordenados por la columna Class, los ordenamos. Y miramos que no existan valores codificados como NA.

```{r}
glass <- glass[order(glass$Class), ]
any(is.na(glass))
```

Como se ha comentado anteriormente, la columna Class representa la variabla clase. Pero en este caso contamos con 6 variables explicativas. Para poder generar una representación binária seleccionaremos solo los elementos de la columna Class con los valores {1, 2}, les cambiaremos el nombre {1 = positive, 2 = negative} y factorizaremos la varible clase.

```{r}
glass <- subset(glass , glass$Class < 3)
for (i in 1:146) {
  if (glass$Class[i] == 1){
    glass$Class[i] <- 'positive'
  }
  else {
    glass$Class[i] <- 'negative'
  }
}
glass[,10]=as.factor(glass[,10])
str(glass)
```

## División de los datos en muestra de entrenamiento y de test

Tomaremos una muestra del 70% del conjunto de datos como entrenamiento, el 30% del mismo como un conjunto de prueba.

La validación cruzada 5 veces con muestreo estratificado se utiliza para dividir el conjunto de datos en conjuntos de entrenamiento y prueba. 

```{r}
set.seed(123)
inTraining <- createDataPartition(glass$Class, p = .7, list = FALSE)
training <- glass[ inTraining,]
testing  <- glass[-inTraining,]
fitControl <- trainControl(method = "cv", 
                           number = 5,
                           classProbs = FALSE)
str(training)
str(testing)
```

## Entrenamiento de los modelos

Se utilizarán 3 algoritmos de clasificación diferentes para predecir. Los modelos son: OneR, kNN y Multilayer Perceptrón.

1. OneR.

```{r}
oner <- train(Class ~ ., data = training,
              method = "OneR",
              trControl = fitControl)
oner
onerPredict <- predict(oner, newdata = testing)
cm_oner <- confusionMatrix(onerPredict, testing$Class)

onerPredictProb <- predict(oner, newdata = testing, type = "prob")
onerPred <- prediction(onerPredictProb$positive, testing$Class)
onerPerf <- performance(onerPred, "tpr", "fpr")
```

2. kNN con k=1, k=3 y con peso por distancia (tres configuraciones en total).

```{r}
grid_knn <- expand.grid(k = seq(1, 3))

knn <- train(Class ~ ., data = training,
              method = "knn",
              trControl = fitControl,
              tuneGrid = grid_knn)
knn

knnPredict <- predict(knn, newdata = testing)
cm_knn <- confusionMatrix(knnPredict, testing$Class)

knnPredictProb <- predict(knn, newdata = testing, type = "prob")
knnPred <- prediction(knnPredictProb$positive, testing$Class)
knnPerf <- performance(knnPred, "tpr", "fpr")
```

3. Multilayer Perceptrón con una sola capa oculta y 3, 5, y 7 unidades ocultas en la misma (tres configuraciones en total).

```{r}
grid_mlp = expand.grid(layer1 = 3,
                       layer2 = 5,
                       layer3 = 7)

mlp <- train(Class ~., data = training,
             method = "mlpML",
             trControl = fitControl,
             tuneGrid = grid_mlp)
mlp

mlpPredict <- predict(mlp, newdata = testing)
cm_mlp <- confusionMatrix(mlpPredict,testing$Class)

mlpPredictProb <- predict(mlp, newdata = testing, type = "prob")
mlpPred <- prediction(mlpPredictProb$positive, testing$Class)
mlpPerf <- performance(mlpPred, "tpr", "fpr")
```

## Resultados

```{r}
plot(onerPerf, col = "orange", add = FALSE)
plot(knnPerf, col = "blue", add = TRUE)
plot(mlpPerf, col = "black", add = TRUE)
title(main = "CURVAS ROC")
legend("bottomright", legend = c("OnerR", "kNN", "MLP"),
       col = c("orange", "blue", "black"),
       lty = 1, lwd = 1)
```