original <- c(1000, 800, 900, 1100, 900)
predicted <- predict(original)
new.cars <- data.frame(wt=c(1.7, 2.4, 3.6))
predict(Model, newdata=new.cars)
fit_1 <- lm(original, data = original)
fit_1 <- lm(original)
lm_kang <- lm(nose_length ~ nose_width, data=original)
original <- c(1000, 800, 900, 1100, 900)
lm_kang <- lm(nose_length ~ nose_width, data=original)
lm_original -> lm(data = original)
lm_original <- lm(data = original)
lm_original <- lm(original~1)
View(lm_original)
original <- c(1000, 800, 900, 1100, 900)
original
lm_original <- lm(original~1)
lm_original
lm_original[["residuals"]]
original = c(1000, 800, 900, 1100, 900)
original
lm_original <- lm(original~1)
predicted = c(60, -140, -40, 160, -40)
predicted
d = original-predicted
mse = mean((d)^2)
mae = mean(abs(d))
setwd("C:/Users/Laura/masterAI/A3/Proyecto Kaggle")
#predict
library(data.table)
data <- as.data.frame(fread("data.csv", header = TRUE, stringsAsFactors = TRUE))
##dropping unneeded variables
drops <- c("game_event_id", "game_id", "loc_x", "loc_y", "lat", "lon",
"shot_zone_area", "shot_zone_basic", "shot_zone_range",
"team_id", "team_name", "game_date", "matchup",
"minutes_remaining", "seconds_remaining")
cat("splitting data to train and test......\n")
train <- data[!is.na(data$shot_made_flag),]
test <- data[is.na(data$shot_made_flag),]
cat("precessing the train data......\n")
train$shot_made_flag <- as.factor(train$shot_made_flag)
outliers <- boxplot(train$shot_distance, plot=FALSE)$out
min(outliers)
#handle with the train features
train$shot_distance[train$shot_distance > 40] <- 40
train$time_remaining <- train$minutes_remaining * 60 + train$seconds_remaining
train <- train[ , !(names(train) %in% drops)]
#normalize function
myNormalize <- function (target) {
(target - min(target))/(max(target) - min(target))
}
train$shot_distance <- myNormalize(train$shot_distance)
train$time_remaining <- myNormalize(train$time_remaining)
train_dat <- data.frame(train$shot_distance, train$time_remaining, train$shot_made_flag)
colnames(train_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")
#handle with the test features
test$shot_distance[test$shot_distance > 40] <- 40
test$time_remaining <- test$minutes_remaining * 60 + test$seconds_remaining
test <- test[ , !(names(test) %in% drops)]
test$shot_distance <- myNormalize(test$shot_distance)
test$time_remaining <- myNormalize(test$time_remaining)
test_dat <- data.frame(test$shot_distance, test$time_remaining, test$shot_made_flag)
colnames(test_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")
#build model by train data
model <- glm(shot_made_flag~., data=train_dat, family = binomial(link = "logit"))
library(e1071)
wts=c(1,1)
names(wts)=c(1,0)
model <- svm(shot_made_flag~., data=train_dat, kernel="radial",  gamma=1, cost=1, class.weights=wts)
#anova(model)
# show accuracy by train data
# predict generates a vector of probabilities that we threshold at 0.5
newdata <- data.frame(train_dat[,-3])
pred <- predict(model, newdata, type = 'response')
confusionMatrix(pred, train_dat$shot_made_flag)
newdf <- data.frame(shot_id=train$shot_id, shot_made_flag=pred)
newdf$shot_made_flag <- myNormalize(newdf$shot_made_flag)
preds_th <- ifelse(as.numeric(pred) > 0.5,1,0)
# make the Confusion Matrix
cm <- table(newdf$shot_made_flag, preds_th)
accuracy <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
#model predict the test data
newdata <- data.frame(test_dat[,-3])
pred <- predict(model, newdata)
submission <- data.frame(shot_id=test$shot_id, shot_made_flag=pred)
submission$shot_made_flag <- myNormalize(submission$shot_made_flag)
cat("saving the submission file\n");
write.csv(submission, "glm.csv", row.names = FALSE)
newdf <- data.frame(shot_id=train$shot_id, shot_made_flag=pred)
newdf$shot_made_flag <- myNormalize(newdf$shot_made_flag)
preds_th <- ifelse(as.numeric(pred) > 0.5,1,0)
# make the Confusion Matrix
cm <- table(newdf$shot_made_flag, preds_th)
accuracy <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
#predict
library(data.table)
data <- as.data.frame(fread("data.csv", header = TRUE, stringsAsFactors = TRUE))
##dropping unneeded variables
drops <- c("game_event_id", "game_id", "loc_x", "loc_y", "lat", "lon",
"shot_zone_area", "shot_zone_basic", "shot_zone_range",
"team_id", "team_name", "game_date", "matchup",
"minutes_remaining", "seconds_remaining")
cat("splitting data to train and test......\n")
train <- data[!is.na(data$shot_made_flag),]
test <- data[is.na(data$shot_made_flag),]
cat("precessing the train data......\n")
train$shot_made_flag <- as.factor(train$shot_made_flag)
outliers <- boxplot(train$shot_distance, plot=FALSE)$out
min(outliers)
#handle with the train features
train$shot_distance[train$shot_distance > 40] <- 40
train$time_remaining <- train$minutes_remaining * 60 + train$seconds_remaining
train <- train[ , !(names(train) %in% drops)]
#normalize function
myNormalize <- function (target) {
(target - min(target))/(max(target) - min(target))
}
train$shot_distance <- myNormalize(train$shot_distance)
train$time_remaining <- myNormalize(train$time_remaining)
train_dat <- data.frame(train$shot_distance, train$time_remaining, train$shot_made_flag)
colnames(train_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")
#handle with the test features
test$shot_distance[test$shot_distance > 40] <- 40
test$time_remaining <- test$minutes_remaining * 60 + test$seconds_remaining
test <- test[ , !(names(test) %in% drops)]
test$shot_distance <- myNormalize(test$shot_distance)
test$time_remaining <- myNormalize(test$time_remaining)
test_dat <- data.frame(test$shot_distance, test$time_remaining, test$shot_made_flag)
colnames(test_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")
#build model by train data
model <- glm(shot_made_flag~., data=train_dat, family = binomial(link = "logit"))
anova(model)
# show accuracy by train data
# predict generates a vector of probabilities that we threshold at 0.5
newdata <- data.frame(train_dat[,-3])
pred <- predict(model, newdata, type = 'response')
newdf <- data.frame(shot_id=train$shot_id, shot_made_flag=pred)
newdf$shot_made_flag <- myNormalize(newdf$shot_made_flag)
preds_th <- ifelse(as.numeric(pred) > 0.5,1,0)
# make the Confusion Matrix
cm <- table(newdf$shot_made_flag, preds_th)
accuracy <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
newdata <- data.frame(test_dat[,-3])
pred <- predict(model, newdata)
submission <- data.frame(shot_id=test$shot_id, shot_made_flag=pred)
submission$shot_made_flag <- myNormalize(submission$shot_made_flag)
cat("saving the submission file\n");
write.csv(submission, "glm.csv", row.names = FALSE)
summary(data)
library(caret)
library(MASS)
library(randomForest)
data <- read.csv("data.csv", sep = "," , stringsAsFactors = FALSE)
cat("splitting data to train and test......\n")
train <- subset(data, !is.na(data$shot_made_flag))
test <- subset(data, is.na(data$shot_made_flag))
cat("precessing the train data......\n")
train$shot_made_flag <- as.factor(train$shot_made_flag)
train$shot_made_flag <- factor(train$shot_made_flag, levels = c("1", "0"))
#handle with the train features
train$shot_distance[train$shot_distance > 40] <- 40
train$time_remaining <- train$minutes_remaining*60 + train$seconds_remaining
#normalize function
myNormalize <- function (target) {
(target - min(target))/(max(target) - min(target))
}
train$shot_distance <- myNormalize(train$shot_distance)
train$time_remaining <- myNormalize(train$time_remaining)
#create subset of train to predict
train_dat <- data.frame(train$shot_distance, train$time_remaining, train$shot_made_flag)
colnames(train_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")
colnames(train_dat) <- make.names(colnames(train_dat))
train_dat <- train_dat[order(train_dat$shot_made_flag), ] # order by shot_made_flag
#handle with the test features
test$shot_distance[test$shot_distance > 40] <- 40
test$time_remaining <- test$minutes_remaining*60 + test$seconds_remaining;
test$shot_distance <- myNormalize(test$shot_distance)
test$time_remaining <- myNormalize(test$time_remaining)
#create subset of test to predict
test_dat <- data.frame(test$shot_distance, test$time_remaining, test$shot_made_flag)
colnames(test_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")
colnames(test_dat) <- make.names(colnames(test_dat))
#prediction
fitControl <- trainControl(method = "cv",
number = 5,
verboseIter = TRUE)
#build model by train data
lda <- train(shot_made_flag ~ .,
data=train_dat,
method="lda",
trControl=fitControl)
naive_bayes <- train(shot_made_flag ~ .,
data=train_dat,
method="naive_bayes",
trControl=fitControl)
rpart2 <- train(shot_made_flag ~ .,
data=train_dat,
method="rpart2",
trControl=fitControl)
nnet <- train(shot_made_flag ~ .,
data=train_dat,
method="nnet",
trControl=fitControl)
grid_knn <- expand.grid(k = seq(1, 3))
knn <- train(shot_made_flag ~ .,
data=train_dat,
method="knn",
trControl=fitControl, tuneGrid = grid_knn)
svmLinear <- train(shot_made_flag ~ .,
data=train_dat,
method="svmLinear",
trControl=fitControl)
OneR <- train(shot_made_flag ~ .,
data=train_dat,
method="OneR",
trControl=fitControl)
grid_mlp = expand.grid(layer1 = 3, layer2 = 5, layer3 = 7)
mlpML <- train(shot_made_flag ~ .,
data=train_dat,
method="mlpML",
trControl=fitControl, tuneGrid = grid_mlp)
rf <- train(shot_made_flag ~ .,
data=train_dat,
method="rf",
trControl=fitControl)
resamps <- resamples(list(
"LDA"=lda,
"Naive Bayes"=naive_bayes,
"Decision Tree"=rpart2,
"Neural Network"=nnet,
"Nearest Neighbour"=knn,
"SVM (linear kernel)"=svmLinear,
"Perceptron"=mlpML,
"Random Forest"=rf
))
View(resamps)
resamps[["metrics"]]
resamps[["metrics"]][1]
resamps
resamps[["values"]]
View(resamps[["values"]])
View(resamps[["values"]][1])
View(resamps[["values"]]["Accuracy"])
View(resamps[["values"]])
resamps[, 2:3:2]
resamps[, 2:3]
resamps[, 1]
resamps
View(resamps[["values"], 1])
View(resamps[["values"]]
)
resamps[["values"]][["LDA~Accuracy"]][["Naive Bayes~Accuracy"]][["Decision Tree~Accuracy"]][["Neural Network~Accuracy"]]
View(resamps[["values"]]
)
resamps[["values"], c("LDA~Accuracy")]
resamps[["values"]c("LDA~Accuracy")]
resamps[ , c(1, 7, 8)]
resamps[ , c(1)]
resamps[ , c(1)]
resamps[, 3:11, with=FALSE]
resamps[["values"]]
resamps[["values"], 1]
resamps[["values"][1]]
resamps[["values"]][[1]]
resamps[["values"]][[2]]
result
result <- summary(resamps)
View(result)
result[["values"]]
#show accuracy by train data
pred_lda <- pdredict(lda, train_dat)
pred_nn <- predict(naive_bayes, train_dat)
pred_dt <- predict(rpart2, train_dat)
pred_nnet <- predict(nnet, train_dat)
pred_knn <- predict(knn, train_dat)
pred_svm <- predict(svmLinear, train_dat)
pred_mlpML <- predict(mlpML, train_dat)
pred_rf <- predict(rf, train_dat)
confusionMatrix(pred_lda, train_dat$shot_made_flag)
pred_lda <- predict(lda, train_dat)
paste("Trainig_error =", trainig_error, "%")
confusionMatrix(pred_lda, train_dat$shot_made_flag)
cm_lda <- confusionMatrix(pred_lda, train_dat$shot_made_flag)
pred_lda <- predict(lda, train_dat)
pred_nn <- predict(naive_bayes, train_dat)
pred_dt <- predict(rpart2, train_dat)
pred_nnet <- predict(nnet, train_dat)
pred_knn <- predict(knn, train_dat)
pred_svm <- predict(svmLinear, train_dat)
pred_mlpML <- predict(mlpML, train_dat)
pred_rf <- predict(rf, train_dat)
trainig_error <- mean(train_dat$shot_made_flag != pred) * 100
paste("Trainig_error =", trainig_error, "%")
cm_lda <- confusionMatrix(pred_lda, train_dat$shot_made_flag)
cm_nn <- confusionMatrix(pred_nn, train_dat$shot_made_flag)
cm_dt <- confusionMatrix(pred_dt, train_dat$shot_made_flag)
cm_nnet <- confusionMatrix(pred_nnet, train_dat$shot_made_flag)
cm_knn <- confusionMatrix(pred_knn, train_dat$shot_made_flag)
cm_svm <- confusionMatrix(pred_svm, train_dat$shot_made_flag)
cm_mlpML <- confusionMatrix(pred_mlpML, train_dat$shot_made_flag)
cm_rf <- confusionMatrix(pred_rf, train_dat$shot_made_flag)
View(cm_dt)
resamps <- resamples(list(
"LDA"=cm_lda[["overall"]][["Accuracy"]],
"Naive Bayes"=cm_nn[["overall"]][["Accuracy"]],
"Decision Tree"=cm_dt[["overall"]][["Accuracy"]],
"Neural Network"=cm_nnet[["overall"]][["Accuracy"]],
"Nearest Neighbour"=cm_knn[["overall"]][["Accuracy"]],
"SVM (linear kernel)"=cm_svm[["overall"]][["Accuracy"]],
"Perceptron"=cm_mlpML[["overall"]][["Accuracy"]],
"Random Forest"=cm_rf[["overall"]][["Accuracy"]]
))
cm_lda <- confusionMatrix(pred_lda, train_dat$shot_made_flag)
cm_nn <- confusionMatrix(pred_nn, train_dat$shot_made_flag)
cm_dt <- confusionMatrix(pred_dt, train_dat$shot_made_flag)
cm_nnet <- confusionMatrix(pred_nnet, train_dat$shot_made_flag)
cm_knn <- confusionMatrix(pred_knn, train_dat$shot_made_flag)
cm_svm <- confusionMatrix(pred_svm, train_dat$shot_made_flag)
cm_mlpML <- confusionMatrix(pred_mlpML, train_dat$shot_made_flag)
cm_rf <- confusionMatrix(pred_rf, train_dat$shot_made_flag)
resamps <- resamples(list(
"LDA"=cm_lda[["overall"]][["Accuracy"]],
"Naive Bayes"=cm_nn[["overall"]][["Accuracy"]],
"Decision Tree"=cm_dt[["overall"]][["Accuracy"]],
"Neural Network"=cm_nnet[["overall"]][["Accuracy"]],
"Nearest Neighbour"=cm_knn[["overall"]][["Accuracy"]],
"SVM (linear kernel)"=cm_svm[["overall"]][["Accuracy"]],
"Perceptron"=cm_mlpML[["overall"]][["Accuracy"]],
"Random Forest"=cm_rf[["overall"]][["Accuracy"]]
))
pred_lda <- predict(lda, train_dat)
pred_nn <- predict(naive_bayes, train_dat)
pred_dt <- predict(rpart2, train_dat)
pred_nnet <- predict(nnet, train_dat)
pred_knn <- predict(knn, train_dat)
pred_svm <- predict(svmLinear, train_dat)
pred_mlpML <- predict(mlpML, train_dat)
pred_rf <- predict(rf, train_dat)
trainig_error <- mean(train_dat$shot_made_flag != pred) * 100
paste("Trainig_error =", trainig_error, "%")
cm_lda <- confusionMatrix(pred_lda, train_dat$shot_made_flag)
cm_nn <- confusionMatrix(pred_nn, train_dat$shot_made_flag)
cm_dt <- confusionMatrix(pred_dt, train_dat$shot_made_flag)
cm_nnet <- confusionMatrix(pred_nnet, train_dat$shot_made_flag)
cm_knn <- confusionMatrix(pred_knn, train_dat$shot_made_flag)
cm_svm <- confusionMatrix(pred_svm, train_dat$shot_made_flag)
cm_mlpML <- confusionMatrix(pred_mlpML, train_dat$shot_made_flag)
cm_rf <- confusionMatrix(pred_rf, train_dat$shot_made_flag)
resamps <- resamples(list(
"LDA"=cm_lda[["overall"]][["Accuracy"]],
"Naive Bayes"=cm_nn[["overall"]][["Accuracy"]],
"Decision Tree"=cm_dt[["overall"]][["Accuracy"]],
"Neural Network"=cm_nnet[["overall"]][["Accuracy"]],
"Nearest Neighbour"=cm_knn[["overall"]][["Accuracy"]],
"SVM (linear kernel)"=cm_svm[["overall"]][["Accuracy"]],
"Perceptron"=cm_mlpML[["overall"]][["Accuracy"]],
"Random Forest"=cm_rf[["overall"]][["Accuracy"]]
))
View(cm_rf)
cm_rf[["overall"]][["Accuracy"]]
resamps <- resamples(list(
"LDA"=cm_lda[["overall"]][["Accuracy"]],
"Naive Bayes"=cm_nn[["overall"]][["Accuracy"]],
"Decision Tree"=cm_dt[["overall"]][["Accuracy"]],
"Neural Network"=cm_nnet[["overall"]][["Accuracy"]],
"Nearest Neighbour"=cm_knn[["overall"]][["Accuracy"]],
"SVM (linear kernel)"=cm_svm[["overall"]][["Accuracy"]],
"Perceptron"=cm_mlpML[["overall"]][["Accuracy"]],
"Random Forest"= cm_rf[["overall"]][["Accuracy"]]
))
data("airports", package = "pnwflights14")
joined_worst <- inner_join(worst_arr_delays, airports, by = c("dest" = "faa")) %>%
select(name, dest, mean_arr_delay) %>%
rename("Airport Name" = name, "Airport Code" = dest, "Mean Arrival Delay" = mean_arr_delay)
kable(joined_worst)
kable(
cm_rf[["overall"]][["Accuracy"]], caption = 'A subset of mtcars.'
)
knitr::opts_chunk$set(echo = TRUE)
kable(
cm_rf[["overall"]][["Accuracy"]], caption = 'A subset of mtcars.'
)
smoke <- matrix(c(51,43,22,92,28,21,68,22,9),ncol=2,byrow=TRUE)
colnames(smoke) <- c("Model","Accuracy")
rownames(smoke) <- c("current","former","never")
smoke <- as.table(smoke)
smoke
smoke <- matrix(c(51,43,22,92,28,21,68,22,9),ncol=2,byrow=TRUE)
colnames(smoke) <- c("Model","Accuracy")
rownames(smoke) <- c("LDA", "Naive Bayes","Decision Tree", "Neural Network", "Nearest Neighbour",
"SVM (linear kernel)", "Multilayer Perceptron", "Random Forest")
smoke <- as.table(smoke)
smoke
smoke <- matrix(c(51,43,22,92,28,21,68,22,9),ncol=1,byrow=TRUE)
colnames(smoke) <- c("Accuracy")
rownames(smoke) <- c("LDA", "Naive Bayes","Decision Tree", "Neural Network", "Nearest Neighbour",
"SVM (linear kernel)", "Multilayer Perceptron", "Random Forest")
smoke <- as.table(smoke)
smoke
smoke <- matrix(c(cm_lda[["overall"]][["Accuracy"]], cm_nn[["overall"]][["Accuracy"]],
cm_dt[["overall"]][["Accuracy"]], cm_nnet[["overall"]][["Accuracy"]],
cm_knn[["overall"]][["Accuracy"]], cm_svm[["overall"]][["Accuracy"]],
cm_mlpML[["overall"]][["Accuracy"]], cm_rf[["overall"]][["Accuracy"]]),
ncol=1,byrow=TRUE)
colnames(smoke) <- c("Accuracy")
rownames(smoke) <- c("LDA", "Naive Bayes","Decision Tree", "Neural Network", "Nearest Neighbour",
"SVM (linear kernel)", "Multilayer Perceptron", "Random Forest")
smoke <- as.table(smoke)
smoke
library(e1071)
wts=c(1,1)
names(wts)=c(1,0)
model <- svm(shot_made_flag~., data=train_dat, kernel="radial",  gamma=1, cost=1, class.weights=wts)
newdata <- data.frame(train_dat[,-3])
pred <- predict(model, newdata, type = 'response')
confusionMatrix(pred, train_dat$shot_made_flag)
table <- matrix(c(cm_lda[["overall"]][["Accuracy"]], cm_nn[["overall"]][["Accuracy"]],
cm_dt[["overall"]][["Accuracy"]], cm_nnet[["overall"]][["Accuracy"]],
cm_knn[["overall"]][["Accuracy"]], cm_svm[["overall"]][["Accuracy"]],
cm_mlpML[["overall"]][["Accuracy"]], cm_rf[["overall"]][["Accuracy"]]),
ncol=1,byrow=TRUE)
colnames(table) <- c("Accuracy")
rownames(table) <- c("LDA", "Naive Bayes","Decision Tree", "Neural Network", "Nearest Neighbour",
"SVM (linear kernel)", "Multilayer Perceptron", "Random Forest")
table <- as.table(table)
table
table <- matrix(c(0.5972292, 0.6083590, 0.6099156, 0.6085924, 0.7203565, 0.5879675, 0.6076585, 0.8043351),
ncol=1,byrow=TRUE)
colnames(table) <- c("Accuracy")
rownames(table) <- c("LDA", "Naive Bayes","Decision Tree", "Neural Network", "Nearest Neighbour",
"SVM (linear kernel)", "Multilayer Perceptron", "Random Forest")
table <- as.table(table)
table
