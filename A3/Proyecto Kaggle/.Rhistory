cm_dt[["overall"]][["Accuracy"]],
cm_nnet[["overall"]][["Accuracy"]],
cm_svm[["overall"]][["Accuracy"]],
cm_mlpML[["overall"]][["Accuracy"]],
cm_glm[["overall"]][["Accuracy"]],
cm_rf[["overall"]][["Accuracy"]]),
ncol=1,byrow=TRUE)
colnames(table) <- c("Accuracy")
rownames(table) <- c("LDA",
"Decision Tree",
"Neural Network",
"SVM (linear kernel)",
"Multi-Layer Perceptron",
"Random Forest")
table <- as.table(table)
table
gen_some_data = function(n_obs = 50) {
x1 = seq(0, 10, length.out = n_obs)
x2 = runif(n = n_obs, min = 0, max = 2)
x3 = sample(c("A", "B", "C"), size = n_obs, replace = TRUE)
x4 = round(runif(n = n_obs, min = 0, max = 5), 1)
x5 = round(runif(n = n_obs, min = 0, max = 5), 0)
y = round(x1 ^ 2 + x2 ^ 2 + 2 * (x3 == "B") + rnorm(n = n_obs), 3)
data.frame(y, x1, x2, x3, x4, x5)
}
set.seed(42)
sim_trn = gen_some_data(n_obs = 500)
sim_tst = gen_some_data(n_obs = 5000)
sim_knn_mod = train(
y ~ .,
data = sim_trn,
method = "knn",
trControl = trainControl(method = "cv", number = 5),
# preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = seq(1, 31, by = 2))
)
sim_knn_mod$modelType
get_best_result(sim_knn_mod)
get_best_result = function(caret_fit) {
best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
best_result = caret_fit$results[best, ]
rownames(best_result) = NULL
best_result
}
get_best_result(sim_knn_mod)
gen_some_data = function(n_obs = 50) {
x1 = seq(0, 10, length.out = n_obs)
x2 = runif(n = n_obs, min = 0, max = 2)
x3 = sample(c("A", "B", "C"), size = n_obs, replace = TRUE)
x4 = round(runif(n = n_obs, min = 0, max = 5), 1)
x5 = round(runif(n = n_obs, min = 0, max = 5), 0)
y = round(x1 ^ 2 + x2 ^ 2 + 2 * (x3 == "B") + rnorm(n = n_obs), 3)
data.frame(y, x1, x2, x3, x4, x5)
}
set.seed(42)
sim_trn = gen_some_data(n_obs = 500)
sim_tst = gen_some_data(n_obs = 5000)
sim_knn_mod = train(
y ~ .,
data = sim_trn,
method = "rf",
trControl = trainControl(method = "cv", number = 5),
# preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = seq(1, 31, by = 2))
)
sim_knn_mod$modelType
get_best_result = function(caret_fit) {
best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
best_result = caret_fit$results[best, ]
rownames(best_result) = NULL
best_result
}
get_best_result(sim_knn_mod)
gen_some_data = function(n_obs = 50) {
x1 = seq(0, 10, length.out = n_obs)
x2 = runif(n = n_obs, min = 0, max = 2)
x3 = sample(c("A", "B", "C"), size = n_obs, replace = TRUE)
x4 = round(runif(n = n_obs, min = 0, max = 5), 1)
x5 = round(runif(n = n_obs, min = 0, max = 5), 0)
y = round(x1 ^ 2 + x2 ^ 2 + 2 * (x3 == "B") + rnorm(n = n_obs), 3)
data.frame(y, x1, x2, x3, x4, x5)
}
set.seed(42)
sim_trn = gen_some_data(n_obs = 500)
sim_tst = gen_some_data(n_obs = 5000)
sim_knn_mod = train(
y ~ .,
data = sim_trn,
method = "knn",
trControl = trainControl(method = "cv", number = 5),
# preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = seq(1, 31, by = 2))
)
sim_knn_mod$modelType
get_best_result = function(caret_fit) {
best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
best_result = caret_fit$results[best, ]
rownames(best_result) = NULL
best_result
}
get_best_result(sim_knn_mod)
sim_knn_mod = train(
shot_made_flag ~ .,
data = train_dat,
method = "knn",
trControl = trainControl(method = "cv", number = 5),
# preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = seq(1, 31, by = 2))
)
sim_knn_mod$modelType
get_best_result = function(caret_fit) {
best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
best_result = caret_fit$results[best, ]
rownames(best_result) = NULL
best_result
}
get_best_result(sim_knn_mod)
sim_knn_mod = train(
shot_made_flag ~ .,
data = train_dat,
method = "rf",
trControl = trainControl(method = "cv", number = 5),
# preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = seq(1, 31, by = 2))
)
sim_knn_mod$modelType
get_best_result = function(caret_fit) {
best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
best_result = caret_fit$results[best, ]
rownames(best_result) = NULL
best_result
}
get_best_result(sim_knn_mod)
sim_knn_mod = train(
shot_made_flag ~ .,
data = train_dat,
method = "rf",
trControl = trainControl(method = "cv", number = 5)
)
sim_knn_mod$modelType
get_best_result = function(caret_fit) {
best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
best_result = caret_fit$results[best, ]
rownames(best_result) = NULL
best_result
}
get_best_result(sim_knn_mod)
sim_knn_mod = train(
shot_made_flag ~ .,
data = train_dat,
method = "glm",
family="bonominal",
trControl = trainControl(method = "cv", number = 5)
)
sim_knn_mod = train(
shot_made_flag ~ .,
data = train_dat,
method = "glm",
family="binominal",
trControl = trainControl(method = "cv", number = 5)
)
sim_knn_mod = train(
shot_made_flag ~ .,
data = train_dat,
method = "glm",
trControl = trainControl(method = "cv", number = 5)
)
sim_knn_mod$modelType
get_best_result = function(caret_fit) {
best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
best_result = caret_fit$results[best, ]
rownames(best_result) = NULL
best_result
}
get_best_result(sim_knn_mod)
plot(submission)
plot(submission$shot_made_flag)
plot(model)
library(car)
scatterplotMatrix(x=train)
library(car)
scatterplotMatrix(x=train_dat)
library(car)
scatterplotMatrix(x=train_dat)
pca_attenu <- princomp(train, cor=TRUE)
pca_attenu
pca_attenu <- princomp(train, cor=TRUE)
pca_attenu <- princomp(train_dat, cor=TRUE)
pca_attenu
#predict
library(data.table)
data <- as.data.frame(fread("data.csv", header = TRUE, stringsAsFactors = TRUE))
##dropping unneeded variables
drops <- c("game_event_id", "game_id", "loc_x", "loc_y", "lat", "lon",
"shot_zone_area", "shot_zone_basic", "shot_zone_range",
"team_id", "team_name", "game_date", "matchup",
"minutes_remaining", "seconds_remaining")
cat("splitting data to train and test......\n")
train <- data[!is.na(data$shot_made_flag),]
test <- data[is.na(data$shot_made_flag),]
cat("precessing the train data......\n")
train$shot_made_flag <- as.factor(train$shot_made_flag)
outliers <- boxplot(train$shot_distance, plot=FALSE)$out
min(outliers)
#handle with the train features
train$shot_distance[train$shot_distance > 40] <- 40
train$time_remaining <- train$minutes_remaining * 60 + train$seconds_remaining
train <- train[ , !(names(train) %in% drops)]
#normalize function
myNormalize <- function (target) {
(target - min(target))/(max(target) - min(target))
}
train$shot_distance <- myNormalize(train$shot_distance)
train$time_remaining <- myNormalize(train$time_remaining)
train_dat <- data.frame(train$shot_distance, train$time_remaining, train$shot_made_flag)
colnames(train_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")
#handle with the test features
test$shot_distance[test$shot_distance > 40] <- 40
test$time_remaining <- test$minutes_remaining * 60 + test$seconds_remaining
test <- test[ , !(names(test) %in% drops)]
test$shot_distance <- myNormalize(test$shot_distance)
test$time_remaining <- myNormalize(test$time_remaining)
test_dat <- data.frame(test$shot_distance, test$time_remaining, test$shot_made_flag)
colnames(test_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")
#build model by train data
model <- glm(shot_made_flag~., data=train_dat, family = binomial(link = "logit"))
#anova(model)
# show accuracy by train data
# predict generates a vector of probabilities that we threshold at 0.5
newdata <- data.frame(train_dat[,-3])
pred <- predict(model, newdata, type = 'response')
newdf <- data.frame(shot_id=train$shot_id, shot_made_flag=pred)
newdf$shot_made_flag <- myNormalize(newdf$shot_made_flag)
preds_th <- ifelse(as.numeric(pred) > 0.5,1,0)
# make the Confusion Matrix
cm <- table(newdf$shot_made_flag, preds_th)
accuracy <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
#model predict the test data
newdata <- data.frame(test_dat[,-3])
pred <- predict(model, newdata)
submission <- data.frame(shot_id=test$shot_id, shot_made_flag=pred)
submission$shot_made_flag <- myNormalize(submission$shot_made_flag)
cat("saving the submission file\n");
write.csv(submission, "glm.csv", row.names = FALSE)
set.seed(934)
modFit<- train(wage ~ age + jobclass + education, method = "lm",data=training)
finMod <- modFit$finalModel
print(modFit)
set.seed(934)
modFit<- train(shot_made_flag ~ ., method = "lm",data=train)
finMod <- modFit$finalModel
print(modFit)
set.seed(934)
modFit<- train(shot_made_flag ~ ., method = "lm",data=train_dat)
finMod <- modFit$finalModel
print(modFit)
set.seed(934)
modFit<- train(shot_made_flag ~ ., method = "lm",data=train_dat)
finMod <- modFit$finalModel
layout(matrix(1:4, 2, 2))
plot(model)
SSE = sum(model$residuals^2)
SSE
cor(train_dat)
cor(train_dat$shot_made_flag)
SSE = sum((newdata$shot_made_flag - pred)^2)
SSE
summary(model.alt.2)
calc_class_err <- function(actual, predicted) {
mean(actual != predicted)
}
calc_class_err(actual = train_dat$shot_made_flag, predicted = pred)
calc_class_err <- function(actual, predicted) {
mean(actual != predicted)
}
calc_class_err(actual = train$shot_made_flag, predicted = pred)
library("caret")
confusionMatrix(submission, positive = "Yes")
library("caret")
confusionMatrix(pred, positive = "Yes")
#predict
library(data.table)
data <- as.data.frame(fread("data.csv", header = TRUE, stringsAsFactors = TRUE))
##dropping unneeded variables
drops <- c("game_event_id", "game_id", "loc_x", "loc_y", "lat", "lon",
"shot_zone_area", "shot_zone_basic", "shot_zone_range",
"team_id", "team_name", "game_date", "matchup",
"minutes_remaining", "seconds_remaining")
cat("splitting data to train and test......\n")
train <- data[!is.na(data$shot_made_flag),]
test <- data[is.na(data$shot_made_flag),]
cat("precessing the train data......\n")
train$shot_made_flag <- as.factor(train$shot_made_flag)
outliers <- boxplot(train$shot_distance, plot=FALSE)$out
min(outliers)
#handle with the train features
train$shot_distance[train$shot_distance > 40] <- 40
train$time_remaining <- train$minutes_remaining * 60 + train$seconds_remaining
train <- train[ , !(names(train) %in% drops)]
#normalize function
myNormalize <- function (target) {
(target - min(target))/(max(target) - min(target))
}
train$shot_distance <- myNormalize(train$shot_distance)
train$time_remaining <- myNormalize(train$time_remaining)
train_dat <- data.frame(train$shot_distance, train$time_remaining, train$shot_made_flag)
colnames(train_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")
#handle with the test features
test$shot_distance[test$shot_distance > 40] <- 40
test$time_remaining <- test$minutes_remaining * 60 + test$seconds_remaining
test <- test[ , !(names(test) %in% drops)]
test$shot_distance <- myNormalize(test$shot_distance)
test$time_remaining <- myNormalize(test$time_remaining)
test_dat <- data.frame(test$shot_distance, test$time_remaining, test$shot_made_flag)
colnames(test_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")
#build model by train data
model <- glm(shot_made_flag~., data=train_dat, family = binomial(link = "logit"))
#anova(model)
# show accuracy by train data
# predict generates a vector of probabilities that we threshold at 0.5
newdata <- data.frame(train_dat[,-3])
pred <- predict(model, newdata, type = 'response')
newdf <- data.frame(shot_id=train$shot_id, shot_made_flag=pred)
newdf$shot_made_flag <- myNormalize(newdf$shot_made_flag)
preds_th <- ifelse(as.numeric(pred) > 0.5,1,0)
# make the Confusion Matrix
cm <- table(newdf$shot_made_flag, preds_th)
accuracy <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
#model predict the test data
newdata <- data.frame(test_dat[,-3])
pred <- predict(model, newdata, type = "response")
submission <- data.frame(shot_id=test$shot_id, shot_made_flag=pred)
submission$shot_made_flag <- myNormalize(submission$shot_made_flag)
cat("saving the submission file\n");
write.csv(submission, "glm.csv", row.names = FALSE)
model
arova(model)
anova(model)
submission
ggplot(submission, aes(x=shot_id, y=shot_made_flag)) +
geom_point() +
geom_smooth() +
geom_abline(intercept=0, slope=1, size=0.5)  # reference line
mean((pred >= 0.5 & y==0) | (pred < 0.5 & y==1))
mean((pred >= 0.5 & shot_made_flag==0) | (pred < 0.5 & shot_made_flag==1))
summary(model)
pred
cor(data)
summary(model)
model <- glm(shot_made_flag~., data=train, family = binomial(link = "logit"))
summary(model)
model <- glm(shot_made_flag~shot_distance, data=train, family = binomial(link = "logit"))
summary(model)
train
summary(train)
model <- glm(shot_made_flag~shot_distance+action_type, data=train, family = binomial(link = "logit"))
summary(model)
model <- glm(shot_made_flag~shot_distance+period, data=train, family = binomial(link = "logit"))
summary(model)
model <- glm(shot_made_flag~shot_distance+period+playoffs, data=train, family = binomial(link = "logit"))
summary(model)
model <- glm(shot_made_flag~shot_distance+period+playoffs+time_remaining, data=train, family = binomial(link = "logit"))
summary(model)
model <- glm(shot_made_flag~shot_distance+period+playoffs+time_remaining
opponent, data=train, family = binomial(link = "logit"))
summary(model)
model <- glm(shot_made_flag~shot_distance+period+playoffs+time_remaining+
opponent, data=train, family = binomial(link = "logit"))
summary(model)
model <- glm(shot_made_flag~shot_distance+period+playoffs+time_remaining+
as.numeric(opponent), data=train, family = binomial(link = "logit"))
summary(model)
opponent <- as.numeric(train$opponent)
model <- glm(shot_made_flag~shot_distance+period+playoffs+time_remaining+
opponent, data=train, family = binomial(link = "logit"))
summary(model)
train$opponent <- as.numeric(train$opponent)
model <- glm(shot_made_flag~shot_distance+period+playoffs+time_remaining+
opponent, data=train, family = binomial(link = "logit"))
summary(model)
train$opponent <- as.numeric(train$opponent)
train$opponent <- as.numeric(train$opponent)
train$action_type <- as.numeric(train$action_type)
train$combined_shot_type <- as.numeric(train$combined_shot_type)
train$season <- as.numeric(train$season)
train$shot_type <- as.numeric(train$shot_type)
train$shot_id <- as.numeric(train$shot_id)
train$opponent <- as.numeric(train$opponent)
train$action_type <- as.numeric(train$action_type)
train$combined_shot_type <- as.numeric(train$combined_shot_type)
train$season <- as.numeric(train$season)
train$shot_type <- as.numeric(train$shot_type)
train$shot_id <- as.numeric(train$shot_id)
model <- glm(shot_made_flag~shot_distance+period+playoffs+time_remaining+
opponent+action_type+combined_shot_type+season+shot_type+shot_id
, data=train, family = binomial(link = "logit"))
summary(model)
exp(cbind(OR = coef(model), confint(model)))
#build model by train data
model <- glm(shot_made_flag~., data=train_dat, family = binomial(link = "logit"))
pred <- format(round(predict(model, newdata = test_dat, type = "response")))
#accuracy <- table(pred, df.test[,"admit"])
#sum(diag(accuracy))/sum(accuracy)
#table(pred, df.test$admit)
library(caret)
#confusionMatrix(data=pred, df.test$admit)
confusionMatrix(table(pred, test_dat$shot_made_flag))
pred <- format(round(predict(model, newdata = test_dat, type = "response")))
#accuracy <- table(pred, df.test[,"admit"])
#sum(diag(accuracy))/sum(accuracy)
#table(pred, df.test$admit)
library(caret)
#confusionMatrix(data=pred, df.test$admit)
confusionMatrix(table(pred, train$shot_made_flag))
model <- glm(shot_made_flag~shot_distance+period+playoffs+time_remaining+
opponent+action_type+combined_shot_type+season+shot_type+shot_id
, data=train, family = binomial(link = "logit"))
summary(model)
confint(object = model, level = 0.95 )
unlink('document_cache', recursive = TRUE)
setwd("C:/Users/Laura/masterAI/A3/Proyecto Kaggle")
library(tidyverse)
library(ggplot2)
##load data
tmp_data <- read_csv("data.csv")
##remove NA
tmp_data <- na.omit(tmp_data)
any(is.na(data))
##shot_type
ggplot() +
geom_point(data=data %>% filter(combined_shot_type=="Jump Shot"),
aes(x=lon, y=lat), colour="grey", alpha=0.3) +
geom_point(data=data %>% filter(combined_shot_type!="Jump Shot"),
aes(x=lon, y=lat, colour=combined_shot_type), alpha=0.8) +
labs(title="Shot type") +
ylim(c(33.7, 34.0883)) +
theme_void() +
theme(legend.title=element_blank(),
plot.title=element_text(hjust=0.5))
##accuracy by season
tmp_data %>%
group_by(season) %>%
summarise(Accuracy=mean(shot_made_flag)) %>%
ggplot(aes(x=season, y=Accuracy, group=1)) +
geom_line(aes(colour=Accuracy)) +
geom_point(aes(colour=Accuracy), size=3) +
scale_colour_gradient(low="orangered", high="chartreuse3") +
labs(title="Accuracy by season", x="Season") +
theme(legend.position="none",
plot.title=element_text(hjust=0.5),
axis.text.x=element_text(angle=45, hjust=1))
##shot_type
ggplot() +
geom_point(data=data %>% filter(combined_shot_type=="Jump Shot"),
aes(x=lon, y=lat), colour="grey", alpha=0.3) +
geom_point(data=data %>% filter(combined_shot_type!="Jump Shot"),
aes(x=lon, y=lat, colour=combined_shot_type), alpha=0.8) +
labs(title="Shot type") +
ylim(c(33.7, 34.0883)) +
theme_void() +
theme(legend.title=element_blank(),
plot.title=element_text(hjust=0.5))
p1 <- ggplot(tmp_data, aes(x=lon, y=lat)) +
geom_point(aes(color=shot_zone_range)) +
labs(title="Shot zone range") +
ylim(c(33.7, 34.0883)) +
theme_void() +
theme(legend.position="none",
plot.title=element_text(hjust=0.5))
# Frequency for each shot zone range
p2 <- ggplot(tmp_data, aes(x=fct_infreq(shot_zone_range))) +
geom_bar(aes(fill=shot_zone_range)) +
labs(y="Frequency") +
theme_bw() +
theme(axis.title.x=element_blank(),
legend.position="none")
# Subplot
grid.arrange(p1, p2, layout_matrix=cbind(c(1,2)))
p1 <- ggplot(tmp_data, aes(x=lon, y=lat)) +
geom_point(aes(color=shot_zone_range)) +
labs(title="Shot zone range") +
ylim(c(33.7, 34.0883)) +
theme_void() +
theme(legend.position="none",
plot.title=element_text(hjust=0.5))
p2 <- ggplot(tmp_data, aes(x=fct_infreq(shot_zone_range))) +
geom_bar(aes(fill=shot_zone_range)) +
labs(y="Frequency") +
theme_bw() +
theme(axis.title.x=element_blank(),
legend.position="none")
grid.arrange(p1, p2, layout_matrix=cbind(c(1,2)))
# Subplot
library("gridExtra")
grid.arrange(p1, p2, layout_matrix=cbind(c(1,2)))
summary(model)
ggplot(data = train_dat, aes(x = shot_distance, y = shot_made_flag)) +
geom_point(aes(color = as.factor(shot_made_flag)), shape = 1) +
geom_smooth(method = "glm",
method.args = list(family = "binomial"),
color = "gray20",
se = FALSE) +
theme_bw() +
theme(legend.position = "none")
ggplot(data = train_dat, aes(x = shot_made_flag, y = shot_distance)) +
geom_point(aes(color = as.factor(shot_made_flag)), shape = 1) +
geom_smooth(method = "glm",
method.args = list(family = "binomial"),
color = "gray20",
se = FALSE) +
theme_bw() +
theme(legend.position = "none")
