---
title: '**Kobe Bryant Shot Selection**'
subtitle: 'Proyecto Kaggle'
author: "Laura Rodríguez Navas"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# **Introducción**

Este trabajo lleva a cabo un proyecto completo de Ciencia de Datos donde vamos a analizar, transformar, modelar y evaluar un conjunto de datos de *Kaggle*. Concretamente, para este trabajo se ha usado un conjunto de datos que describe los aciertos y los fallos de lanzamientos a canasta del jugador de baloncesto Kobe Bryant durante los 20 años de su carrera en la NBA (https://www.kaggle.com/c/kobe-bryant-shot-selection/data/). 

El conjunto de datos contiene 30697 instancias y un gran número de variables explicativas (11 discretas y 14 numéricas). Estas 25 variables (incluyendo clase a predecir *“shot_made_flag”*) se centran en la descripción cualitativa y cuantitativa de multitud de aspectos de cada uno de los lanzamientos de Kobe Bryant.

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(ggplot2)
library(data.table)
library(gridExtra)
```


```{r message=FALSE, warning=FALSE, echo=FALSE}
data <- as.data.frame(fread("data.csv", header = TRUE, stringsAsFactors = TRUE))
example <-as.data.frame(fread("sample_submission.csv", header = TRUE, stringsAsFactors = TRUE))
str(data, width = 85, strict.width = "cut")
```

La tarea de este trabajo es predecir si los lanzamientos a canastas de Kobe Bryant entraron o no en el aro, es decir, los lanzamientos acertados (atributo *"shot_made_flag"*). Del conjunto de datos se han eliminado 5000 valores de este atributo (representados como valores faltantes). Estos datos estarán en el conjunto de evaluación (test) sobre el cual se realizará la predicción.

\newpage
Una vez descargados los datos, es necesario dividir el conjunto de datos en un conjunto de datos de entrenamiento y un conjunto de datos de evaluación (test). Para ello, primero analizamos la existencia de esos valores faltantes nombrados anteriormente (atributo *"shot_made_flag"*), que como hemos comentado serán los valores que tendremos que predecir y que estarán en el conjunto de datos de test pero no en el conjunto de datos de entrenamiento.

A continuación, podemos observar este proceso.

```{r message=FALSE, warning=FALSE}
train <- data[!is.na(data$shot_made_flag), ]
any(is.na(train))

```


```{r message=FALSE, warning=FALSE, echo=FALSE}
str(train$shot_made_flag)
```


```{r message=FALSE, warning=FALSE}
test <- data[is.na(data$shot_made_flag), ]
any(is.na(test))
```


```{r message=FALSE, warning=FALSE, echo=FALSE}
str(test$shot_made_flag)
```

Una vez dividido el conjunto de los datos, es necesario realizar un análisis del conjunto de datos, así como un proceso de exploración, transformación y limpieza de estos datos con el objetivo de resaltar información útil para la fase de modelado. Este análisis nos permitirá controlar la presencia de valores fuera de rango, una idea inicial de la forma que tienen los datos, etc. así como las relaciones entre los distintos atributos. Aunque para sintetizar el análisis realizado solo se comentará aquello que se ha considerado más interesante durante éste.

# **Exploración de datos**

```{r message=FALSE, warning=FALSE, include=FALSE}
tmp_data <- read_csv("data.csv")
tmp_data <- na.omit(tmp_data)
```

Empezamos analizando visualmente la variable de clase a predecir (atributo *"shot_made_flag"*), que es binaria y que se distribuye de manera bastante equitativa. Vemos que el número de canastas que no entraron en el aro es superior al número de canastas que sí que entraron. Así que, intentaremos averiguar si esto puede estar relacionado con la gran lesión que tuvo Kobe Bryant durante la temporada 2013-14.

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', out.width='60%'}
qplot(factor(shot_made_flag), data = tmp_data, geom = "bar",
  fill = factor(shot_made_flag, levels = c(0, 1))) +
  scale_fill_manual(values = c("darkblue", "darkgreen")) +
  labs(fill = "levels") + xlab("shot_made_flag") +
  ylab("count") + ggtitle("Distribución de la varaible clase") +
  theme_bw() + theme(plot.title = element_text(hjust = 0.5))
```

A continuación, analizamos visualmente la precisión de los lanzamientos realizados por temporada (atributo *"season"*), y vemos que a partir de la temporada 2013-14 la precisión de los lanzamientos baja drásticamente. ¿Así que, una gran cantidad de los lanzamientos que no entraron en el aro están correlacionados a la gran lesión que tuvo en la temporada 2013-14? Podría ser.

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', out.width='70%'}
tmp_data %>%
  group_by(season) %>%
  summarise(Accuracy=mean(shot_made_flag)) %>%
  ggplot(aes(x=season, y=Accuracy, group=1)) +
  geom_line(aes(colour=Accuracy)) +
  geom_point(aes(colour=Accuracy), size=3) +
  scale_colour_gradient(low="orangered", high="chartreuse3") +
  labs(title="Accuracy por temporada", x="Season") +
  theme(legend.position="none",
        plot.title=element_text(hjust=0.5),
        axis.text.x=element_text(angle=45, hjust=1)) 
```

En el siguiente gráfico analizamos visualmente la precisión de los lanzamientos respecto a la distancia de tiro (atributo *"shot_distance"*), porqué en diferentes exploraciones de datos que han realizado otros usuarios en *Kaggle*, se ha podido observar que el atributo *"shot_distance"* contiene valores fuera de rango que podríamos eliminar en el apartado de limpieza de datos y que nos sería muy beneficioso para reducir los fallos durante la predicción en base a la distancia de los lanzamientos. Los valores fuera de rango podrían encontrarse a partir de los lanzamientos realizados a más de 30 (ft.) ya que la precisión de estos baja drásticamente a partir de este punto.

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', out.width='70%'}
tmp_data %>%
  group_by(shot_distance) %>%
  summarise(Accuracy=mean(shot_made_flag)) %>%
  ggplot(aes(x=shot_distance, y=Accuracy)) + 
  geom_line(aes(colour=Accuracy)) +
  geom_point(aes(colour=Accuracy), size=2) +
  scale_colour_gradient(low="orangered", high="chartreuse3") +
  labs(title="Accuracy por distancia", x="Shot distance (ft.)") +
  xlim(c(0,45)) +
  theme_bw() +
  theme(legend.position="none",
        plot.title=element_text(hjust=0.5)) 
```

Y en siguiente grafico podemos observar la existencia de esos valores fuera de rango que estábamos buscando, en el conjunto de datos de entrenamiento. Y que valores exactamente se encuentran fuera de rango son a partir de 40 (ft.). Así que, en el apartado de limpieza de datos serán eliminados los valores del atributo *shot_distance* superiores a 40 (ft.).

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', out.width='70%'}
qplot(factor(shot_made_flag), shot_distance,  data = tmp_data, geom = "boxplot") +
  xlab("shot_made_flag") + ylab("shot_distance")
```

Anteriormente, hemos analizado visualmente la precisión de los lanzamientos por temporada, los lanzamientos respecto a la distancia y hemos encontrado valores fuera de rango en el conjunto de datos que tendremos que eliminar si queremos realizar una buena predicción de la variable clase *"shot_made_flag"*.

Al trabajar con un conjunto de datos real, debemos tener en cuenta el hecho de que algunos datos pueden faltar o estar dañados, por lo tanto, es crucial realizar los procesos de transformación y limpieza del conjunto de datos para obtener un buen ajuste del modelo y una mejor capacidad predictiva.

# **Transformación de datos**

La primera transformación que tenemos que realizar es la categorización del atributo *"shot_made_flag"*, porqué es la variable clase a predecir e inicialmente es de tipo entero.

```{r message=FALSE, warning=FALSE, echo=FALSE}
str(train$shot_made_flag)
train$shot_made_flag <- as.factor(train$shot_made_flag)
str(train$shot_made_flag)
```

Si nos fijamos en los atributos *"minutes_remaining"* y *"seconds_remaining"* podríamos realizar la segunda transformación sobre el conjunto de datos ya que la información que contienen la podríamos combinar, los minutos del atributo *"minutes_remaining"* los podríamos convertir a segundos y sumar-los con los segundos del atributo *"seconds_remaining"*. La nueva información combinada la guardaríamos en un nuevo atributo *"time_remaining"*. El proceso se muestra a continuación.

```{r message=FALSE, warning=FALSE}
train$time_remaining <- train$minutes_remaining * 60 + train$seconds_remaining
test$time_remaining <- test$minutes_remaining * 60 + test$seconds_remaining
```

El siguiente paso es normalizar los atributos *"time_remaining"* y *"shot_distance"*. También se hace al final con los valores de la variable clase *"shot_made_flag"*, ya que vamos a predecir probabilidades y se tiene que hacer la normalización antes del modelado.

Sabemos que vamos a predecir probabilidades por el fichero de ejemplo que nos facilita Kaggle.

```{r message=FALSE, warning=FALSE, echo=FALSE}
head(example, 5)
```

```{r message=FALSE, warning=FALSE}
normalize <- function (target) {
  (target - min(target))/(max(target) - min(target))
}
train$shot_distance <- normalize(train$shot_distance)
test$shot_distance <- normalize(test$shot_distance)
train$time_remaining <- normalize(train$time_remaining)
test$time_remaining <- normalize(test$time_remaining)
```

Solo normalizamos los atributos *"time_remaining"* y *"shot_distance"* porqué queremos investigar la relación entre los aciertos y los fallos con la distancia de los lanzamientos, durante el tiempo. Como lo sugiere el gráfico siquiente: cuando la distancia se hace mayor, la frequencia de lanzamiento disminuye.

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', out.width='60%'}
p1 <- ggplot(tmp_data, aes(x=lon, y=lat)) +
  geom_point(aes(color=shot_zone_range)) +
  labs(title="Shot zone range") +
  ylim(c(33.7, 34.0883)) +
  theme_void() +
  theme(legend.position="none",
        plot.title=element_text(hjust=0.5)) 

p2 <- ggplot(tmp_data, aes(x=fct_infreq(shot_zone_range))) + 
  geom_bar(aes(fill=shot_zone_range)) +
  labs(y="Frequency") +
  theme_bw() +
  theme(axis.title.x=element_blank(), 
        legend.position="none")

grid.arrange(p1, p2, layout_matrix=cbind(c(1,2)))
```

Todas las operaciones de transformación realizadas se han aplicado sobre el conjunto de datos de entrenamiento y el conjunto de datos de test.

# **Limpieza de datos**

Durante la limpieza de datos vamos a eliminar los valores fuera de rango que hemos encontrado durante la exploración del conjunto de datos y eliminaremos los atributos que hemos creído independendientes al modelado.

Comenzamos eliminando los valores fuera de rango, que como hemos visto anteriormente una buena opción es descartar los lanzamientos por distancia superiores a 40 (ft.). El proceso se muestra a continuación.

```{r message=FALSE, warning=FALSE}
train$shot_distance[train$shot_distance > 40] <- 40
test$shot_distance[test$shot_distance > 40] <- 40
```

Y creemos que las siguientes columnas pueden descartarse, con independencia de la variable clase.

```{r message=FALSE, warning=FALSE, include=FALSE}
drops <- c("game_event_id", "game_id", "loc_x", "loc_y", "lat", "lon",
           "shot_zone_area", "shot_zone_basic", "shot_zone_range",
           "team_id", "team_name", "game_date", "matchup",
           "minutes_remaining", "seconds_remaining")
```

- **game_event_id**. Independiente al modelado.
- **game_id**. Independiente al modelado.
- **loc_x**. Correlacionada con lat. 
- **loc_y**. Correlacionada con lon. 
- **lat**. Correlacionada con loc_x.
- **lon**. Correlacionada con loc_y. 
- **shot_zone_area**. Independiente al modelado.
- **shot_zone_basic**. Independiente al modelado.
- **shot_zone_range**. Independiente al modelado.
- **team_id**. Siempre es el mismo número.
- **team_name**. Siempre es el mismo valor: *LA Lakers*.
- **game_date**. Independiente al modelado.
- **matchup**. Los atributos *oponent* y *matchup* contienen básicamente la misma información. Nos quedamos solo con el atributo *oponente*.
- **minutes_remaining**. Hemos combinado sus valores en una nueva columna (*"time_remaining"*) que contiene la misma información. 
- **seconds_remaining**. Hemos combinado sus valores en una nueva columna (*"time_remaining"*) que contiene la misma información. 

Después de la limpieza los conjuntos de datos de entrenamiento y de test quedaron:

```{r message=FALSE, warning=FALSE, echo=FALSE}
train <- train[ , !(names(train) %in% drops)]
test <- test[ , !(names(test) %in% drops)]
str(train, width = 85, strict.width = "cut")
str(test, width = 85, strict.width = "cut")
```

Todas las operaciones de limpieza realizadas se han aplicado sobre el conjunto de datos de entrenamiento y el conjunto de datos de test.

# **Modelado**

Una vez se ha realizado la exploración, la transformación y la limpieza de los datos, pasamos a la fase del modelado. Crearemos dos nuevos conjuntos de datos sobre los conjuntos de datos de entrenamiento y el conjunto de datos de test con los atributos (*"time_remaining"* y *"shot_distance"*) y la variable de clase a predecir (*"shot_made_flag"*), que usaremos para hacer la predicción.

Los nuevos conjuntos de datos de entrenamiento y de test son:

```{r message=FALSE, warning=FALSE, echo=FALSE}
train_dat <- data.frame(train$shot_distance, train$time_remaining, train$shot_made_flag)
colnames(train_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")

test_dat <- data.frame(test$shot_distance, test$time_remaining, test$shot_made_flag)
colnames(test_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")
str(train_dat, width = 85, strict.width = "cut")
head(train_dat, 5)
str(test_dat, width = 85, strict.width = "cut")
head(test_dat, 5)
```

Se ha escogido un modelo de regresión logística ya que el resultado de la predicción será numérico y porqué la variable a predecir es binaria. La regresión logística generalizada, es un método de regresión que permite estimar la probabilidad de una variable cualitativa binaria, como la variable a predecir *"shot_made_flag"*, en función de alguna variable cuantitativa. Es importante tener en cuenta que, aunque la regresión logística permite clasificar, se trata de un modelo de regresión. Que además nos permite calcular la probabilidad de las variables dependientes para a cada una de las dos categorías en función del valor que adquiera la variable independiente.

Ejecutamos el modelado y obtenemos su resultado.

```{r}
model <- glm(shot_made_flag~., data=train_dat, family = binomial(link = "logit"))
summary(model)
```

En la tabla coeficientes, *shot_distance* es un atributo altamente significativo, con un p-valor bajísimo, lo que demuestra que será un atributo muy útil para predecir la variable (*shot_made_flag*).

# **Resultado**

Finalmente, realizamos la predicción sobre el conjunto de datos de test y guardamos el resultado en un fichero *.CSV" para la presentación del resultado en Kaggle. A continuación, vemos los primeros valores del resultado obtenido para tener una idea de como es el fichero que se ha subido.

```{r}
submission <- read.csv("glm.csv")
head(submission, 10)
```

# **Resultado en Kaggle**

![](submission.png)

La implementación que se ha utilizado se encuentra en el repositoria de *GitHub*: https://github.com/lrodrin/masterAI/tree/master/A3/Proyecto%20Kaggle

# **Conclusiones**

El resultado en Kaggle parece que es bueno. Realizar una técnica de regresión logística ha dado buenos resultados, aunque hay resultados mucho mejores en Kaggle con la aplicación de otros modelos. Un dato curioso es que muchos de los usuarios de Kaggle utilizaron el modelo XGBoost. Me pareció más entendedor y interesante utilizar un modelo de regresión logística.

Además de los buenos resultados en Kaggle y del análisis del conjunto de datos que me ayudó con la elección del modelo, la decisión de escoger el modelo de regresión logística también se basó en el hecho de que aún no había trabajado con una técnica de regresión durante la asignatura, así que me dio la posibilidad de investigar y aprender. Sobre todo, al hacer la evaluación del modelo. Es un modelo muy difícil evaluar. El trabajo se podría mejorar en este punto. 

Otra de las cosas que consideré complicada y que me costó mucho fue la selección de variables para la predicción. Había muchas opciones, al final seleccioné la que me pareció más simple y que reducía más el conjunto de datos con la selección de variables. Ya que como hemos visto en la asignatura la selección de variables es un proceso que también es crucial para una buena predicción.

Que el trabajo se haya desarrollado en Kaggle le ha dado una motivación extra.

## **Citas para fuentes usadas**

- Notebook en Kaggle de xvivancos (https://www.kaggle.com/xvivancos/kobe-bryant-shot-selection/).
- Notebook en Kaggle de khozzy (https://www.kaggle.com/khozzy/kobe-shots-show-me-your-best-model/).
- Notebook en Kaggle de dixhom (https://www.kaggle.com/dixhom/data-analysis-for-beginners/).