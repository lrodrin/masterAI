---
title: '**Kobe Bryant Shot Selection**'
subtitle: 'Proyecto Kaggle'
author: "Laura Rodríguez Navas"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# **Introducción**

Este trabajo lleva a cabo un proyecto completo de Ciencia de Datos donde vamos a analizar, transformar, modelar y evaluar un conjunto de datos de *Kaggle*. Concretamente, para este trabajo se ha usado un conjunto de datos que describe los aciertos y los fallos de lanzamientos a canasta del jugador de baloncesto Kobe Bryant durante los 20 años de su carrera en la NBA (https://www.kaggle.com/c/kobe-bryant-shot-selection/data/). 

El conjunto de datos contiene 30697 instancias y un gran número de variables explicativas (11 discretas y 14 numéricas). Estas 25 variables (incluyendo clase a predecir *“shot_made_flag”*) se centran en la descripción cualitativa y cuantitativa de multitud de aspectos de cada uno de los lanzamientos de Kobe Bryant.

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(ggplot2)
library(data.table)
library(gridExtra)
library(ModelMetrics)
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
data <- as.data.frame(fread("data.csv", header = TRUE, stringsAsFactors = TRUE))
example <-as.data.frame(fread("sample_submission.csv", header = TRUE, stringsAsFactors = TRUE))
str(data, width = 85, strict.width = "cut")
```

La tarea de este trabajo es predecir si los lanzamientos a canastas de Kobe Bryant entraron o no en el aro, es decir, los lanzamientos acertados (atributo *"shot_made_flag"*). Del conjunto de datos se han eliminado 5000 valores de este atributo (representados como valores faltantes). Estos datos estarán en el conjunto de evaluación (test) sobre el cual se realizará la predicción.

\newpage
Una vez descargados los datos, es necesario dividir el conjunto de datos en un conjunto de datos de entrenamiento y un conjunto de datos de evaluación (test). Para ello, primero analizamos la existencia de esos valores faltantes nombrados anteriormente (atributo *"shot_made_flag"*), que serán los valores que tendremos que predecir y que estarán en el conjunto de datos de test pero no en el conjunto de datos de entrenamiento.

```{r message=FALSE, warning=FALSE}
train <- data[!is.na(data$shot_made_flag), ]
any(is.na(train))

```

```{r message=FALSE, warning=FALSE, echo=FALSE}
str(train$shot_made_flag)
```

```{r message=FALSE, warning=FALSE}
test <- data[is.na(data$shot_made_flag), ]
any(is.na(test))
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
str(test$shot_made_flag)
```

Una vez dividido el conjunto de los datos, es necesario realizar un análisis del conjunto de datos, así como un proceso de exploración, transformación y limpieza de estos datos con el objetivo de resaltar información útil para la fase de modelado. Este análisis nos permitirá controlar la presencia de valores fuera de rango, una idea inicial de la forma que tienen los datos, etc. así como las relaciones entre los distintos atributos. Aunque para sintetizar el análisis realizado solo se comentará aquello que se ha considerado más interesante durante éste.

# **Exploración, Limpieza y Transformación**

```{r message=FALSE, warning=FALSE, include=FALSE}
tmp_data <- read_csv("data.csv")
tmp_data <- na.omit(tmp_data)
```

Empezamos analizando visualmente la variable de clase a predecir (atributo *"shot_made_flag"*), que es binaria y que se distribuye de manera bastante equitativa. Vemos que el número de canastas que no entraron en el aro es superior al número de canastas que sí que entraron. Así que, intentaremos averiguar si esto puede estar relacionado con la gran lesión que tuvo Kobe Bryant durante la temporada 2013-14.

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', out.width='60%'}
qplot(factor(shot_made_flag), data = tmp_data, geom = "bar",
  fill = factor(shot_made_flag, levels = c(0, 1))) +
  scale_fill_manual(values = c("darkblue", "darkgreen")) +
  labs(fill = "levels") + xlab("shot_made_flag") +
  ylab("count") + ggtitle("Distribución de la varaible clase") +
  theme_bw() + theme(plot.title = element_text(hjust = 0.5))
```

A continuación, analizamos visualmente la precisión de los lanzamientos realizados por temporada (atributo *"season"*), y vemos que a partir de la temporada 2013-14 la precisión de los lanzamientos baja drásticamente. ¿Así que, una gran cantidad de los lanzamientos que no entraron en el aro podrían estar relacionados con la gran lesión que tuvo Kobe Bryant en la temporada 2013-14? Seguramente que sí.

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', out.width='70%'}
tmp_data %>%
  group_by(season) %>%
  summarise(Accuracy=mean(shot_made_flag)) %>%
  ggplot(aes(x=season, y=Accuracy, group=1)) +
  geom_line(aes(colour=Accuracy)) +
  geom_point(aes(colour=Accuracy), size=3) +
  scale_colour_gradient(low="orangered", high="chartreuse3") +
  labs(title="Accuracy por temporada", x="Season") +
  theme(legend.position="none",
        plot.title=element_text(hjust=0.5),
        axis.text.x=element_text(angle=45, hjust=1)) 
```

En el siguiente gráfico analizamos visualmente la precisión de los lanzamientos respecto a la distancia del tiro (atributo *"shot_distance"*), porqué nos hemos fijado que diferentes exploraciones de datos que han realizado otros usuarios en *Kaggle*, se ha podido observar que el atributo *"shot_distance"* contiene valores fuera de rango que podríamos eliminar y que nos sería muy beneficioso para reducir los fallos durante la predicción. Los valores fuera de rango podrían encontrarse a partir de los lanzamientos realizados a más de 30 (ft.) ya que la precisión de baja drásticamente a partir de este punto.

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', out.width='70%'}
tmp_data %>%
  group_by(shot_distance) %>%
  summarise(Accuracy=mean(shot_made_flag)) %>%
  ggplot(aes(x=shot_distance, y=Accuracy)) + 
  geom_line(aes(colour=Accuracy)) +
  geom_point(aes(colour=Accuracy), size=2) +
  scale_colour_gradient(low="orangered", high="chartreuse3") +
  labs(title="Accuracy por distancia", x="Shot distance (ft.)") +
  xlim(c(0,45)) +
  theme_bw() +
  theme(legend.position="none",
        plot.title=element_text(hjust=0.5)) 
```

Y en el siguiente grafico podemos observar la existencia de esos valores fuera de rango que estábamos buscando. Los valores que exactamente se encuentran fuera de rango se producen cuando el lanzamiento se realiza a una distancia superior a 40 (ft.). Así que, más adelante serán eliminados los valores del atributo *shot_distance* superiores a 40 (ft.).

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', out.width='70%'}
qplot(factor(shot_made_flag), shot_distance,  data = tmp_data, geom = "boxplot") +
  xlab("shot_made_flag") + ylab("shot_distance")
```

Hemos realizado una pequeña exploración de los datos donde hemos analizado visualmente la precisión de los lanzamientos por temporada, los lanzamientos respecto a la distancia y hemos encontrado valores fuera de rango en el conjunto de datos que tendremos que eliminar si queremos realizar una buena predicción de la variable clase *"shot_made_flag"*.

Al trabajar con un conjunto de datos real y con muchos atributos, debemos tener en cuenta el hecho de que algunos datos pueden faltar o estar dañados, por lo tanto, es crucial realizar los procesos de transformación y limpieza del conjunto de datos para obtener un buen ajuste del modelo y una mejor capacidad predictiva.

## **Limpieza**

En la limpieza de datos primero eliminamos los atributos que hemos creído independendientes al modelado. Los atributos que pueden descartarse son:

```{r message=FALSE, warning=FALSE, include=FALSE}
drops <- c("game_event_id", "game_id", "loc_x", "loc_y", "lat", "lon",
           "shot_zone_area", "shot_zone_basic", "shot_zone_range",
           "team_id", "team_name", "game_date", "matchup")
```

- **game_event_id**. Independiente al modelado.
- **game_id**. Independiente al modelado.
- **loc_x**. Correlacionada con lat. 
- **loc_y**. Correlacionada con lon. 
- **lat**. Correlacionada con loc_x.
- **lon**. Correlacionada con loc_y. 
- **shot_zone_area**. Independiente al modelado.
- **shot_zone_basic**. Independiente al modelado.
- **shot_zone_range**. Independiente al modelado.
- **team_id**. Siempre es el mismo número.
- **team_name**. Siempre es el mismo valor: *LA Lakers*.
- **game_date**. Independiente al modelado.
- **matchup**. Los atributos *oponent* y *matchup* contienen básicamente la misma información. Nos quedamos solo con el atributo *oponente*.

También eliminamos los valores fuera de rango, que como hemos visto anteriormente una buena opción seria descartar los lanzamientos realizados a una distancia superior a 40 (ft.). El proceso se muestra a continuación.

```{r message=FALSE, warning=FALSE}
train$shot_distance[train$shot_distance > 40] <- 40
test$shot_distance[test$shot_distance > 40] <- 40
```

\newpage
El conjunto de datos de entrenamiento y de test después de la limpieza quedan:

```{r message=FALSE, warning=FALSE, echo=FALSE}
train <- train[ , !(names(train) %in% drops)]
test <- test[ , !(names(test) %in% drops)]
str(train, width = 85, strict.width = "cut")
str(test, width = 85, strict.width = "cut")
```

Todas las operaciones de limpieza realizadas se han aplicado sobre el conjunto de datos de entrenamiento y el conjunto de datos de test.

## **Transformación**

La primera transformación que tenemos que realizar es la categorización del atributo *"shot_made_flag"*, porqué es la variable clase a predecir e inicialmente es de tipo entero.

```{r message=FALSE, warning=FALSE, echo=FALSE}
str(train$shot_made_flag)
train$shot_made_flag <- as.factor(train$shot_made_flag)
str(train$shot_made_flag)
```

Si nos fijamos en los atributos *"minutes_remaining"* y *"seconds_remaining"* podríamos realizar la segunda transformación sobre el conjunto de datos ya que la información que contienen la podríamos combinar, los minutos del atributo *"minutes_remaining"* los podríamos convertir a segundos y sumar-los con los segundos del atributo *"seconds_remaining"*. La nueva información combinada la guardaríamos en un nuevo atributo *"time_remaining"*. 

El proceso se muestra a continuación y al final los atributos *"minutes_remaining"* y *"seconds_remaining"* se eliminaran porqué contendrán información irrelevante al combinar los valores en *"time_remaining"*.

```{r message=FALSE, warning=FALSE}
train$time_remaining <- train$minutes_remaining * 60 + train$seconds_remaining
test$time_remaining <- test$minutes_remaining * 60 + test$seconds_remaining
train <- subset(train, select = -c(minutes_remaining, seconds_remaining))
test <- subset(test, select = -c(minutes_remaining, seconds_remaining))
```

\newpage
El siguiente paso es normalizar los atributos *"time_remaining"* y *"shot_distance"*. También se hace al final con los valores de la variable clase *"shot_made_flag"*, ya que vamos a predecir probabilidades. Sabemos que tenemos que predecir probabilidades por el fichero de ejemplo que nos facilita *Kaggle*.

```{r message=FALSE, warning=FALSE, echo=FALSE}
head(example, 5)
```

Procedemos con la normalización.

```{r message=FALSE, warning=FALSE}
normalize <- function (target) {
  (target - min(target))/(max(target) - min(target))
}
train$shot_distance <- normalize(train$shot_distance)
test$shot_distance <- normalize(test$shot_distance)
train$time_remaining <- normalize(train$time_remaining)
test$time_remaining <- normalize(test$time_remaining)
```

Solo normalizamos los atributos *"time_remaining"* y *"shot_distance"* porqué queremos investigar la relación entre los aciertos y los fallos con la distancia de los lanzamientos, durante más tiempo. Como lo sugiere el gráfico siguiente: cuando la distancia se hace mayor, la frequencia de lanzamiento disminuye.

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', out.width='70%'}
p1 <- ggplot(tmp_data, aes(x=lon, y=lat)) +
  geom_point(aes(color=shot_zone_range)) +
  labs(title="Shot zone range") +
  ylim(c(33.7, 34.0883)) +
  theme_void() +
  theme(legend.position="none",
        plot.title=element_text(hjust=0.5)) 

p2 <- ggplot(tmp_data, aes(x=fct_infreq(shot_zone_range))) + 
  geom_bar(aes(fill=shot_zone_range)) +
  labs(y="Frequency") +
  theme_bw() +
  theme(axis.title.x=element_blank(), 
        legend.position="none")

grid.arrange(p1, p2, layout_matrix=cbind(c(1,2)))
```

Todas las operaciones de transformación realizadas se han aplicado sobre el conjunto de datos de entrenamiento y el conjunto de datos de test.

# **Modelado y Evaluación**

Una vez se ha realizado la exploración, la transformación y la limpieza de los datos, pasamos a la fase del modelado. Crearemos dos nuevos conjuntos de datos sobre los conjuntos de datos de entrenamiento y el conjunto de datos de test con los atributos (*"time_remaining"* y *"shot_distance"*) y la variable de clase a predecir (*"shot_made_flag"*), que usaremos para hacer la predicción. Que como se ha comentado anteriormente, porqué queremos investigar la relación entre los aciertos y los fallos con la distancia de los lanzamientos, durante más tiempo.

\newpage
Los nuevos conjuntos de datos de entrenamiento y de test después de hacer esta selección de variables son:

```{r message=FALSE, warning=FALSE, echo=FALSE}
train_dat <- data.frame(train$shot_distance, train$time_remaining, train$shot_made_flag)
colnames(train_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")
train_dat <- train_dat[order(-train_dat$time_remaining),] 
test_dat <- data.frame(test$shot_distance, test$time_remaining, test$shot_made_flag)
colnames(test_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")
test_dat <- test_dat[order(-test_dat$time_remaining),] 
#str(train_dat, width = 85, strict.width = "cut")
head(train_dat, 5)
#str(test_dat, width = 85, strict.width = "cut")
head(test_dat, 5)
```

Para comprobar que ha sido una buena decisión, se han realizado todas las observaciones posibles de todos los atributos del conjunto de datos de entrenamiento con la variable clase *"shot_made_flag"*. Y hemos observado que parece existir diferencias entre los lanzamientos acertados y los no acertados con la distancia de estos. Así que, la variable escogida *"shot_distance"* puede ser un buen predictor. Lo podemos observar en el siguiente gráfico.

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', out.width='70%'}
ggplot(data = train_dat, aes(x = shot_made_flag, y = shot_distance, color = shot_made_flag)) +
  geom_boxplot() +
  geom_jitter(width = 0.1) +
  theme_bw() +
  theme(legend.position = "null")
```

El modelo final que se ha escogido es un modelo de regresión binominal (clasificación binaria) ya que la respuesta de la predicción debe que ser numérica y sabemos que la variable a predecir es categórica de 2 niveles binaria. 

La regresión logística, es un método de regresión que permite estimar la probabilidad de una variable cualitativa binaria, como la variable a predecir *"shot_made_flag"*, en función de alguna variable cuantitativa. Es importante tener en cuenta que, aunque la regresión logística permite clasificar, se trata de un modelo de regresión. Que además nos permite calcular la probabilidad de la variable dependiente para a cada una de las dos categorías en función del valor que adquiera la variable independiente.

\newpage
Generamos el modelo de regresión logística.

```{r message=FALSE, warning=FALSE}
model <- glm(shot_made_flag~., data=train_dat, family = binomial(link = "logit"))
summary(model)
```

A la hora de evaluar la validez y la calidad del modelo se utiliza la métrica *Accuracy* y *LogLoss* (score utilizado en Kaggle como evaluación). Para calcular *Accuracy* se va a utilizar un intervalo de 0.5. Es decir, si la probabilidad de que la variable *"shot_made_flag"* adquiera el valor 1 (acierto) es superior a 0.5, se asigna a este nivel, si es menor a 0.5 se asigna al nivel 0 (no acierto).

```{r message=FALSE, warning=FALSE}
newdata <- data.frame(train_dat[,-3])
pred <- predict(model, newdata, type = 'response')

newdf <- data.frame(shot_id=train$shot_id, shot_made_flag=pred)
normalize <- function (target) {
  (target - min(target))/(max(target) - min(target))
}
newdf$shot_made_flag <- normalize(newdf$shot_made_flag)
preds_th <- ifelse(as.numeric(pred) > 0.5,1,0)

# confusion matrix
cm <- table(newdf$shot_made_flag, preds_th)
accuracy <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
accuracy
loglogg <- logLoss(train_dat$shot_made_flag, pred)
loglogg
```

Con este modelo obtenemos un Accuracy de 0.9294118 y un valor de LogLoss de 0.8921015, lo cuan parece bastante bueno para realizar la predicción con él.

# **Resultado**

Una vez generado y evaluado el modelo se realiza la predicción para estimar los datos restantes no empleados como entrenamiento, y guardamos el resultado en un fichero *.CSV* para la presentación final del resultado en *Kaggle*. También se normaliza la variable a predecir final.

```{r message=FALSE, warning=FALSE}
newdata <- data.frame(test_dat[,-3])
pred <- predict(model, newdata, type = "response")
submission <- data.frame(shot_id=test$shot_id, shot_made_flag=pred)
normalize <- function (target) {
  (target - min(target))/(max(target) - min(target))
}
submission$shot_made_flag <- normalize(submission$shot_made_flag)
```

A continuación, vemos los primeros valores del resultado obtenido para tener una idea de como es el fichero que se ha subido.

```{r message=FALSE, warning=FALSE}
submission <- read.csv("glm.csv")
head(submission, 10)
```


# **Resultado en Kaggle**

![](submission.png){width=70%}

Diferentes implementaciones personales que se ha utilizado para el trabajo se encuentran en el repositorio de *GitHub*: https://github.com/lrodrin/masterAI/tree/master/A3/Proyecto%20Kaggle

# **Conclusiones**

El modelo creado para predecir la probabilidad de los lanzamientos acertados a partir de la distancia de estos durante más tiempo ha dado un LogLoss de 0.86488 en *Kaggle*, un valor mejor que el predicho sobre el conjunto de datos de entrenamiento, por tanto, mejor, pero muy parecido al calculado sobre el conjunto de datos de entrenamiento.

Realizar una técnica de regresión logística ha dado buenos resultados, aunque hay resultados mucho mejores en *Kaggle* con la aplicación de otros modelos. Un dato curioso es que muchos de los usuarios de *Kaggle* utilizan el modelo *XGBoost*. Es de mi opinión que el modelo de regresión logística es más entendedor y interesante ya que da muy buenos resultados pero que pocos usuarios lo han utilizado, y teóricamente es un buen candidato para este problema en concreto por sus características.

Además de los buenos resultados que el modelo da en *Kaggle* y del análisis del conjunto de datos, la decisión final de escoger el modelo de regresión logística también se basó en el hecho de que personalmente aún no había trabajado con una técnica de regresión logística durante la asignatura, así dio la posibilidad de investigar y aprender. 

Del resultado de la investigación del modelo de regresión logística se comprobó la gran dificultad de la evaluación de este tipo de modelos. Se evalúan de diferente manera a lo que se ha podido practicar en la asignatura, partir de desviaciones, coeficientes, diferentes métricas como p-value, etc. un proceso de evaluación mucho más complicado que en este trabajo no ha sido necesario desarrollar, ya que las realizamos una clasificación binaria.

## **Citas para fuentes usadas**

- Notebook en *Kaggle* de xvivancos (https://www.kaggle.com/xvivancos/kobe-bryant-shot-selection/).
- Notebook en *Kaggle* de khozzy (https://www.kaggle.com/khozzy/kobe-shots-show-me-your-best-model/).
- Notebook en *Kaggle* de dixhom (https://www.kaggle.com/dixhom/data-analysis-for-beginners/).