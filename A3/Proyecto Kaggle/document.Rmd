---
title: '**Kobe Bryant Shot Selection**'
author: "Laura Rodríguez Navas"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# **Introducción**

Este proyecto lleva a cabo un proyecto completo de Ciencia de Datos donde vamos a analizar, transformar, modelar y evaluar un conjunto de datos de Kaggle (https://www.kaggle.com/). Concretamente, para este proyecto se ha usado un conjunto de datos que describe los aciertos y fallos de lanzamientos a canasta del jugador de baloncesto Kobe Bryant durante 20 años de su carrera en la NBA (https://www.kaggle.com/c/kobe-bryant-shot-selection/data). 

El conjunto de datos contiene 30697 (25697 + 5000) instancias y un gran número de variables explicativas (11 discretas y 14 numéricas). Estas 25 variables (incluyendo clase a predecir *“shot_made_flag”*) se centran en la descripción cualitativa y cuantitativa de multitud de aspectos de cada uno de los lanzamientos de Kobe Bryant.

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(ggplot2)
library(data.table)
```


```{r message=FALSE, warning=FALSE, echo=FALSE}
data <- as.data.frame(fread("data.csv", header = TRUE, stringsAsFactors = TRUE))
str(data, width = 85, strict.width = "cut")
```

La tarea del proyecto es predecir si los lanzamientos a canastas de Kobe Bryant entraron o no en el aro (atributo *“shot_made_flag”*), es decir, los lanzamientos acertados. Del conjunto de datos se han eliminado 5000 valores de este atributo (representados como valores faltantes en el conjunto de datos). Estos datos serán el conjunto de prueba sobre el cual se realizará la predicción.

# **Exploración de datos**

```{r message=FALSE, warning=FALSE, include=FALSE}
tmp_data <- read_csv("data.csv")
tmp_data <- na.omit(tmp_data)
```

Empezamos analizando visualmente la variable de clase a predecir (atributo *"shot_made_flag"*). Podemos ver que la variable de clase se distribuye de manera bastante equitativa. No se realizará ninguna acción para tratar con el conjunto de datos desequilibrado.

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', out.width='50%'}
qplot(factor(shot_made_flag), data = tmp_data, geom = "bar",
  fill = factor(shot_made_flag, levels = c(0, 1))) +
  scale_fill_manual(values = c("darkblue", "darkgreen")) +
  labs(fill = "levels") + xlab("shot_made_flag") +
  ylab("count") + ggtitle("Distribución de la clase") +
  theme_bw() + theme(plot.title = element_text(hjust = 0.5))
```

A continuación, analizamos visualmente la precisión de los lanzamientos por temporada (atributo *"season"*). Observamos que a partir de la temporada 2013-2014 la precisión de los lanzamientos baja drásticamente. Así que, exploraremos las correlaciones de este período de tiempo con los atributos del conjunto de datos y la variable de clase a predecir.

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', out.width='70%'}
tmp_data %>%
  group_by(season) %>%
  summarise(Accuracy=mean(shot_made_flag)) %>%
  ggplot(aes(x=season, y=Accuracy, group=1)) +
  geom_line(aes(colour=Accuracy)) +
  geom_point(aes(colour=Accuracy), size=3) +
  scale_colour_gradient(low="orangered", high="chartreuse3") +
  labs(title="Accuracy por temporada", x="Season") +
  theme(legend.position="none",
        plot.title=element_text(hjust=0.5),
        axis.text.x=element_text(angle=45, hjust=1)) 
```

En el siguiente gráfico vemos visualmente que la precisión de los lanzamientos por distancia (atributo *"shot_distance"*) se correlaciona con la precisión de los lanzamientos por temporada. Es más, los lanzamientos realizados a más de 30 (ft.) los podríamos considerar como valores inusuales. En el apartado de selección de variables concretaremos que valores son con más exactitud y en el apartado de limpieza de datos serán eliminados.

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', out.width='70%'}
tmp_data %>%
  group_by(shot_distance) %>%
  summarise(Accuracy=mean(shot_made_flag)) %>%
  ggplot(aes(x=shot_distance, y=Accuracy)) + 
  geom_line(aes(colour=Accuracy)) +
  geom_point(aes(colour=Accuracy), size=2) +
  scale_colour_gradient(low="orangered", high="chartreuse3") +
  labs(title="Accuracy por distancia de lanzamiento", x="Shot distance (ft.)") +
  xlim(c(0,45)) +
  theme_bw() +
  theme(legend.position="none",
        plot.title=element_text(hjust=0.5)) 
```

Dividiremos el conjunto de datos en un conjunto de datos de entrenamiento y un conjunto de datos de evaluación (test). Para ello primero tenemos que analizar si existen valores faltantes y observamos que sí que existen valores faltantes dentro de la variable de clase a predecir (*"shot_made_flag"*). Concretamente, esos valores son los que tendremos que predecir en la evaluación. 

En este proyecto consideramos que para dividir el conjunto de datos en un conjunto de datos de entrenamiento y un conjunto de datos de test para realizar una mejor predicción, tenemos que crear un conjunto de datos de entrenamiento sin valores faltantes y un conjunto de datos de test con los valores faltantes que tenemos que queremos predecir.

```{r message=FALSE, warning=FALSE}
train <- data[!is.na(data$shot_made_flag), ]
any(is.na(train))
test <- data[is.na(data$shot_made_flag), ]
any(is.na(test))
```

Anteriormente, hemos analizado visualmente la precisión de los lanzamientos por temporada con los lanzamientos por distancia y hemos encontrado valores inusuales en el conjunto de datos que tendremos que eliminar si queremos realizar una buena predicción de la variable de clase *"shot_made_flag"*. Ahora, veremos que valores inusuales se encuentran primero en el conjunto de datos de entrenamiento y después en el conjunto de datos de test.

```{r message=FALSE, warning=FALSE, echo=FALSE}
outliers_train <- boxplot(train$shot_distance, plot=FALSE)$out
outliers_train
outliers_test <- boxplot(test$shot_distance, plot=FALSE)$out
outliers_test
```

Los valores inusuales los podemos directamente correlacionar con la falta de acierto de los lanzamientos superiores a 46 (ft.) y 49 (ft.).

```{r message=FALSE, warning=FALSE, echo=FALSE}
min(outliers_train)
min(outliers_test)
```

En el apartado de limpieza de datos seran eliminados.

# **Transformación de datos**

La primera transformación que realizamos es la binarización de la variable clase *"shot_made_flag"*. Factorizamos el atributo *"shot_made_flag"*, que inicialmente es de tipo entero.

```{r message=FALSE, warning=FALSE, echo=FALSE}
str(train$shot_made_flag)
train$shot_made_flag <- as.factor(train$shot_made_flag)
str(train$shot_made_flag)
```

Si nos fijamos en las columnas *"minutes_remaining"* y *"seconds_remaining"*, vemos que la información que contienen la podríamos combinar, los minutos del atributo *"minutes_remaining"* los podríamos convertir a segundos y sumar-los con los segundos del atributo*"seconds_remaining"*. La nueva información combinada la guardamos en una nueva columna denominada *"time_remaining"*. 

```{r message=FALSE, warning=FALSE}
train$time_remaining <- train$minutes_remaining * 60 + train$seconds_remaining
test$time_remaining <- test$minutes_remaining * 60 + test$seconds_remaining
```

A continuación, normalizaremos los atributos (*"time_remaining"* y *"shot_distance"*) que seleccionaremos para la predicción para que permitan la comparación en el conjunto de datos.

```{r message=FALSE, warning=FALSE}
normalize <- function (target) {
  (target - min(target))/(max(target) - min(target))
}
train$shot_distance <- normalize(train$shot_distance)
test$shot_distance <- normalize(test$shot_distance)
train$time_remaining <- normalize(train$time_remaining)
test$time_remaining <- normalize(test$time_remaining)
```

Todas las operaciones de transformación realizadas se han aplicado sobre el conjunto de datos de entrenamiento y el conjunto de datos de test.

# **Limpieza de datos**

Con la independencia de cada lanzamiento, las siguientes columnas pueden descartarse.

```{r message=FALSE, warning=FALSE, include=FALSE}
drops <- c("game_event_id", "game_id", "loc_x", "loc_y", "lat", "lon",
           "shot_zone_area", "shot_zone_basic", "shot_zone_range",
           "team_id", "team_name", "game_date", "matchup",
           "minutes_remaining", "seconds_remaining")
```

- **game_event_id**. Independiente al análisis.
- **game_id**. Independiente al análisis.
- **loc_x**. Correlacionada con lat. 
- **loc_y**. Correlacionada con lon. 
- **lat**. Correlacionada con loc_x.
- **lon**. Correlacionada con loc_y.
- **shot_zone_area**. Independiente al análisis.
- **shot_zone_basic**. Independiente al análisis.
- **shot_zone_range**. Independiente al análisis.
- **team_id**. Siempre es el mismo número.
- **team_name**. Siempre es el mismo valor: *LA Lakers*.
- **game_date**. Independiente al análisis.
- **matchup**. Los atributos oponent y matchup contienen básicamente la misma información. Solo se necesita oponente.
- **minutes_remaining**. Hemos combinado los valores en una nueva columna (*"time_remaining"*) que contiene la misma información. 
- **seconds_remaining**. Hemos combinado los valores en una nueva columna (*"time_remaining"*) que contiene la misma información. 

Después de la eliminación de estas columnas los conjuntos de datos de entrenamiento y test quedaron:

```{r message=FALSE, warning=FALSE, echo=FALSE}
train <- train[ , !(names(train) %in% drops)]
test <- test[ , !(names(test) %in% drops)]
str(train)
str(test)
```

Durante la limpieza de datos también eliminaremos los valores inusuales observados anteriormente en la exploración de datos. Observando esos valores, una buena opción es descartar los lanzamientos por distancia superiores a 40 (ft.).

```{r message=FALSE, warning=FALSE}
train$shot_distance[train$shot_distance > 40] <- 40
test$shot_distance[test$shot_distance > 40] <- 40
```

Todas las operaciones de limpieza realizadas se han aplicado sobre el conjunto de datos de entrenamiento y el conjunto de datos de test.

# **Modelado**

Una vez se ha realizado la exploración de los datos, incluyendo la transformación, la limpieza y la generación de nuevas variables interesantes, pasamos a la fase del modelado.

Volveremos a dividir el conjunto de datos en un nuevo conjunto de datos de entrenamiento y un nuevo conjunto de datos de evaluación con los atributos (*"time_remaining"* y *"shot_distance"*) y la variable de clase a predecir (*"shot_made_flag"*). Concretamente, esos valores son los que queremos predecir en la evaluación. Usaremos los conjuntos de datos que acabamos de obtener para el modelo final y la predicción.

```{r message=FALSE, warning=FALSE, echo=FALSE}
train_dat <- data.frame(train$shot_distance, train$time_remaining, train$shot_made_flag)
colnames(train_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")

test_dat <- data.frame(test$shot_distance, test$time_remaining, test$shot_made_flag)
colnames(test_dat) <- c("shot_distance", "time_remaining", "shot_made_flag")
head(train_dat)
head(test_dat)
```

Inicialmente al decidirnos por un modelo en concreto probamos diferentes modelos que hemos ido viendo durante la asignatura. A continuación, podemos observar una tabla con el valor de *Accuracy* de los modelos que se han probado. 

```{r message=FALSE, warning=FALSE, echo=FALSE}
table <- matrix(c(0.5972292, 0.6083590, 0.6099156, 0.6085924, 0.7203565, 0.5879675, 0.6076585, 0.8043351,
                  0.9294118), ncol=1,byrow=TRUE)
colnames(table) <- c("Accuracy")
rownames(table) <- c("LDA", "Naive Bayes","Decision Tree", "Neural Network", "Nearest Neighbour",
                     "SVM (linear kernel)", "Multilayer Perceptron", "Random Forest",  "GLM")
table <- as.table(table)
table
```

Como se observa en la tabla anterior, el mejor modelo es un modelo lineal generalizado con un valor de *Accuracy* de 0.9294118, el valor más alto. Concretamente, se trata del modelo binominal (distribución binomial).

```{r}
model <- glm(shot_made_flag~., data=train_dat, family = binomial(link = "logit"))
anova(model)
```

# **Evaluación**

Finalmente, predecimos sobre el el conjunto de datos de test y guardamos el resultado en un fichero *".CSV"* para la presentación de los resultados en Kaggle.

```{r message=FALSE, warning=FALSE, echo=FALSE}
newdata <- data.frame(test_dat[,-3])
pred <- predict(model, newdata)
submission <- data.frame(shot_id=test$shot_id, shot_made_flag=pred)
submission$shot_made_flag <- normalize(submission$shot_made_flag)
head(submission)
write.csv(submission, "glm.csv", row.names = FALSE)
```

# **Conclusiones**

# **Resultado de Kaggle**

![](submission.png)

## **Citas para fuentes usadas**

- Notebook en Kaggle de xvivancos https://www.kaggle.com/xvivancos/kobe-bryant-shot-selection/data#header.
- Notebook en Kaggle de khozzy https://www.kaggle.com/khozzy/kobe-shots-show-me-your-best-model.
- Notebook en Kaggle de dixhom https://www.kaggle.com/dixhom/data-analysis-for-beginners.