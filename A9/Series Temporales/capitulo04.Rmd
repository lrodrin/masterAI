---
author: "Laura Rodríguez Navas"
date: "`r format(Sys.time(), '%B, %Y')`"
documentclass: book
principal: yes
forprint: false
fontsize: 11pt
geometry: margin = 2.5cm
bibliography: bib/library.bib
metodobib: yes
biblio-style: plainnat
csl: methods-in-ecology-and-evolution.csl
link-citations: yes
output:
  pdf_document:
    keep_tex: no
    number_sections: yes
    citation_package: natbib
    fig_caption: yes
    template: latex/template.tex
  html_document: 
    toc: yes
    fig_caption: yes
---


```{r include=FALSE}
knitr::opts_chunk$set(
  fig.path = 'figurasR/',
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.pos = "H",
  fig.align = "center",
  out.width = "85%",
  cache = FALSE)
```

\ifdefined\ifprincipal
\else
\setlength{\parindent}{1em}
\pagestyle{fancy}
\setcounter{tocdepth}{4}
\tableofcontents

\fi

\ifdefined\ifdoblecara
\fancyhead{}{}
\fancyhead[LE,RO]{\scriptsize\rightmark}
\fancyfoot[LO,RE]{\scriptsize\slshape \leftmark}
\fancyfoot[C]{}
\fancyfoot[LE,RO]{\footnotesize\thepage}
\else
\fancyhead{}{}
\fancyhead[RO]{\scriptsize\rightmark}
\fancyfoot[LO]{\scriptsize\slshape \leftmark}
\fancyfoot[C]{}
\fancyfoot[RO]{\footnotesize\thepage}
\fi
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

# Aplicación del modelo ARIMA

Puesto que el entrenamiento del modelo de una serie temporal muy larga puede ser computacionalmente costoso, se filtran los datos de la serie para contemplar sólo desde el lunes 8 de junio hasta el domingo 14 de junio con un horizonte temporal de 4 horas. Para no modificar el conjunto de datos al añadir otra estacionalidad usaremos la función *msts()*, que al contrario que la función *ts()* que ya hemos usado, puede manejar diferentes estacionalidades de una misma serie temporal.

```{r}
ts <- data %>% filter(
  datetime >= as.POSIXct("2015-06-08 00:00:00", tz = "UTC"),
  datetime <= as.POSIXct("2015-06-14 23:50:00", tz = "UTC")
  ) %>%
  select(demand) %>%
  msts(seasonal.periods = c(24 * 60 / 10, 24 / 4)) # 10 minutos, 4 horas
```

Se utilizan los siguientes paquetes para la aplicación del modelo ARIMA:

```{r warning=FALSE}
library(tidyverse)
library(xts)
library(forecast)
library(tseries)
```

- [tseries](https://www.rdocumentation.org/packages/tseries/) es una librería para analizar series temporales.

## Transformación de la serie

El análisis previo del primer capítulo nos ha revelado que la serie no es estacionaria por su estacionalidad, y como el modelo que vamos a utilizar es un modelo ARIMA, necesitamos que la serie sea estacionaria. Para ello, tendremos que eliminar la estacionalidad de la serie, diferenciando la serie lograremos que se convierta en estacionaria. Para empezar la transformación de la serie, primero se observa que resultado devuelve la función *ndiffs()*, que calcula el número de diferenciaciones estacionales que se necesitan llevar a cabo para que la serie sea estacionaria.

```{r}
ndiffs(ts) 
```

El cálculo nos muestra que la serie necesita de una diferenciación estacional (d = 1). Con la función *diff()* eliminaremos la estacionalidad. Compararemos el resultado gráficamente, antes y después de eliminar la estacionalidad.

```{r}
tsstationary <- diff(ts, differences = 1)
plot(ts,  main = "Serie temporal con estacionalidad",
     ylab = "Demanda")
plot(tsstationary, main = "Serie temporal sin estacionalidad",
     ylab = "Demanda")
```

Como podemos ver se ha eliminado la componente de estacionalidad. Aunque ahora la serie tiene ruido, la serie se parece bastante a una serie estacionaria, ya que parece ser constante en media y varianza, pero para asegurarlo se aplica un test de estacionariedad como el test de Dickey-Fuller Aumentado *(Augmented Dickey-Fuller Test (ADF), en inglés)* y el test de Phillips–Perron (PP), una modificación del test de Dickey-Fuller. En estos tests, se considera que en la hipótesis nula se observan raíces unitarias en la serie, por tanto, no es estacionaria. Al contrario, la serie es estacionaria. Con un *p-value* inferior a 0.05, la hipótesis nula se rechaza, confirmando que la serie es estacionaria. 

El motivo de basarse en la observación de raíces unitarias es porqué una raíz unitaria, es una tendencia estocástica en la serie temporal. Algunas veces se le llama *"paseo aleatorio con deriva"*. Por tanto, si la serie tiene una raíz unitaria, ésta presenta un patrón sistemático que es impredecible. Entonces, una serie temporal es estacionaria si un cambio en el tiempo no cambia la forma de la distribución; y las raíces unitarias son una causa de no estacionalidad.

Primero se aplica el test de Dickey-Fuller Aumentado *adf.test* y después el test de PP.

```{r warning=FALSE}
adf.test(tsstationary)
```

Como se puede observar, después de transformar la serie, ahora sí es estacionaria; el *p-value* de 0.01, indica que rechazamos la hipótesis nula de no estacionalidad.

```{r warning=FALSE}
pp.test(tsstationary)
```

Con este test, también se obtiene un *p-value* de 0.01, por tanto, también rechazamos la hipótesis nula y podemos decir que la serie es estacionaria en su totalidad.

## Ajuste del modelo

Una vez que tenemos la serie transformada que satisface las condiciones del modelo ARIMA, para determinar el orden del modelo que se ajustará a la serie, se necesitan tres variables: *p*, *d* y *q*, que son enteros positivos que se refieren al orden de los componentes que forman el modelo: AutoReressive *(AR(p))*, Integrated *(I(d))* y Moving Average *(MA(q))*, respectivamente. Para identificar que valores de *p* y *q* serán apropiados, se necesita ejecutar las funciones *acf()* y *pacf()*.

*pacf()* en el retardo *k-éssimo* es la función de autocorrelación parcial que describe la correlación entre todos los puntos de la serie que están exactamente *k* instantes antes, después de tener en cuenta su correlación con la serie entre esos *k* instantes.

```{r}
acf(tsstationary, lag.max = 140, 
    main = "Autocorrelación de la serie temporal")
pacf(tsstationary, lag.max = 140,
    main = "Autocorrelación parcial de la serie temporal")
```

Vistas la figuras *acf()* y *pacf()* se pueden plantear varias soluciones para ajustar el modelo, como lo serían: ARIMA(0,1,2) o ARIMA(1,1,0), o realizando una combinación de componentes como ARIMA(1,1,2) o incluso solo variando algunos de los componentes como puede ser con ARIMA(1,1,1) o ARIMA(1,1,2) o ARIMA(0,1,1) o ARIMA(1,1,0), ... En este caso, el proceso de ajuste será un proceso recursivo y necesitaremos ejecutar la función *arima()* con diferentes valores (p, d, q) para encontrar el modelo más optimizado y eficiente.

```{r}

trainset <- subset(tsstationary, end = length(tsstationary) - (24 / 4))
testset <- subset(tsstationary, start = length(tsstationary) - (24 / 4) + 1)

arima.1 <- arima(trainset, order = c(0, 1, 2))
arima.2 <- arima(trainset, order = c(1, 1, 0))
arima.3 <- arima(trainset, order = c(1, 1, 2))
arima.4 <- arima(trainset, order = c(1, 1, 1))
arima.5 <- arima(trainset, order = c(1, 1, 2))
arima.6 <- arima(trainset, order = c(0, 1, 1))
arima.7 <- arima(trainset, order = c(1, 1, 0))
```

Cálculo del valor *AIC* para seleccionar el modelo más optimizado y eficiente.

```{r}
aic <- AIC(arima.1, arima.2, arima.3, arima.4, arima.5, arima.6, arima.7)
aic
```

Aquí se puede apreciar que el modelo que mejor AIC presenta es aquel que tienen un componente AutoReressive *(AR(p))*, un componente Integrated *(I(d))* y un componente Moving Average *(MA(q))*, siendo ARIMA(1, 1, 1) el modelo que el test arroja con un menor valor y por tanto con una mayor consideración. 

Una vez estimados diferentes modelos y elegido el mejor de ellos, en este caso ARIMA(1,1,1), se procede a validar el modelo con el test *Box-Ljung* para evaluar si los residuos que tiene son ruido blanco, ruido aleatorio que no es problemático para el modelo y no afectará a la futura predicción. 

```{r include=FALSE}
rm(
  list = c(
    "arima.1",
    "arima.2",
    "arima.3",
    "arima.5",
    "arima.6",
    "arima.7"
  )
)
```

El test de *Box-Ljung* es una prueba para comprobar si una serie de observaciones en un período de tiempo especifico son aleatorias o independientes en todos los retardos hasta el especificado. En lugar de probar la aleatoriedad en cada retardo distinto, prueba la aleatoriedad *"general"* basada en un número de retardos y, por lo tanto, es una prueba de comparación. Se aplica a los residuos de un modelo ARIMA ajustado, no a la serie original, y en tales aplicaciones, la hipótesis que se prueba es que los residuos del modelo ARIMA no tengan autocorrelación. Si los retardos no son independientes, un retardo puede estar relacionado con otros retardos de *k* unidades de tiempo por lo que la autocorrelacion puede reducir la exactitud del modelo predictivo y conducir a una interpretación errónea de los datos. La hipótesis ($H_{0}$) nula del test de *Box-Ljung* dice que los datos no son diferentes del "ruido blanco". Por lo tanto, los valores *p-value* pequeños indicarán residuos independientes.

\newpage

Se aplica el test de *Box-Ljung*:

```{r}
checkresiduals(arima.4)
```

En este caso, el valor de *p-value* está muy lejos de ser significativo (7.83e-11). Por lo tanto, no rechazamos la hipótesis nula de que los residuos se distribuyen aleatoriamente y se concluye que el modelo ARIMA, como se especifica, se ha ajustado correctamente.

## Predicción

```{r}
futurVal <- forecast(arima.4, 10)
plot(futurVal)
```

