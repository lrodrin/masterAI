---
author: "Laura Rodríguez Navas"
date: "`r format(Sys.time(), '%B, %Y')`"
documentclass: book
principal: yes
forprint: false
fontsize: 11pt
geometry: margin = 2.5cm
bibliography: bib/library.bib
metodobib: yes
biblio-style: plainnat
csl: methods-in-ecology-and-evolution.csl
link-citations: yes
output:
  pdf_document:
    keep_tex: no
    number_sections: yes
    citation_package: natbib
    fig_caption: yes
    template: latex/template.tex
  html_document: 
    toc: yes
    fig_caption: yes
---


```{r include=FALSE}
knitr::opts_chunk$set(
  fig.path = 'figurasR/',
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.pos = "H",
  fig.align = "center",
  out.width = "80%",
  cache = FALSE)
```

\ifdefined\ifprincipal
\else
\setlength{\parindent}{1em}
\pagestyle{fancy}
\setcounter{tocdepth}{4}
\tableofcontents

\fi

\ifdefined\ifdoblecara
\fancyhead{}{}
\fancyhead[LE,RO]{\scriptsize\rightmark}
\fancyfoot[LO,RE]{\scriptsize\slshape \leftmark}
\fancyfoot[C]{}
\fancyfoot[LE,RO]{\footnotesize\thepage}
\else
\fancyhead{}{}
\fancyhead[RO]{\scriptsize\rightmark}
\fancyfoot[LO]{\scriptsize\slshape \leftmark}
\fancyfoot[C]{}
\fancyfoot[RO]{\footnotesize\thepage}
\fi
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

# Aplicación del modelo ARIMA

Puesto que el entrenamiento del modelo de una serie temporal muy larga puede ser computacionalmente costoso, se filtran los datos de la serie para contemplar sólo desde el lunes 8 de junio hasta el domingo 14 de junio.

```{r}
ts <- data %>% filter(
  datetime >= as.POSIXct("2015-06-08 00:00:00", tz = "UTC"),
  datetime <= as.POSIXct("2015-06-14 23:50:00", tz = "UTC")
  ) %>%
  select(demand) %>%
  ts(frequency = 24 * 60 / 10)
```

Se utilizan los siguientes paquetes para la aplicación del modelo ARIMA:

```{r warning=FALSE}
library(tidyverse)
library(xts)
library(forecast)
library(tseries)
```

Las librerías *tidyverse*, *xts* y *forecast* se han usado anteriormente. En este capítulo se añade la librería *tseries.*

- [tseries](https://www.rdocumentation.org/packages/tseries/) es una librería para analizar series temporales.

## Transformación de la serie

El análisis previo del primer capítulo nos ha revelado que la serie temporal no es estacionaria por su estacionalidad, y como el modelo que vamos a utilizar para la predicción es un modelo ARIMA, necesitamos que la serie sea estacionaria. Para ello, tendremos que transformar la serie eliminando la estacionalidad. Diferenciando la serie lograremos que se convierta en estacionaria. Para empezar con la transformación de la serie, primero se observará el resultado de la función *ndiffs()*, que calcula el número de diferenciaciones estacionales que se necesitan llevar a cabo para que la serie sea estacionaria.

```{r}
ndiffs(ts) 
```

El respectivo cálculo muestra que la serie necesita de una diferenciación estacional. Para eliminar la estacionalidad se usa la función *diff()* que resta el componente estacional de la serie original y luego lo diferencia para que sea estacionario (varianza constante e independiente).

```{r}
tsstationary <- diff(ts, differences = 1)
plot(ts,  main = "Serie con estacionalidad", ylab = "Demanda")
plot(tsstationary, main = "Serie sin estacionalidad", ylab = "Demanda")
```

Como podemos ver ahora en la serie se ha eliminado la componente de estacionalidad. Aunque la serie parece tener ruido, que trataremos más adelante, se parece bastante a una serie estacionaria, ya que parece ser constante en media y varianza. Volvemos a visualizar la función de autocorrelación.

```{r}
acf(ts, main = "Autocorrelación con estacionalidad")
acf(tsstationary, main = "Autocorrelación sin estacionalidad")
```

Podemos apreciar que la serie ya es estacionaria una vez se ha eliminado la componente estacional. Para asegurarnos se aplica la prueba de estacionalidad como la prueba de Dickey-Fuller Aumentado *(Augmented Dickey-Fuller Test (ADF), en inglés) * y la prueba de Phillips–Perron (PP), una modificación del test de Dickey-Fuller. En estas pruebas, se considera que en la hipótesis nula $H_{0}$ se observan raíces unitarias en la serie, por tanto, no es estacionaria. Al contrario, la serie es estacionaria ($H_{1}$). Con un *p-value* inferior a 0.05 (significancia $\alpha$), la hipótesis nula $H_{0}$ se rechaza, confirmando que la serie es estacionaria.

El motivo de basarse en la observación de las raíces unitarias es porqué una raíz unitaria, es una tendencia estocástica en la serie temporal. Algunas veces se le llama *"paseo aleatorio con deriva"*. Y, por tanto, si la serie temporal tiene raíces unitarias, ésta presenta un patrón sistemático que es impredecible. Entonces, la serie temporal es estacionaria si un cambio en el tiempo no cambia la forma de la distribución, y las raíces unitarias son una causa de no estacionalidad.

Se aplica la prueba de Dickey-Fuller Aumentado:

```{r warning=FALSE}
adf.test(tsstationary)
```

El valor del *p-value* de 0.01, indica que rechazamos la hipótesis nula$H_{0}$, indicando que la serie es estacionaria. A continuación se aplica la prueba de PP:

```{r warning=FALSE}
pp.test(tsstationary)
```

El valor del *p-value* de 0.01, indica que también rechazamos la hipótesis nula$H_{0}$, indicando que la serie es estacionaria.

## Ajuste del modelo

Después de eliminar la estacionalidad y hacer que los datos sean estacionarios, se dividen los datos en un conjunto de entrenamiento y en un conjunto de prueba.

```{r}
trainset <- subset(tsstationary, 
                   end = length(tsstationary) - (24 * 60 / 10))
testset <- subset(tsstationary, 
                  start = length(tsstationary) - (24 * 60 / 10) + 1)
```

Una vez que tenemos los datos listos y han satisfecho todas las suposiciones del modelo ARIMA, para determinar el orden del modelo que se ajustará a los datos, necesitamos tres variables: $p$, $d$ y $q$ que son enteros positivos que se refieren al orden de las partes medias autorregresivas, integradas y móviles del modelo, respectivamente.

Para identificar que valores de $p$, $d$ y $q$ serán apropiados, se usa la función *auto.arima()*. La función calcula automáticamente cuál es la mejor combinación de órdenes para el modelo. Para ello, utiliza una combinación de pruebas de raíz unitaria, minimización de los valores [AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion) y [MLE](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) para obtener el mejor modelo. Básicamente, los valores $p$, $d$ y $q$ son elegidos minimizando el AIC. La función utiliza el algoritmo @HyndmanKhandakar2008, que usa una búsqueda por pasos para recorrer el espacio del modelo para seleccionar el mejor modelo con el AIC más pequeño.

```{r}
fitARIMA <- auto.arima(trainset, trace = TRUE)
fitARIMA
```

En este caso la función sugiere que el mejor modelo que representa a la serie sería un ARIMA(2,0,0)(0,1,0) sin tendencia, y que arroja un AIC de 9925.15. Lo validaremos con la prueba *Ljung-Box* (una versión simplificada de la prueba de Box y Pierce) que evalúa si los residuos de la serie son ruido aleatorio. 

La prueba de *Ljung-Box* es una prueba para comprobar si una serie de observaciones, en un período de tiempo específico, son aleatorias o independientes en todos los retardos hasta el retardo especificado. En lugar de probar la aleatoriedad en cada retardo distinto, se prueba la aleatoriedad *"general"* basada en un número de retardos y, por lo tanto, también es una prueba de comparación. 

La prueba se aplica a los residuos de un modelo ARIMA ajustado y no a la serie original, y en tales aplicaciones, la hipótesis que se prueba es que los residuos del modelo no tengan autocorrelación. Si los retardos no son independientes, un retardo puede estar relacionado con otros retardos de $k$ unidades de tiempo, por lo que la autocorrelación puede reducir la exactitud del modelo predictivo y conducir a una interpretación errónea de los datos. La hipótesis nula $H_{0}$ indicará que los datos no son diferentes del ruido aleatorio ($H_{0}$: los residuos se distribuyen aleatoriamente). 

A continuación, se aplica la prueba de *Ljung-Box* sobre el modelo ARIMA(2,0,0)(0,1,0), si el modelo rechaza la hipótesis nula $H_{0}$, debemos considerar el modelo como problemático.

```{r}
Box.test(fitARIMA$residuals, type = "Ljung-Box")
```

En este caso, el valor de p (*p-value = 0.8777*) está lejos de ser significativo (inferior a 0.05). Por lo tanto, no podemos rechazar la hipótesis nula $H_{0}$de que los residuos se distribuyen aleatoriamente y se concluye que el modelo, como se especifica, se ha ajustado correctamente.

\newpage

## Predicción

Los parámetros del modelo ARIMA se pueden usar como un modelo predictivo para hacer pronósticos de valores futuros de las series temporales, una vez que se selecciona el modelo más adecuado para los datos de la serie temporal. Se usará la función *forecast()* para la predicción de la serie.

```{r}
forecastARIMA <- forecast(fitARIMA)
autoplot(trainset, xlab = "Minutos", ylab = "Demanda en MW") +
  autolayer(testset) +
  autolayer(forecastARIMA, series = "ARIMA(2,0,0)(0,1,0)", PI = FALSE) +
  ggtitle("Predicción obtenida del modelo ARIMA")
```
La figura muestra que el modelo proporciona una buena predicción. Finalmente, se guarda el resultado de la predicción en un fichero Excel. Para ello, necesitaremos el paquete [openxlsx](https://www.rdocumentation.org/packages/openxlsx/versions/4.2.3).

```{r warning=FALSE}
library(openxlsx)

resultado <- createWorkbook()
addWorksheet(resultado, "resultado")
writeData(resultado, "resultado", forecastARIMA, rowNames = TRUE)
saveWorkbook(resultado, "resultado.xlsx", overwrite = TRUE)
```

