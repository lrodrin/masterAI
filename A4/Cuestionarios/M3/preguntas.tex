\documentclass[11pt]{exam}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}

\title{Evaluación del Módulo 3}
\author{Laura Rodríguez Navas \\ rodrigueznavas@posgrado.uimp.es}
\date{Febrero 2020}

\pagestyle{plain}

\begin{document}

\maketitle

\begin{questions}
	
% Pregunta 1
{\bf \question Describa los distintos tipos de recursos lingüísticos que puede usar un sistema de PLN, así como indique al menos dos ejemplos de cada tipo de recurso. Se valoraran positivamente que los ejemplos se refieran a recursos para el procesamiento de Español (2 puntos).}

Los tipos de recursos lingüísticos que puede usar un sistema de PLN son: Lexicones y Diccionarios, Ontologías y Corpus.

Los {\bf Lexicones} son series ordenadas de palabras de una lengua, una persona, una región, una materia o una época determinada. Y podemos clasificar-los como generales o especializados.

Los lexicones generales son repositorios de palabras. Pueden ser tan simples como una lista de palabras o pueden ser tan complejos como una base de datos terminológica. También incorporan información o conocimiento sobre las palabras; como información fonológica, morfológica, sintáctica, semántica y pragmática.

Hay de muchos tipos de lexicones especializados, dentro de distintas categorías, como, por ejemplo:

\begin{itemize}
	\item Diccionarios de locuciones.
	\item Bases de datos léxicas.
	\item Gazetteers.
	\item Bases de datos terminológicas.
	\item Listas de nombres propios.
	\item Listas de siglas o jergas.
	\item Detectores de fechas, números, fórmulas, etc.
\end{itemize}

En realidad, los lexicones especializados están orientados a ciertas aplicaciones o a ciertos dominios concretos. Por ejemplo, en las aplicaciones de análisis de sentimientos aparecen listas de términos polares (positivos y negativos); y en las aplicaciones de recuperación de información geográfica se pueden tener listas de topónimos y localizaciones. Por otra parte, en los dominios de tipo biomédico aparecen listas de términos; y en los dominios de tipo turístico se pueden tener listas de monumentos, ciudades, etc.; o también listas de topónimos, como en el caso de las aplicaciones.

Los {\bf Diccionarios} son listas de palabras, donde cada palabra contiene su definición y a veces su etimología. Existen diferentes tipos de diccionarios dependiendo de si son normativos, de uso, de aprendizaje, etc. Y según el número de lenguas utilizadas puede ser diccionarios monolingües, bilingües o multilingües.

Dentro de este tipo también se encuentran las enciclopedias y los tesauros que son recursos lingüísticos parecidos a los diccionarios, pero son un poco más avanzados. Por ejemplo, un tesauro es una lista de palabras o términos controlados, empleados para representar conceptos.

Una {\bf Ontología} es la especificación formal y explícita de una conceptualización compartida.

\begin{itemize}
	\item Conceptualización porqué es una forma de entender o describir un dominio. 
	\item Compartida porqué se entiende consensuada por un grupo y por varias partes.
	\item Explícita porqué está descrita en un lenguaje.
	\item Formal porqué es comprensible por las máquinas.
\end{itemize}

Los tipos de ontologías conocidas son:

\begin{itemize}
	\item Las genéricas, que describen conceptos genéricos (espacio, tiempo, objeto, ...).
	\item Las específicas para un dominio, que expresan conceptos de dominios particulares (medicina, bioquímica, turismo, ...).
	\item Las específicas para una tarea, que expresan conceptos sobre la resolución de problemas (diagnósticos, ventas, ...).
	\item Las que están diseñadas específicamente para una aplicación, que describen conceptos que dependen tanto de un dominio específico como de una tarea específica
	(procesos de producción, cardiología, ...).
\end{itemize}

En la actualidad, el uso de las ontologías y su integración en los sistemas de PLN se está potenciando muchísimo precisamente porqué están apareciendo nuevas tareas que requieren de su potencial para trabajar con información que puede ser ingerida o de sentido común y con ello poder generar y desarrollar nuevos sistemas mucho más eficientes. Alguna de esas nuevas tareas son la Web semántica, la implicación textual, la minería de datos y el Big Data. 

Este uso de las ontologías es para:

\begin{itemize}
	\item Definir e unificar un espacio global de la información para compartir conocimiento, facilitar el razonamiento automático, etc.
	\item Estandarizar tipos de datos.
	\item Simplificar el acceso a los datos.
	\item Gestionar los datos definiendo los conceptos y sus relaciones básicas para la comprensión de un área.
\end{itemize}

Un {\bf Corpus} es una colección de textos representativos de una lengua, de un dialecto o un subconjunto de una lengua, que se utiliza para el análisis lingüístico. Si además incluye información lingüística adicional, representa una herramienta y un recurso fundamental con un valor añadido para integrarse en tareas del PLN. De hecho, son uno de los recursos lingüísticos más utilizados en el ámbito del PLN con la aparición de la Web y Internet; y el uso de estos se ha fomentado porqué proporcionan la obtención de recursos de manera fácil y accesible.

Los Corpus se pueden clasificar,

\begin{itemize}
	\item según el material que incorporan como textuales o orales.
	\item según el propósito como generales o específicos.
		\subitem Los corpus con fines generales, tienen como objetivo principal, constituir una fuente de información textual de una lengua para fines y aplicaciones diversas.
		\subitem En cambio, los corpus con fines específicos, se han creado como respuesta a un propósito particular, como el
		estudio de aspectos	concretos de la gramática o	del léxico de la lengua para un	dominio concreto, para una aplicación concreta, o para una tarea concreta.
	\item según el número de lenguas utilizadas como monolingües o multilingües. Dentro de los corpus multilingües hay que distinguir entre los corpus paralelos y los corpus comparables.
		\subitem Los corpus paralelos son un conjunto de textos donde cada uno de éstos es la traducción exacta y fiable del idioma original a otras lenguas.
		\subitem Los corpus comparables son un conjunto de textos en varios idiomas que contienen información sobre un tema común pero que no requieren una traducción exacta del idioma original a otras lenguas.
	\item según la información lingüística que incorporan como anotados (etiquetados) o no anotados (no-etiquetados). Los corpus no anotados pueden ser recolecciones directas desde Internet. Y los corpus anotados son fundamentales ya que proporcionan una información valiosísima adicional en forma de marcas o anotaciones incluidas en cada secuencia de	caracteres de los textos para trabajar con los sistemas del PLN.
\end{itemize}

\section*{Ejemplos}

\subsection*{Lexicones}

Dos ejemplos de lexicones en español que merecen especial atención son WordNet y Acquilex, que son considerados bases de datos léxicas multilingüe. 

{\bf WordNet} es un sistema electrónico de referencia léxica multilingüe, desarrollado en forma de base de datos léxica. Su diseño está en consonancia con teorías psicolingüísticas relativas a la organización de la información léxica en la mente del hablante. Además constituye el intento de reflejar un modelo de memoria léxica, basado en redes semánticas, en un modelo lexicográfico de organización léxica. 

Los objetivos principales de WordNet son: 

\begin{itemize}
	\item La validación de las teorías psicolingüísticas sobre organización léxica anteriormente mencionadas.
	\item Su previsible utilización en diversas aplicaciones que requieran acceso a información léxica.
\end{itemize}

Concretamente, el WordNet en español que sigue el marco de EuroWordNet, se estructuran de la misma manera que el WordNet americano para el inglés (\href{https://wordnet.princeton.edu/}{Princeton WordNet}) en términos de conjuntos de sinónimos de palabras con relaciones semánticas básicas entre ellos. Los sustantivos, verbos y adjetivos en español se organizan en conjuntos de sinónimos, cada uno de los cuales representa un concepto léxico subyacente. Y diferentes relaciones son las encargadas de vincular los conjuntos de sinónimos. 

La diferencia básica entre éste y otros lexicones es que pertenece a un único proyecto a gran escala en el que se ha tenido como idea fundamental la organización léxica en campos semánticos. 

Por otra parte, {\bf Acquilex} se basa en la utilización de diccionarios de soporte magnético (M.R.Ds, Machine Readable Dictionaries) para la construcción de componentes léxicos. Los diccionarios automatizados constituyen una fuente de adquisición de información léxica y conceptual que, potencialmente, permite abordar algunos aspectos especialmente costos de la construcción de una base de datos léxica multilingüe a partir de estos.

La extracción de la información de los MRDs está formada por:

\begin{itemize}
	\item Análisis sintáctico de las definiciones.
	\item Extracción de información semántica de las definiciones analizadas.
	\item Desambiguación del género contenido en las definiciones y la construcción de taxonomías.
	\item Filtrado de la información contenida en la parte correspondiente a la diferencia específica de las definiciones.
	\item Conversión de los resultados de los procedimientos de extracción en un sistema de representación formal.
\end{itemize}

Acquilex se encuentra en un área poco explorada, debido a la dificultad que supone el tratamiento complejo de grandes volúmenes de información en el proceso de conversión de los MRDs a una base de datos léxica.

\subsection*{Diccionarios, Enciclopedias, Tesauros}

En esta sección se destacan tres ejemplos. Un ejemplo de diccionario (el diccionario de la lengua española), un ejemplo de enciclopedia (la Wikipedia en español) y un ejemplo de tesauro (\href{https://digital.csic.es/handle/10261/30257}{el ISOC de Economía}).

\begin{itemize}
	\item El diccionario de la lengua española es un diccionario normativo del idioma español editado y elaborado por la Real Academia Española (RAE). El diccionario incluye palabras de uso común extendido, al menos en un ámbito representativo de entre aquellos en los que se habla el español o castellano y además incluye numerosos arcaísmos y vocablos hoy en desuso, para entender la literatura castellana antigua. Actualmente, es la obra lexicográfica académica española por excelencia y se ha convertido en el diccionario de referencia y consulta del español.
	
	\item La Wikipedia es una enciclopedia \texttt{libre} \footnote{no posee restricciones legales significativas en relación con el derecho de uso, la redistribución y la creación de versiones modificadas o derivadas por parte de terceros.} políglota y editada de manera colaborativa, que permite la recopilación, el almacenamiento y la transmisión de la información de forma estructurada. Una de sus ediciones es en español.
	
	La Wikipedia está sustituyendo a todas las enciclopedias españolas conocidas, como por ejemplo a la Enciclopedia Libre Universal en Español o la enciclopedia Encarta de Microsoft, aunque a veces su fiabilidad es cuestionada ya que puede ser editada por todo el mundo.
	
	Un dato importante en términos de PLN es que es una enciclopedia que se incorpora muy bien con los sistemas de PLN, con resultados realmente sorprendentes.
	
	\item El tesauro ISOC de Economía tiene como objetivo, facilitar un análisis homogéneo de los documentos que se incorporen a las bases de datos terminológicas y permitir al usuario la recuperación de estos de forma precisa y exhaustiva. El rasgo determinante de este tesauro es su base empírica y su utilidad contrastada durante décadas en distintos sistemas de información económica especializada. Por lo demás, su estructura interna responde al modelo tradicional de los tesauros que articula los términos en torno a una red de relaciones jerárquicas, asociativas y de equivalencia, eliminando así las posibles ambigüedades y polisemias, y facilitando la percepción de la afinidad y/o diferenciación semántica entre ellos. 
	
	En concreto, este tesauro contiene 6.792 términos (5.464 descriptores y 1.328 no descriptores) distribuidos en 13 áreas temáticas y consta de un índice alfabético, otro jerárquico y un tercero permutado. Se completa con dos anexos: uno de identificadores, que recoge nombres de personas, instituciones, partidos políticos, etc.; y otro con la denominación de las monedas nacionales. 
	 
\end{itemize}

\subsection*{Ontologías}

De ejemplos de ontologías hay muchísimos.

Curiosamente, el lexicón {\bf WordNet}, comentado anteriormente, también puede ser un ejemplo de ontología ya que muchos de sus autores lo consideran como una auténtica ontología. De hecho porqué las ontologías generan cierta controversia en el campo de la Inteligencia Artificial (IA), ya que no existe claridad entre las ontologías y los lexicones.

Otro ejemplo parecido a WordNet, es \href{https://babelnet.org/}{BabelNet} . {\bf BabelNet} es una red semántica multilingüe creada a partir de la integración de WordNet y Wikipedia, y también una ontología lexicalizada. BabelNet ha sido creado automáticamente integrando la Wikipedia en la base de datos léxica WordNet. La integración se realiza a través de un mapeo automático, al tiempo que se llenan los huecos de idiomas con pocos recursos con la ayuda de traductores automáticos. El resultado es un diccionario enciclopédico que provee conceptos y entidades lexicalizadas en muchos idiomas, incluido el español, y conectadas a través de relaciones semánticas. 

Su uso mayoritario es en aplicaciones de sistemas multilingües de PLN. Y el conocimiento lexicalizado que se encuentra disponible en BabelNet también se ha utilizado para obtener los mejores resultados conocidos hasta el momento en similitud semántica y desambiguación multilingüe.

Familiarmente a WordNet, BabelNet agrupa palabras de diferentes idiomas en conjuntos de sinónimos. Para cada conjunto de sinónimos, BabelNet provee pequeñas definiciones en muchos idiomas obtenidos tanto de WordNet como de Wikipedia.

\subsection*{Corpus}

Dos ejemplos de corpus que incorporan el español son el corpus oral \href{http://www.talp.upc.edu/content/albayzin}{Albayzin} y el corpus anotado \href{https://www.dlsi.ua.es/projectes/3lb/}{3LB}. 

El corpus oral español {\bf Albayzin} consta de 3 subcorpus de señales de 16 kHz y 16 bits, grabadas por 304 hablantes de castellano.

Los 3 subcorpus son:

\begin{itemize}
	\item un corpus fonético con 6.800 enunciados de oraciones fonéticamente equilibradas, incluidos 1000 enunciados con segmentación fonética.
	\item un corpus geográfico con 6.800 enunciados de oraciones extraídas de una base de datos geográfica española.
	\item un corpus "lombardo" con 2.000 declaraciones de diferentes corpus.
\end{itemize}

Albayzin fue producido en 1998 después de ser diseñado entre los años 1991 y 1993 por un consorcio de 6 grupos de investigación españoles liderados por el grupo de Procesamiento del Habla de la UPC.

Por otro lado, el corpus anotado {\bf 3LB} es un proyecto para la construcción de una base de datos de árboles sintáctico-semánticos que tiene como objetivo la construcción de tres corpus anotados sintácticamente para el español, el catalán y el euskera.

A pesar de que la construcción de tres corpus anotados sintácticamente es una tarea costosa, es una labor imprescindible para el desarrollo de aplicaciones reales en el área del PLN y como tal para el desarrollo de la sociedad de la información. 
Resulta imprescindible la obtención de gramáticas computacionales a partir de corpus que son un primer paso hacia procesos posteriores que requieren más elaboración. Entre estos procesos se halla la delimitación de las entidades discursivas, lo que, junto con la identificación de los elementos anafóricos y correferentes mejora sustancialmente la calidad de todos los sistemas de Traducción Automática (TA), Extracción de Información (EI), Recuperación de Información (RI), Resumen Automático (RA) y sistemas de Pregunta-Respuesta (PR). 

Otras tareas lingüísticas que pueden abordarse si se dispone de tres corpus anotados sintácticamente son el aprendizaje de restricciones de selección o el de los patrones de subcategorización de los verbos.


% Pregunta 2
{\bf \question Explique las aplicaciones de PLN que pueden estar interesadas en el uso de un Gazetter (2 puntos).}

% Pregunta 3
{\bf \question Describa las diferencias entre un reconocedor de entidades y un clasificador de entidades (2 puntos).}

% Pregunta 4
{\bf \question Indique al menos 5 ejemplos de entidades ambiguas (2 puntos).}

% Pregunta 5
{\bf \question Razone si el uso de un reconocedor de entidades sería beneficioso para el Análisis de Opiniones. El Análisis de Opiniones es la tarea que se encarga de la clasificación automática de opiniones (2 puntos).}

\end{questions}

\end{document}