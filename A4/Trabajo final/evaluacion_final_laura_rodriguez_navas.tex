\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{vmargin}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{siunitx}
\setpapersize{A4}
\setlength{\parskip}{\baselineskip}%
\setlength{\parindent}{0pt}%

\title{Evaluación Final de PLN \\ Modelo de Espacio Vectorial}
\author{Laura Rodríguez Navas \\ rodrigueznavas@posgrado.uimp.es} 
\date{Mayo 2020}

\begin{document}

\maketitle

\renewcommand{\contentsname}{Índice}
\tableofcontents

\section{Motivación y definición del MEV}

\subsection{Motivación}

\subsection{Definición del MEV}

En un modelo de espacio vectorial (MEV), los documentos se almacenan como vectores de términos y pueden encontrarse en un espacio vectorial de n dimensiones, en grupos formando colecciones de documentos de acuerdo con la relevancia para una misma clase de necesidad de información. Es decir, cuando queremos acceder a cierta información usando la consulta, esa consulta llega a ser comparada con cada elemento de la colección, si se obtiene un alto grado de coincidencia como consecuencia el documento tendrá más probabilidades de ser relevante, y se nos devolverá lo que buscamos.

El proceso para construir un MEV comienza con la extracción de los términos de indización, es decir, los términos que van a ser utilizados para describir el contenido del documento. La posibilidad más simple consiste en considerar todas las palabras aisladas que aparecen en el texto como los términos de indización. Habitualmente se eliminan algunas palabras (las denominadas palabras vacías, entre las que suelen figurar números, preposiciones, conjunciones, etc.). Una vez extraídas las palabras del texto, se ordenan por orden alfabético y se guardan en un matriz, junto con la referencia del documento de donde proceden (normalmente un número de documento asignado previamente por el sistema). Si se repite este proceso con todos los documentos de la colección, obtenemos finalmente una matriz que almacena los siguientes datos:

\begin{itemize}
	\item En primer lugar, los términos de indización (las palabras) que aparecen en toda la colección (ya sean los propios textos, los resúmenes de los textos del fondo y/o los títulos).
	\item En segundo lugar, cada uno de estos términos (palabras) incorpora una lista con los números de los documentos en los que aparece.
\end{itemize}

Por ejemplo, el objetivo principal de una colección de \textit{n} documentos indexados por \textit{m} términos que se puede representar por una matriz A de dimensión \textit{n} x \textit{m}, donde cada elemento a$_{ij}$ es definido por una frecuencia ponderada del término \textit{i} en el documento \textit{j} es mejorar el rendimiento en la habilidad de recuperar información relevante y descartar información irrelevante. 

La siguiente tabla (ver Tabla \ref{table: Table 1}) muestra la matriz A, donde cada fila representa un término en la colección, cada columna un documento y cada celda o elemento de la matriz la ocurrencia del término en el documento.

\begin{table}[h]
	\begin{center}
		\begin{tabular}{ |c|c|c|c| }
			\hline 
			& D1 & D2 & D3 \\
			\hline
			T1 & 1 & 0 & 0 \\ 
			\hline
			T2 & 0 & 0	& 1 \\ 
			\hline
			T3 & 1 & 1	& 1 \\
			\hline
		\end{tabular}
		\caption{Matriz A.}
		\label{table: Table 1}
	\end{center}
\end{table}

En ella podemos ver que el término 1 aparece en el documento 1, pero no en los documentos 2 y 3, y así se puede demostrar que cada fila de la matriz de 3×3 puede ser representada en un espacio de tres dimensiones.

Más formalmente, cada elemento a$_{ij}$ de la matriz A queda definido como: 

\begin{center}
	a$_{ij}$ = l$_{ij}$ * g$_{i}$ * d$_{j}^-1$
\end{center}

donde l$_{ij}$ es el peso local del término \textit{i} en el documento \textit{j}, el cual mide la importancia de dicho término en el documento, g$_{i}$ es el peso global del término \textit{i} en la colección de documentos y d$_{j}$ es el factor de normalización para el j-ésimo documento. 

\section{Tipos de MEV}

\subsection{Modelo Booleano}

En la tabla de ejemplo (ver Tabla \ref{table: Table 1}) de la sección anterior, se muestra un tipo de MEV: el modelo booleano. Este modelo constituye el primer modelo teórico de RI, el más antiguo, empleado para establecer un subconjunto de documentos relevantes. Al mismo tiempo es, sin duda, uno de los modelos más sencillos tanto desde un punto de vista teórico como práctico, por una parte, al basarse en la teoría de conjuntos y en el álgebra de Boole, y por otra parte al ser fácil de diseñar e implementar.

Una propiedad importante del modelo booleano es que no puede efectuar ningún proceso de ordenación con los documentos resultantes de las consultas. Esta característica suele denominarse \textbf{equiparación exacta}, impidiendo que se pueda situar en primer lugar aquel documento posiblemente más útil o relevante para el usuario y relegando a las últimas posiciones a aquellos otros documentos con menos probabilidades de ser relevantes en relación a la consulta.

También se denomina modelo binario por su carácter binario porqué considera exclusivamente la presencia (con el número 1) y la ausencia (con el número 0), los términos en los documentos. Pero ese carácter es el principal responsable de la equiparación exacta, siendo considerada la principal desventaja del modelo. 

A pesar de esta desventaja, todavía hoy sigue constituyendo el modelo más habitual. Muchos motores de búsqueda en la web se basan en este modelo, por ser de desarrollo sencillo (como hemos visto, en su versión básica solamente involucra el empleo de una matriz y una interfaz de consulta que permita realizar consultas expresadas mediante palabras o expresiones booleanas), fácil de utilizar por parte de un usuario medio (basta introducir palabras relativas a la necesidad informativa), y bastante eficaz en los resultados obtenidos (en gran parte debido al volumen ingente de documentación presente en la red, lo que provoca que la reducción de la respuesta a los documentos que satisfagan estrictamente las condiciones de la consulta.

Observando mejor el ejemplo de la sección anterior (ver Tabla \ref{table: Table 1}) vemos que de la consulta de la matriz A únicamente se puede saber si un determinado término de indización está presente (en cuyo caso se simboliza con el número 1) o no lo está (en cuyo caso se simboliza con el número 0) en cada uno de los documentos de la colección. De manera que la matriz A se puede generalizar por la siguiente table cuyos datos básicos son:

\begin{table}[h]
	\begin{center}
		\begin{tabular}{ |c|c|c|c|c| }
			\hline 
			& D1 & D2 & ... & D$_{n}$ \\ 
			\hline
			T1 & 1 & 0 & ... & 1 \\ 
			\hline
			T2 & 0 & 1 & ... & 0 \\ 
			\hline
			... & ... & ...	& ... & ... \\
			\hline
			T$_{n}$ & 0 & 1 & ... & 1 \\ 
			\hline
		\end{tabular}
		\caption{Matriz A.}
		\label{table: Table 2}
	\end{center}
\end{table}

donde T1, T2, …, T$_{n}$ son los términos de indización empleados en la colección de documentos D1, D2, …, D$_{n}$ y donde el número 1 significa que el término correspondiente aparece en ese documento concreto, mientras que el número 0 significa que el término no aparece en dicho documento. Esto implica que no se tiene en cuenta la frecuencia de aparición de los términos en los documentos. Se entiendo entonces porqué se denomina modelo binario, pues únicamente se juega con dos posibilidades: la aparición y la no aparición de los términos en los documentos.

Si observamos la tabla anterior (ver Tabla \ref{table: Table 2}), podemos deducir de ella las dos representaciones empleadas al manejar un modelo binario. Por una parte, cada término de indización se representa por la lista de documentos en los que aparece, lo que implica la observación de la tabla por filas:

\begin{center}
	T1 = \{D1, ..., D$_{n}$\} \\
	T2 = \{D2, ..., D$_{n}$\} \\
	\rotatebox{90}{...} \\
	T$_{n}$ = \{D2, ..., D$_{n}$\} \\
\end{center}

Por otra parte, cada documento se representa por una lista de ceros y sus correspondientes términos de indización que contiene, lo que implica la observación de la tabla por columnas:

\begin{center}
	D1 = \{1, 0, ..., 0\} \\
	D2 = \{0, 1, ..., 1\} \\
	\rotatebox{90}{...} \\
	D$_{n}$ = \{1, 0, ..., 1\} \\
\end{center}

Se comprende bien ahora por qué se dice que en el modelo binario todo documento se representa mediante una serie ordenada de ceros y unos, tantos como términos se empleen en una colección: des del primer número que siempre corresponderá a T1, el segundo número corresponderá a T2, y así sucesivamente hasta llegar a T$_{n}$, siendo \textit{n} el número de términos distintos que representan el contenido de esa colección.

\subsection{Modelo Probabilístico}

El modelo probabilístico fue introducido en la década de los setenta por Robertson y Sparck Jones. También es conocido como modelo de recuperación de independencia binaria (RIB). Este modelo evitando el empleo de fórmulas matemáticas, se basa en las siguientes consideraciones:

\begin{itemize}
	\item Para caracterizar los documentos de la colección se emplean ciertos términos de indización.
	
	\item Dada una necesidad informativa del usuario, existe un subconjunto de documentos de la colección que contiene exclusivamente los documentos relevantes con relación a ella.
	
	\item Se parte exclusivamente de la presencia o ausencia de los términos en los documentos de la colección. Se trata, pues también, de un modelo binario, como el modelo booleano.
	
	\item El usuario no sabe cuáles son los términos de indización que configurarían la consulta ideal. Tampoco sabe en qué medida los términos empleados en la consulta permiten discernir de los documentos relevantes y rechazar simultáneamente los documentos irrelevantes.
	
	\item Actúa sobre los términos que configuran la consulta del usuario, ponderándolos; esto es, imponiéndoles un peso a cada uno de ellos, mayor cuanto mejor permita discernir los documentos relevantes de los irrelevantes, y menor en caso contrario. De esta manera se persigue que el modelo efectúe la recuperación de información incidiendo sobre todo en los mejores términos de entre todos los empleados por el usuario en la consulta, minimizando la importancia de aquellos otros términos que, aun figurando en la consulta, son malos términos del conjunto de respuesta ideal.
	
	\item Como tampoco se puede saber a priori cuáles, de entre los términos que configuran la consulta, son buenos términos y cuáles no lo son, a este modelo no le queda otro remedio que considerar, para cada uno de los términos empleados en la consulta, la \textit{"probabilidad de ser buen término"} (probabilidad de que el término empleado en la consulta esté presente en un documento del conjunto de documentos relevantes en relación a la consulta) y simultáneamente, para ese mismo término, la \textit{"probabilidad de ser un mal término"} (probabilidad de que ese mismo término esté presente en un documento del conjunto de documentos irrelevantes en relación a la consulta).
	
	\item Como las probabilidades nombradas anteriormente son desconocidas inicialmente a la consulta, este modelo se ve en la necesidad de efectuar una hipótesis inicial sobre sus valores. La obligatoriedad de hacer una hipótesis inicial sobre las \textit{"probabilidades de ser buen término o de ser un mal término"} para cada término de la consulta se considera el principal inconveniente de este modelo. 
\end{itemize}

El modelo probabilístico es capaz de calcular el grado de similitud existente entre cada documento de la colección y la consulta ponderada, consiguiendo ordenar los documentos de la colección en orden descendente de probabilidad de relevancia en relación con la consulta. De esta manera el modelo supera el gran inconveniente puesto de manifiesto en el modelo booleano, la equiparación exacta. En efecto, el modelo probabilístico, aun siendo un modelo binario, efectúa \textbf{equiparación parcial}, lo que permite ordenar los documentos de la respuesta conforme a su probabilidad de relevancia. Ya que no puede ponderar los términos de la colección ya que es un modelo binario, la equiparación parcial es posible gracias a la ponderación de los términos empleados en la consulta.

Una de las grandes aportaciones del modelo probabilístico a la recuperación de información consiste en el fenómeno denominado retroalimentación por relevancia. Que consiste en la utilización de información generada en procesos de recuperación anteriores o durante el propio proceso de consulta para mejorar los resultados de la recuperación de información solicitando al usuario, tras una respuesta inicial a la consulta, que analice los documentos recuperados y valore cuáles son relevantes. Con esta información se imponen nuevos pesos a las \textit{"probabilidades de ser buen término o de ser un mal término"} para cada término de la consulta, obteniéndose así una nueva respuesta de documentos ordenados por su probabilidad de relevancia, gracias a la información suministrada directamente por el usuario.

Actualmente hay muchos sistemas de recuperación de información que emplean alguna variante de la retroalimentación por relevancia para mejorar y refinar los resultados de las consultas. Quizá la más conocida se base en la sugerencia al usuario de más resultados precedidos de la siguiente advertencia: \textit{"Otros usuarios que adquirieron o preguntaron por ese documento también adquirieron o preguntaron por estos otros"}. Es una manera de emplear la información procedente, en este caso, de procesos de recuperación anteriores.

\subsection{Modelo Vectorial}

El modelo vectorial fue presentado por Salton en 1975 y posteriormente asentado en 1983 junto con Mc Gill y se basa en tres principios esenciales (MARTÍNEZ COMECHE, J.A. 2006):

\begin{itemize}
	\item La equiparación parcial, esto es, la capacidad del sistema para ordenar los resultados de una búsqueda, basado en el grado de similaridad entre cada documento de la colección y la consulta.
	\item La ponderación de los términos en los documentos, no limitándose a señalar la presencia o ausencia de estos, sino adscribiendo a cada término en cada documento un número real que refleje su importancia en el documento.
	\item La ponderación de los términos en la consulta, de manera que el usuario puede asignar pesos a los términos de la consulta que reflejen la importancia de estos en relación a su necesidad informativa.
\end{itemize}

Como hemos observado, se considera que el modelo probabilístico clásico supera al modelo booleano clásico en cuanto que el probabilístico efectúa equiparación parcial mientras que el modelo booleano clásico efectúa equiparación exacta. Sin embargo, ambos siguen presentado una característica negativa: ni el modelo booleano ni el modelo probabilístico tienen en cuenta la frecuencia con la que aparecen los términos de indización dentro de los documentos. Esto es, ambos son modelos binarios de representación documental.

Parece lógico pensar que, si en un documento aparece el término “biblioteca” una vez, y en otro documento aparece ese mismo término veinte veces, consideremos que en el primer documento la importancia de “biblioteca” es menor que ese mismo término en el segundo documento. En consecuencia, surge un tercer modelo de recuperación, el modelo vectorial, basado en tres principios12:

\begin{itemize}
	\item La equiparación parcial, esto es, la capacidad del sistema para ordenar los resultados de una búsqueda, basado en el grado de similaridad entre cada documento de la colección y la consulta.
	\item La ponderación de los términos en los documentos, no limitándose a señalar la presencia o ausencia de los mismos, sino adscribiendo a cada término en cada documento un número real que refleje su importancia en el documento.
	\item La ponderación de los términos en la consulta, de manera que el usuario puede asignar pesos a los términos de la consulta que reflejen la importancia de los mismos en relación a su necesidad informativa.
\end{itemize}

En definitiva, en el modelo vectorial tanto un documento como la consulta se representan mediante conjuntos ordenados de números (no solamente de ceros y unos como en los modelos anteriores; sin embargo, en este modelo también el cero representa la ausencia del término en el documento):

\begin{center}
	$d_{j}$ = ($w_{1, j}$, $w_{2, j}$, ..., $w_{t, j}$) \\
	$q$ = ($w_{1, q}$, $w_{2, q}$, ..., $w_{n, q}$)
\end{center}

Donde “t” es el número total de términos considerados en la descripción de la colección. Lógicamente, aunque el usuario no va a introducir nunca “t” términos, se puede representar siempre en función de tales términos (basta imponer ceros en aquéllos no empleados en la consulta).

Gracias a esta representación, tanto los documentos como las consultas pueden tratarse matemáticamente como vectores en un espacio t dimensional, de donde el nombre de modelo vectorial. Para que podamos comprender las consecuencias de este hecho, consideraremos únicamente dos dimensiones (esto es, dos únicos términos). Sean, por ejemplo, los documentos D1=(3, 5) y D2=(4,1) y la consulta Q=(2,1). Tratándose de un espacio bidimensional, podemos dibujar tanto los documentos como la consulta en el plano de esta hoja, como “flechas” o vectores que parten del origen de coordenadas, cuyo primer número corresponde al valor del término 1 representado en el eje de abcisas y cuyo segundo número corresponde al valor del término 2 representado en el eje de ordenadas. En nuestro ejemplo obtendríamos el siguiente gráfico, donde D1 es el vector más próximo al eje de ordenadas, D2 es el vector más próximo al eje de abcisas, y donde la consulta Q es el vector entre D1 y D2:

%Gràfica.

Como podemos observar en el gráfico, puede resultar relativamente fácil juzgar cuál de los dos documentos se asemeja más a la consulta. Considerando que el vector de la consulta Q está más próximo a D2, podemos deducir gráficamente que el orden de relevancia de los documentos D1 y D2 en relación a la consulta Q sería en nuestro ejemplo: D2 y posteriormente D1. En resumen, en el modelo vectorial basta fijar un criterio de similaridad para poder ordenar fácilmente por orden de relevancia los documentos de una colección en relación a una consulta.

\section{Medidas de cálculo de relevancia}

Medidas de cálculo de relevancia típicamente usadas para la generación de los vectores

Usualmente los componentes principales son el factor término-frecuencia (TF) y el factor de frecuencia inversa del documento, inverse document frequency (IDF).

En cuanto a la manera de ponderar los términos en los documentos de la colección, una de las más utilizadas y de eficacia probada es la denominada ponderación tf.idf. Consiste en multiplicar dos factores que reflejan la importancia de los términos:

\begin{itemize}
	\item El primer factor, tf (abreviatura de Term Frequency), pretende reflejar la importancia de los términos en los documentos, concediendo mayor importancia a los términos cuantas más veces aparezcan en los documentos. La versión más sencilla de este factor lo representa numéricamente mediante la frecuencia de aparición de cada término en cada documento de la colección.
	\item El segundo factor, idf (abreviatura de Inverse Document Frequency), o inverso de la frecuencia de documentos, pretende reflejar la importancia de los términos en la colección, primando la precisión y el poder discriminatorio de los mismos. Así, dará mayor importancia a un término cuanto menor sea el número de documentos de la colección en los que aparezca dicho término. Por el contrario, si un término aparece en todos los documentos de la colección, su precisión y poder discriminatorio (capacidad para discernir los documentos relevantes de los irrelevantes ante una consulta) es nulo (tal término aparecerá necesariamente tanto en todos los documentos relevantes como en todos los documentos irrelevantes), de manera que se le otorgará una importancia mínima en esa colección en concreto (puede que en otra colección ese mismo término posea una gran importancia, porque aparece en muy pocos documentos). Suele representarse numéricamente de manera proporcional al logaritmo neperiano del inverso del número de documentos de la colección en los que aparece dicho término.
\end{itemize}

la colección sigue lo que se denomina un Proceso de Vectorización por el que todos los documentos son representados mediante pesos TF-IDF, la consulta del usuario también requiere de dicho tratamiento. Ello significa que se tiene que ponderar la importancia de los términos de la consulta para poder generar el Vector de la consulta del usuario.

\section{Cálculo de similitud entre vectores de un MEV}

Como expusimos anteriormente, el modelo vectorial propone evaluar el grado de similaridad entre los documentos de una colección y las consultas mediante algún criterio que muestre la mayor o menor cercanía entre los vectores correspondientes a los documentos y el vector correspondiente a la consulta. Uno de las maneras más habituales de cuantificar el nivel de cercanía entre vectores es mediante el coseno del ángulo que forman, pues presenta la propiedad de ser un número mayor cuanto más cercanos estén entre sí ambos vectores (en el límite, el coseno de 0º vale la unidad), mientras que es un número menor cuanto más alejados estén entre sí (en el límite, el coseno de 90º vale cero).

Este paso es imprescindible para poder efectuar el Proceso de Equiparación de la consulta con los documentos de la colección y determinar cuáles de ellos son más relevantes, véase tabla2.

\subsection{Mediante el producto escalar}

Los procesos de equiparación de los documentos de la colección con respecto a la consulta del usuario, en el modelo booleano, se efectúan mediante cálculos de similaridad. Existen muchas modalidades de comparación o equiparación mediante similaridad, en este caso se presenta una de las más sencillas por su simplicidad y sistematización inmediata. Se trata del producto escalar de los pesos, véase figura1. 

De esta forma, la similaridad de un documento y una consulta, es igual a la suma de los productos de sus pesos. (Y no se debe olvidar que cada peso representa a un término). Este método puede aplicarse tanto a pesos binarios como a pesos TF-IDF.

Modalidad de pesos binarios
En el caso de la modalidad binaria, la similaridad de un documento con respecto a la consulta es equivalente a la presencia de los términos de la consulta en el documento, véase tabla3. Esto quiere decir que la ausencia de un término de la consulta o del documento implica un producto igual a 0 y por lo tanto no tienen incidencia en el cálculo. Por el contrario la presencia de un término dado tanto en la consulta como en el documento siempre tendrá valor 1. Por ello sólo basta con contabilizar el número de términos coincidentes de la consulta en el documento y ése será su valor de similaridad.

 Como se puede analizar en la tabla3, el número de términos coincidentes de la consulta con el documento1 es 4 que corresponde a los términos Universidad, Alcalá, Unamuno y Literatura. Por lo tanto, en una escala de 6 (Por ser todos los términos empleados en la consulta original depurada del usuario), el documento1, tiene un alto grado de coincidencia y por ende tiene más probabilidades de ser relevante.

Modalidad de pesos TF-IDF
En el caso de la modalidad de pesos binarios, las limitaciones en la definición de la representatividad de los términos de cada documento quedan patentes. Resulta por tanto un resultado bastante limitado y parcial. Por ello el método de la similaridad mediante el producto escalar se aplica habitualmente con pesos TF-IDF, mucho más precisos, véase tabla4.

El cálculo de la similaridad se aplica a cada uno de los documentos de la colección siguiendo el patrón expuesto en la tabla4. Para el documento1 la similaridad con respecto a la consulta del usuario q, será diferente que para el documento2. Obsérvese que al igual que ocurria con los pesos binarios, sólo tienen incidencia aquellos términos presentes tanto en la consulta como en el documento, pues sus pesos se multiplican y se suman sucesivamente al resto. En este caso, la similaridad del documento1 (35,306) es superior a la del documento2 (27,450), siendo éstas unas cifras mucho más precisas que un simple número entero.

\subsection{Mediante la fórmula del coseno}

Tal como se ha explicado en la fórmula del producto escalar, el proceso de equiparación es posible cuando en el vector de la consulta y en el del documento existen términos coincidentes. Pero este enfoque no supone la representación del vector de la consulta y del documento. De hecho una de las claves del modelo de espacio vectorial es precisamente la posibilidad de determinar el ángulo que forman los vectores del documento y de la consulta que se está comparando, véase figura2.

Es posible medir cuál es la desviación de un documento con respecto a una consulta, por el número de grados del ángulo que forman. Esto es posible porque crean una estructura triangular a la que se aplica el cálculo del ángulo que forma la hipotenusa (en este caso el vector del documento1) y el adyacente (el vector q de la consulta dada por el usuario) que resulta ser el coseno del triángulo. En el caso de la figura2, se comprueba visualmente cierta distancia del vector de la consulta con respecto al documento1; cuando ambos vectores se muestran tan próximos como para superponerse, implicará que el ángulo que forman será menor y que su nivel de coincidencia será superior. De hecho, un coseno de 0º implicaría una similaridad máxima.

Por lo tanto, la fórmula aplicada para calcular el coeficiente de similaridad del coseno entre un documento y una consulta es aquella que permite poner en relación los vectores de la consulta y del documento. De hecho el coseno de alfa de un triángulo cualquiera siempre es igual al cateto adyacente entre la hipotenusa. Tomando como clave esa idea, la figura3 muestra la misma relación pero esta vez con los pesos que forman los vectores del documento y la consulta. De hecho el numerador no deja de ser un producto escalar entre los pesos del documento y la consulta; y el denominador la raíz cuadrada del producto del sumatorio de los pesos del documento y la consulta al cuadrado. La formulación del denominador con raíz cuadrada y cálculo de cuadrados, se diseñó para conseguir un resultado final de la división, inferior a 1, de tal manera que el coeficiente fuera de fácil manejo y lectura. La similaridad del coseno aplicada al ejemplo que se viene utilizando, tendría la forma que sigue a continuación en la tabla5.

Como se puede observar en los resultados del coeficiente de similaridad del coseno para el documento1 y 2 en la tabla5, son diametralmente distintos a los obtenidos en la tabla4. Esto significa que los pesos de los términos del documento2, lo convierten en más representativo y probablemente más relevante que el documento1, dando por lo tanto una mayor precisión que el cálculo del producto escalar. El máximo valor del coeficiente de similaridad del coseno es 1, que equivaldría a un ángulo de 0º entre los vectores del documento y la consulta.



\subsection{Mediante el coeficiente de Dice}

El cálculo del coeficiente de similaridad según Lee Raymond Dice es una adaptación del cálculo del coeficiente del coseno. La diferencia en la formulación estriba en que la cardinalidad del numerador es 2 veces la información compartida y el denominador la suma de los pesos al cuadrado del documento y su consulta. Véase figura4 y tabla6. 



\subsection{Mediante el coeficiente de Jaccard (Tanimoto)}

El cálculo del coeficiente de similaridad de Jaccard* al igual que el de Dice, resultan deudores del coeficiente de similaridad del coseno. Su aplicación, centrada en usos estadísticos, también se aplica a recuperación de información y mide la similitud entre conjuntos. Se puede definir como el tamaño de la intersección (numerador) dividido por el tamaño de la unión de la muestra, en este caso la suma de los pesos al cuadrado del documento y la consulta menos la intersección, véase figura5 y tabla7.

Una vez calculada la similaridad entre cada documento de la colección y la consulta, el sistema es capaz de ordenar todos los documentos de la colección en orden decreciente de su grado de similaridad con la consulta, incorporando de este modo a los resultados aquellos documentos que satisfacen sólo parcialmente los términos de la consulta. Se efectúa, en consecuencia, equiparación parcial.

\section{Espacios vectoriales basados en \textit{word embeddings}}

Espacios vectoriales basados en representaciones continuas o densas de	palabras (\textit{word embeddings})

\section{Aplicaciones de \textit{word embeddings}}

\section{Reflexión personal sobre la utilidad y futuro de los MEV}

Reflexión personal sobre la utilidad y futuro de los MEV para la representación de la semántica, de la información y la generación de conocimiento.
 Ventajas

El modelo vectorial es muy versátil y eficiente a la hora de generar rankings de precisión en colecciones de gran tamaño, lo que le hace idóneo para determinar la equiparación parcial de los documentos. 
Tiene en cuenta los pesos TF-IDF para determinar la representatividad de los documentos de la colección.

Inconvenientes

El modelo vectorial por producto escalar tiene la desventaja de que sólo tiene en cuenta la intersección de los términos del documento con respecto a la consulta, por lo que la gradación de los resultados no es tan precisa como en el caso del cálculo del coseno.
Necesita de la intersección de los términos de la consulta con los documentos, en caso contrario no se produce la recuperación de información.
Al ser un modelo estadístico-matemático, no tiene en cuenta la estructura sintáctico-semántica del lenguaje natural.


Actualmente la recuperación de información ha cobrado un gran auge debido al crecimiento espectacular de Internet, tratando de facilitar la tarea de discernimiento de los escasos documentos relevantes que puedan existir en la red frente a los millones de documentos irrelevantes en relación a cada consulta formulada en la red. Dado que esta inmensa “colección” carece por completo de organización, la automatización de los procesos de análisis y recuperación de los billones de documentos que configuran la red se ha convertido en una tarea de importancia capital.

Los programas que rastrean la web en busca de páginas y los programas que efectúan el proceso de análisis y tratamiento de tales páginas con el objeto de poder recuperarlas ante las consultas de los usuarios, además de muchos otros programas con un objetivo semejante en cualquier ámbito (desde las bibliotecas hasta el comercio electrónico), se siguen basando en los tres modelos clásicos de recuperación de información creados entre los años sesenta y ochenta del siglo XX: los modelos booleano, probabilístico y vectorial. 

Como hemos podido observar, el fenómeno más destacado actualmente en estos sistemas de recuperación de información consiste en el empleo simultáneo de características y algoritmos propios de cada uno de estos modelos. Así, lo más frecuente es que los buscadores de Internet se basen en el modelo booleano, pero efectúen la ordenación de los documentos de las respuestas empleando criterios de similaridad originarios del modelo vectorial clásico. De igual modo, cada vez en mayor medida los SRI emplean una u otra variante de la retroalimentación por relevancia para aumentar la precisión de la respuesta, técnica empleada en sus inicios por el modelo probabilístico.
En consecuencia, puede afirmarse que con la popularización de Internet han cobrado nuevo auge los modelos clásicos de recuperación de información, tratando de aunar en un mismo programa de recuperación las ventajas primordiales de cada uno de ellos. La investigación en este área, muy activa en la actualidad, sigue tratando de mejorar la precisión y exhaustividad de los sistemas, pero tratando ahora de incorporar el usuario real y su punto de vista subjetivo en la evaluación de los sistemas. Sin duda en un futuro –esperemos que no muy lejano- tales avances se incorporarán a los SRI en beneficio de un acceso rápido y eficaz a la información por parte de cualquier habitante de nuestro planeta.

\end{document}
