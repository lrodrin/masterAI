---
title: "Práctica de Detección de Anomalías"
author: "Laura Rodriguez Navas"
date: "20/07/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r include=FALSE}
source("!Outliers_A2_Librerias_a_cargar_en_cada_sesion.R")
```


```{r echo=FALSE}
source("!Outliers_A3_Funciones_a_cargar_en_cada_sesion.R", encoding = "UTF-8")
```

### !MasterIA_GuionPracticas_Outliers_B1_1Variate_IQR

```{r fig.align='center', out.width='90%'}

###########################################################################
# UNIVARIATE STATISTICAL OUTLIERS -> IQR 
###########################################################################

# Siga las instrucciones indicadas en el fichero INSTRUCCIONES.txt.

# Vamos a trabajar con los siguientes objetos:

# mydata.numeric: frame de datos.
# indice.columna: Índice de una columna de datos de mydata.numeric.
# nombre.mydata:  Nombre del frame para que aparezca en los plots.

# En este script los estableceremos a la base de datos mtcars, 
# columna 1 y nombre "mtcars"

mydata.numeric = mtcars[, -c(8:11)]  # mtcars[1:7]
indice.columna = 1
nombre.mydata = "mtcars"

# Ahora creamos los siguientes objetos:

# mydata.numeric.scaled -> Debe contener los valores normalizados demydata.numeric. 
# Para ello, usad la función scale.
# columna -> Contendrá la columna de datos correspondiente a indice.columna. 
# Basta realizar una selección con corchetes de mydata.numeric.
# nombre.columna -> Debe contener el nombre de la columna. 
# Para ello, aplicamos la función names sobre mydata.numeric.
# columna.scaled -> Debe contener los valores normalizados de la anterior.

mydata.numeric.scaled = scale(mydata.numeric)
columna = mydata.numeric[, indice.columna]
nombre.columna = names(mydata.numeric)[indice.columna]
columna.scaled = mydata.numeric.scaled[, indice.columna]

###########################################################################
###########################################################################
# Parte primera. Cómputo de los outliers IQR
###########################################################################
###########################################################################

###########################################################################
# Calcular los outliers según la regla IQR
# Directamente sin funciones propias
###########################################################################

# Transparencia 82

# Calculamos las siguientes variables:

# cuartil.primero -> primer cuartil
# cuartil.tercero -> tercer cuartil
# iqr -> distancia IQR

# Para ello, usamos las siguientes funciones:
# quantile(columna, x) para obtener los cuartiles
#    x=0.25 para el primer cuartil, 0.5 para la mediana y 0.75 para el tercero
# IQR para obtener la distancia intercuartil 
#    (o bien reste directamente el cuartil tercero y el primero)

# Calculamos las siguientes variables -los extremos que delimitan los outliers-

# extremo.superior.outlier.normal  = cuartil tercero + 1.5 IQR
# extremo.inferior.outlier.normal  = cuartil primero - 1.5 IQR
# extremo.superior.outlier.extremo = cuartil tercero + 3 IQR
# extremo.inferior.outlier.extremo = cuartil primero - 3 IQR

# Construimos sendos vectores: 

# vector.es.outlier.normal 
# vector.es.outlier.extremo

# Son vectores de valores lógicos TRUE/FALSE que nos dicen 
# si cada registro es o no un outlier con respecto a la columna fijada.
# Para ello, basta comparar con el operador > o el operador < la columna 
# con alguno de los valores extremos anteriores.

# El resultado debe ser el siguiente:
# [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
# [18] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE

# COMPLETAR

cuartil.primero <- quantile(columna, 0.25) 
cuartil.tercero <- quantile(columna, 0.75)
iqr <- IQR(columna)

cuartil.primero
cuartil.tercero
iqr

extremo.superior.outlier.normal = cuartil.tercero + 1.5 * iqr
extremo.inferior.outlier.normal = cuartil.primero - 1.5 * iqr
extremo.superior.outlier.extremo = cuartil.tercero + 3 * iqr
extremo.inferior.outlier.extremo = cuartil.primero - 3 * iqr

extremo.superior.outlier.normal
extremo.inferior.outlier.normal
extremo.superior.outlier.extremo
extremo.inferior.outlier.extremo

vector.es.outlier.normal = columna > extremo.superior.outlier.normal |
  columna < extremo.inferior.outlier.normal

vector.es.outlier.extremo = columna > extremo.superior.outlier.extremo |
  columna < extremo.inferior.outlier.extremo

vector.es.outlier.normal
vector.es.outlier.extremo

###########################################################################
# Índices y valores de los outliers
###########################################################################

# Construimos las siguientes variables:

# claves.outliers.normales -> Vector con las claves (identificador numérico de fila) de 
# los valores que son outliers. Para obtenerlo, usad which sobre vector.es.outlier.normal
# data.frame.outliers.normales -> data frame obtenido con la selección del data frame 
# original de las filas que son outliers. 
# Puede usarse o bien vector.es.outlier.normal o bien claves.outliers.normales.
# Este dataframe contiene los datos de todas las columnas de aquellas filas que son 
# outliers.                           
# nombres.outliers.normales -> vector con los nombres de fila de los outliers. 
# Para obtenerlo, usad row.names sobre el data frame anterior.
# valores.outliers.normales -> vector con los datos de los outliers. Se muestra sólo el 
# valor de la columna que se fijó al inicio del script.
# Idem con los extremos

# Aplicando la selección dada por vector.es.outlier.normal:

#    [1] 20
#                    mpg cyl disp hp drat    wt qsec
#    Toyota Corolla 33.9   4 71.1 65 4.22 1.835 19.9
#    [1] "Toyota Corolla"
#    [1] 33.9

# Aplicando la selección dada por vector.es.outlier.extremo:
# Ninguno

# COMPLETAR

claves.outliers.normales <- which(vector.es.outlier.normal == TRUE)
data.frame.outliers.normales <- as.data.frame(mydata.numeric[claves.outliers.normales, ])
nombres.outliers.normales <- row.names(mydata.numeric)[vector.es.outlier.normal == TRUE]
valores.outliers.normales <- columna[vector.es.outlier.normal]

claves.outliers.normales
data.frame.outliers.normales
nombres.outliers.normales
valores.outliers.normales

claves.outliers.extremos <- which(vector.es.outlier.extremo == TRUE)
data.frame.outliers.extremos <- as.data.frame(mydata.numeric[claves.outliers.extremos, ])
nombres.outliers.extremos <- row.names(mydata.numeric)[vector.es.outlier.extremo == TRUE]
valores.outliers.extremos <- columna[vector.es.outlier.extremo]

claves.outliers.extremos
data.frame.outliers.extremos
nombres.outliers.extremos
valores.outliers.extremos

###########################################################################
# Desviación de los outliers con respecto a la media de la columna
###########################################################################

# Construimos la variable:

# valores.normalizados.outliers.normales -> Contiene los valores normalizados de los 
# outliers. 
# Usad columna.scaled y (o bien vector.es.outlier.normal o bien claves.outliers.normales)

# Toyota Corolla 
# 2.291272 

# COMPLETAR

valores.normalizados.outliers.normales <- columna.scaled[vector.es.outlier.normal]
valores.normalizados.outliers.normales

###########################################################################
# Plot
###########################################################################

# Mostramos en un plot los valores de los registros (los outliers se muestran en color 
# rojo).
# Para ello, llamamos a la siguiente función:
# MiPlot_Univariate_Outliers (columna de datos, indices -claves numéricas- de outliers, 
# nombre de columna).
# Lo hacemos con los outliers normales.

# COMPLETAR

MiPlot_Univariate_Outliers(mydata.numeric, 
                           claves.outliers.normales, 
                           nombres.outliers.normales)
## MiPlot_Univariate_Outliers
```


```{r fig.align='center', out.width='70%'}

###########################################################################
# BoxPlot
###########################################################################

# Vemos el diagrama de caja. 

# Para ello, llamaremos a la función boxplot, pero no muestra el outlier en la columna 
# mpg, boxplot(columna, xlab=nombre.columna, main=nombre.mydata, las = 1)   
# las = 1 all axis labels horizontal, range = 3 for exteme outliers.

# Para resolverlo, vemos el diagrama de caja con ggplot geom_boxplot
# Para ello, llamamos a la siguiente función
# MiBoxPlot_IQR_Univariate_Outliers = function (datos, indice.de.columna, coef = 1.5)

# Llamamos a la misma función pero con los datos normalizados
# Lo hacemos para resaltar que el Boxplot es el mismo ya que el poder de la normalización 
# es que no afecta a la posición relativa de los datos 

# COMPLETAR

boxplot(columna, xlab=nombre.columna, data=mydata.numeric, las = 1, range = 3) 
```

\newpage

```{r fig.align='center', out.width='70%'}
MiBoxPlot_IQR_Univariate_Outliers(mydata.numeric, indice.columna, coef = 1.5)
## MiBoxPlot_IQR_Univariate_Outliers
```


```{r fig.align='center', out.width='70%'}
MiBoxPlot_IQR_Univariate_Outliers(mydata.numeric.scaled, indice.columna, coef = 1.5)
## MiBoxPlot_IQR_Univariate_Outliers scaled
```


```{r fig.align='center', out.width='70%'}

###########################################################################
# Cómputo de los outliers IQR con funciones propias
###########################################################################

# En este apartado hacemos lo mismo que antes, pero llamando a funciones que están dentro 
# de !Outliers_A3_Funciones_a_cargar_en_cada_sesion.R:

# vector_es_outlier_IQR -> devuelve un vector TRUE/FALSE
# vector.claves.outliers.IQR -> devuelve los índices de los outliers

vector.es.outlier.normal  = vector_es_outlier_IQR(mydata.numeric, indice.columna)
vector.es.outlier.extremo = vector_es_outlier_IQR(mydata.numeric, indice.columna, 3)

valores.outliers.normales = columna[vector.es.outlier.normal]
valores.outliers.extremos = columna[vector.es.outlier.extremo]

claves.outliers.normales = vector_claves_outliers_IQR (mydata.numeric, indice.columna)
claves.outliers.extremos = vector_claves_outliers_IQR (mydata.numeric, indice.columna, 3)

claves.outliers.normales
valores.outliers.normales
claves.outliers.extremos
valores.outliers.extremos
```

### !MasterIA_GuionPracticas_Outliers_B2_1Variate_TestsEstadisticos

```{r fig.align='center', out.width='65%', warning=FALSE}

###########################################################################
# UNIVARIATE STATISTICAL OUTLIERS -> 1-variate Normal Distribution

# Grubbs' test. Normal 1-dim. 1 Único outlier.
# grubbs.test {outliers}

# Rosner's test. Normal 1-dim. <= k outliers.
# rosnerTest {EnvStats}

###########################################################################
# Conjuntos de datos 
###########################################################################

datos.con.un.outlier = c(45,56,54,34,32,45,67,45,67,140,65)
datos.con.dos.outliers.masking = c(45,56,54,34,32,45,67,45,67,154,125,65)

mydata.numeric = datos.con.un.outlier


###########################################################################
# Test de Grubbs
###########################################################################

# Transparencia 85

###########################################################################
# datos.con.un.outlier
# Mostramos el histograma de mydata.numeric usando la función hist y un gráfico 
# de puntos con la función plot.Observamos que hay un dato con un valor extremo.

# COMPLETAR

hist(mydata.numeric)
plot(mydata.numeric)

# Aplicamos el test de Grubbs sobre datos.con.un.outlier.
# Usamos la función grubbs.test (two.sided = TRUE).
# Guardamos el resultado en test.de.Grubbs y vemos el p.value correspondiente.

# [1] 0.001126431  

# Este resultado es significativo con los valores de alpha usuales 0.025, 0.01.

# COMPLETAR

test.de.Grubbs = grubbs.test(mydata.numeric, two.sided = TRUE)
test.de.Grubbs$p.value

# El test de Grubbs es significativo por lo que se concluye que hay un ÚNICO outlier.
# El valor que toma (140) los podríamos obtener a través de la función outlier del 
# paquete outliers pero éste no nos dice cuál es el índice correspondiente (10).
# Por lo tanto, calculamos manualmente cuál es el índice de aquel registro
# que más se desvía de la media de la columna correspondiente.
# Tendremos que usar las funciones abs(valor absoluto), mean(media) y order (para ordenar).
# El resultado lo guardamos en las siguientes variables:

# indice.de.outlier.Grubbs
# valor.de.outlier.Grubbs

# [1] 10
# [1] 140

# COMPLETAR

indice.de.outlier.Grubbs = order(abs(mydata.numeric - mean(mydata.numeric)), 
                                 decreasing = TRUE)[1]

valor.de.outlier.Grubbs = mydata.numeric[indice.de.outlier.Grubbs]

indice.de.outlier.Grubbs
valor.de.outlier.Grubbs
```


```{r fig.align='center', out.width='65%'}

# Ahora que sabemos el índice del outlier, podemos usar la función 
# MiPlot_Univariate_Outliers.
# Esta función muestra un plot similar al que ya hablámos mostrado, pero usa el color rojo 
# para mostrar el outlier.
# Los parámetros son: el conjunto de datos, los índices de los outliers 
# (sólo uno en este caso) y el título a mostrar.
# MiPlot_Univariate_Outliers = function (datos, indices_de_Outliers, titulo).

# Resultado:

# Número de datos: 11
# ¿Quién es outlier?: 
# FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE

# COMPLETAR

MiPlot_Univariate_Outliers(mydata.numeric, indice.de.outlier.Grubbs, "Test de Grubbs")
## MiPlot_Univariate_Outliers
```


```{r fig.align='center', out.width='70%'}

###########################################################################
# El mismo proceso anterior empaquetado en una función 
###########################################################################

# Llamamos a la función MiPlot_resultados_TestGrubbs
# MiPlot_resultados_TestGrubbs = function(datos).
# Esta función realiza todo el proceso de aplicar el test de Grubbs tal y como hemos hecho 
# anteriormente. También muestra los resultados: para ello, la función llama directamente 
# a MiPlot_Univariate_Outliers.
# El parámetro a pasar a la función MiPlot_resultados_TestGrubbs es el conjunto de datos.

# p.value: 0.001126431
# Índice de outlier: 10
# Valor del outlier: 140
# Número de datos: 11
# ¿Quién es outlier?: 
# FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE

# COMPLETAR

MiPlot_resultados_TestGrubbs(mydata.numeric)
## MiPlot_resultados_TestGrubbs
```


```{r fig.align='center', out.width='70%'}

###########################################################################
# Volvemos a aplicar el mismo proceso con los otros conjuntos de datos
###########################################################################

# Transparencia 88

###########################################################################
# datos.con.dos.outliers.masking
# Mostramos un gráfico de puntos con la función plot.
# Vemos que hay dos outliers.

# Aplicamos el test de Grubbs sobre datos.con.dos.outliers.masking.

# [1] 0.05614091

# El resultado no es significativo con ninguno de los valores de alpha usuales (<= 0.05).
# Sin embargo, hay dos outliers. (125, 154). 
# La razón es que se ha producido un efecto de "masking".  
# Ningún outlier es detectado por Grubbs.

# COMPLETAR

plot(datos.con.dos.outliers.masking)

test.de.Grubbs = grubbs.test(datos.con.dos.outliers.masking, two.sided = TRUE)
test.de.Grubbs$p.value
```


```{r fig.align='center', out.width='70%', warning=FALSE}

###########################################################################
# Test de Rosner
###########################################################################

# Hay tests para detectar un número exacto de k outliers, pero no son muy útiles.
# Mejor usamos un test para detectar un número menor o igual que k outliers (Rosner).

# Transparencia 90

# Aplicamos el Test de Rosner (rosnerTest) con k=4 sobre datos.con.dos.outliers.masking.
# Nos dará un aviso ocasionado por tener pocos datos.
# Guardamos el resultado en test.de.rosner .
# El test ordena los valores de mayor a menor distancia de la media y lanza el test 
# de hipótesis para ver si hay menos de k=4 outliers.

# Imprimimos los siguientes campos:
# test.de.rosner$all.stats$Outlier 
# Es un vector de 4 boolean. 
# Nos indica si son considerados outliers los 4 valores que más se alejan de la media.
# En este caso:
# [1]  TRUE  TRUE FALSE FALSE
# Los dos primeros son TRUE y el resto FALSE => El test indica que hay dos outliers
  
# test.de.rosner$all.stats$Obs.Num
# Es un vector con los cuatro índices de los 4 valores que más se alejan de la media.
# En este caso:
# [1]  10    11   5     4

# Construimos el vector con los índices de los que son outliers (10, 11)
# y se lo pasamos como parámetro a la función.
# MiPlot_Univariate_Outliers
# MiPlot_Univariate_Outliers = function (datos, indices_de_Outliers, titulo)

# Número de datos: 12
# ¿Quién es outlier?: 
# FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE FALSE

# COMPLETAR

test.de.rosner = rosnerTest(datos.con.dos.outliers.masking, k = 4)
test.de.rosner$all.stats$Outlier 
test.de.rosner$all.stats$Obs.Num

MiPlot_Univariate_Outliers(datos.con.dos.outliers.masking, c(10, 11), "Test de Rosner")
## MiPlot_Univariate_Outliers
```


```{r fig.align='center', out.width='70%', warning=FALSE}

#######################################################################
# La función MiPlot_resultados_TestRosner = function(datos)
# hace directamente las anteriores tareas, es decir, lanza el test y dibuja el plot.
# Lanzamos esta función con el dataset datos.con.dos.outliers.masking 
# y comprobamos que ofrece los resultados vistos anteriormente.

# COMPLETAR

MiPlot_resultados_TestRosner(datos.con.dos.outliers.masking)
## MiPlot_resultados_TestRosner
```


```{r fig.align='center', out.width='70%', warning=FALSE}

#######################################################################
# Para ver el comportamiento del Test de Rosner con el conjunto de datos inicial 
# lanzamos la función MiPlot_resultados_TestRosner con k=4 sobre datos.con.un.outlier.

# Test de Rosner
# Índices de las k-mayores desviaciones de la media: 10 5 4 7
# De las k mayores desviaciones, ¿Quién es outlier? TRUE FALSE FALSE FALSE
# Los índices de los outliers son: 10
# Los valores de los outliers son: 140
# Número de datos: 11
# ¿Quién es outlier?: FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE

# El test indica que sólo hay un outlier.

# COMPLETAR

MiPlot_resultados_TestRosner(mydata.numeric)
## MiPlot_resultados_TestRosner
```


### !MasterIA_GuionPracticas_Outliers_C1_MultiVariate_Mahalanobis

```{r fig.align='center', out.width='90%'}

###########################################################################
# MULTIVARIATE STATISTICAL OUTLIERS -> Multivariate Normal Distribution --> Mahalanobis
###########################################################################

# Los outliers son respecto a un conjunto de variables.
# Un registro será un outlier porque tenga un valor anómalo en alguna variable
# o porque tenga una combinación anómala de valores.


# Necesita:
# mydata.numeric
# mydata.numeric.scaled

# Trabajamos sobre mtcars[, -c(8:11)]

mydata.numeric = mtcars[, -c(8:11)]
mydata.numeric.scaled = scale(mydata.numeric)

###########################################################################
# Paquete mvoutlier
###########################################################################

# Obtención de los outliers multivariantes

# Transparencia 95

# Calcula los outliers calculando las distancias de Mahalanobis y usando la 
# aproximación de la Chi cuadrado.
# La estimación de la matriz de covarianzas es la estimación robusta según MCD.
# No hay que normalizar los datos ya que la distancia de Mahalanobis está
# diseñada, precisamente para evitar el problema de la escala.

# uni.plot genera el gráfico similar a MiPlot_Univariate_Outliers con todas las columnas.
# Además, devuelve en $outliers los índices de los outliers.

# Establecemos los valores de significación.
# alpha.value.penalizado es para tener en cuenta el error FWER.

alpha.value = 0.05
alpha.value.penalizado = 1 - (1 - alpha.value) ^ (1 / nrow(mydata.numeric))       

# Transparencia 91

# Establecemos la semilla para el método iterativo que calcula MCD 
# IMPORTANTE: Para que el resultado sea el mismo en todas las ejecuciones, siempre 
# hay que establecer la semilla antes de lanzar la función correspondiente.

set.seed(12)  

# Llamamos a uni.plot del paquete mvoutlier con symb=FALSE, alpha = alpha.value.penalizado.
# Guardamos el resultado en la variable mvoutlier.plot.
# Esta función calcula los outliers MULTIVARIANTES según la distancia de Mahalanobis
# considerando la estimación robusta de la matriz de covarianzas -MCD- y la estimación 
# robusta de la media de cada variable.
# También imprime un plot 1-dimensional para ver los valores que toman los outliers en 
# cada atributo pero el plot no imprime las etiquetas de los outliers. 

# Nota: Es posible que haya que instalar el paquete pcaPP para que se pueda ejecutar 
# uni.plot.

X11()

# COMPLETAR

mvoutlier.plot = uni.plot(mydata.numeric, symb=FALSE, alpha = alpha.value.penalizado)

###########################################################################
# Análisis de los outliers

# Vamos a ver las variables que más influyen en la designación de los outliers.
# a) Viendo el valor normalizado sobre cada variable para ver cuánto se desvía de la media.
# Pero esto no es suficiente ya que no es fácil apreciar interacciones entre atributos.
# b) Gráficamente, con un biplot sobre las componentes principales.
# El Biplot permite ver las dimensiones importantes que influyen en la designación de 
# los outliers.

# Construimos las variables. 
# is.MCD.outlier 
# numero.de.outliers.MCD
# que será un vector TRUE/FALSE que nos dice si cada dato es o no un outlier. 
# Para ello, accedemos a mvoutlier.plot$outliers.
# Contamos el número total de outliers y lo guardamos en la variable 
# numero.de.outliers.MCD.
# Debe salir lo siguiente:

# is.MCD.outlier 
# Mazda RX4       Mazda RX4 Wag          Datsun 710   ......
# FALSE               FALSE               FALSE       ......
# ......  

# numero.de.outliers.MCD
# [1] 10

# COMPLETAR

is.MCD.outlier = mvoutlier.plot$outliers
numero.de.outliers.MCD = sum(is.MCD.outlier)
is.MCD.outlier
numero.de.outliers.MCD

# Calculamos los índices de los outliers multivariantes en la variable 
# indices.de.outliers.multivariantes.MCD 
# y los mostramos en pantalla. Debe salir lo siguiente:

# indices.de.outliers.multivariantes.MCD
# Merc 230  Cadillac Fleetwood Lincoln Continental   Chrysler Imperial          Fiat 128 
# 9                  15                  16                  17                 18 
# Honda Civic      Toyota Corolla        Lotus Europa        Ferrari Dino   Maserati Bora 
# 19   

# Vemos qué outliers son multivariantes "puros", es decir, que NO son 1 variantes
# con respecto a ninguna columna. Estos outliers multivariantes son interesantes
# ya que nos indican que no son outliers porque una de sus columnas tenga un valor
# extremo, sino porque hay alguna combinación anómala de valores de columnas.

# Por tanto, en primer lugar, debemos obtener los índices (claves) de aquellos registros 
# que son outliers IQR en alguna de las columnas.
# Para ello, basta usar la función vector_claves_outliers_IQR_en_alguna_columna
# y construimos la variable indices.de.outliers.en.alguna.columna

# Con las variables indices.de.outliers.en.alguna.columna y 
# indices.de.outliers.multivariantes.MCD construimos las siguientes variables:
# indices.de.outliers.multivariantes.MCD.pero.no.1variantes (debe usar setdiff).
# nombres.de.outliers.multivariantes.MCD.pero.no.1variantes (debe usar rownames).

# Debe salir lo siguiente:

# indices.de.outliers.multivariantes.MCD
# Merc 230  Cadillac Fleetwood Lincoln Continental   Chrysler Imperial          Fiat 128 
# 9                  15                  16                  17                 18 
# Honda Civic      Toyota Corolla        Lotus Europa        Ferrari Dino   Maserati Bora 
# 19                  20                  28                  30                  31 

# indices.de.outliers.multivariantes.MCD.pero.no.1variantes
# [1] 18 19 28 30

# nombres.de.outliers.multivariantes.MCD.pero.no.1variantes
# [1] "Fiat 128"     "Honda Civic"  "Lotus Europa" "Ferrari Dino"

# COMPLETAR

indices.de.outliers.multivariantes.MCD <- which(is.MCD.outlier==TRUE)
indices.de.outliers.en.alguna.columna <- vector_claves_outliers_IQR_en_alguna_columna(
  mydata.numeric, coef = 1.5)

indices.de.outliers.multivariantes.MCD.pero.no.1variantes <- setdiff(
  indices.de.outliers.multivariantes.MCD, indices.de.outliers.en.alguna.columna)

data.frame.de.outliers.multivariantes.MCD.pero.no.1variantes <- as.data.frame(
  mydata.numeric[indices.de.outliers.multivariantes.MCD.pero.no.1variantes,])

nombres.de.outliers.multivariantes.MCD.pero.no.1variantes <- row.names(
  data.frame.de.outliers.multivariantes.MCD.pero.no.1variantes)

indices.de.outliers.multivariantes.MCD
indices.de.outliers.multivariantes.MCD.pero.no.1variantes
nombres.de.outliers.multivariantes.MCD.pero.no.1variantes

# ¿Cuál es el valor normalizado de cada outlier, es decir, 
# ¿Cuánto se desvía de la media de cada columna?
# Esta desviación ya se ha mostrado antes al llamar a uni.plot, 
# pero sólo se muestran los outliers como puntos rojos.
# Al no tener las etiquetas, no sabemos cuáles son los valores de los outliers 
# en cada columna.

# Construimos una tabla numérica data.frame.solo.outliers que muestre los valores 
# normalizados de los outliers en todas las columnas. 
# Para ello, usamos mydata.numeric.scaled y is.MCD.outlier:

# mpg        cyl       disp         hp        drat          wt        qsec
# Merc 230             0.44954345 -1.2248578 -0.7255351 -0.7538702  0.60491932 -0.06873063
# Cadillac Fleetwood  -1.60788262  1.0148821  1.9467538  0.8504968 -1.24665983  2.07750476
# Lincoln Continental -1.60788262  1.0148821  1.8499318  0.9963483 -1.11574009  2.25533570
# Chrysler Imperial   -0.89442035  1.0148821  1.6885616  1.2151256 -0.68557523  2.17459637
# Fiat 128             2.04238943 -1.2248578 -1.2265893 -1.1768396  0.90416444 -1.03964665
# Honda Civic          1.71054652 -1.2248578 -1.2507948 -1.3810318  2.49390411 -1.63752651
# Toyota Corolla       2.29127162 -1.2248578 -1.2879099 -1.1914248  1.16600392 -1.41268280
# Lotus Europa         1.71054652 -1.2248578 -1.0942658 -0.4913374  0.32437703 -1.74177223
# Ferrari Dino        -0.06481307 -0.1049878 -0.6916474  0.4129422  0.04383473 -0.45709704
# Maserati Bora       -0.84464392  1.0148821  0.5670394  2.7465668 -0.10578782  0.36051645

# COMPLETAR

data.frame.solo.outliers <- as.data.frame(
  mydata.numeric.scaled[indices.de.outliers.multivariantes.MCD,])

data.frame.solo.outliers

# Mostramos los boxplots de forma conjunta con las etiquetas de los outliers.
# Para ello llamamos a la función MiBoxPlot_juntos pasando como parámetro is.MCD.outlier.
# MiBoxPlot_juntos = function (datos, vector_TF_datos_a_incluir)  

# COMPLETAR

MiBoxPlot_juntos(mydata.numeric, is.MCD.outlier) 
```


```{r fig.align='center', out.width='90%'}

# Transparencia 79  (Biplot)

# El BoxPlot conjunto nos informa sobre los valores extremos que hay en cada variable.
# Puede apreciarse que casi todos los outliers multivariate corresponden a outliers 
# univariate.
# Las únicas excepciones son Fiat 128 y Ferrari Dino, aunque Fiat 128 es casi un outlier 
# en mpg.

# El BiPlot nos muestra también esta información, junto con las correlaciones 
# entre variables.
# Los puntos mostrados son resultados de proyecciones de n dimensiones a 2, por lo que 
# sólo es una representación aproximada (mejor cuanto mayor sea la suma de los porcentajes
# que aparecen como componentes principales PC1 y PC2).
# Llamamos a la función MiBiPlot_Multivariate_Outliers
# MiBiPlot_Multivariate_Outliers = function (datos, vectorTFoutliers, titulo)

# COMPLETAR

MiBiPlot_Multivariate_Outliers(mydata.numeric, is.MCD.outlier, "")




## MiBiPlot_Multivariate_Outliers
```


```{r fig.align='center', out.width='90%'}

# El BiPlot muestra claramente que Ferrari Dino no es outlier univariate en ninguna 
# variable.
# (no está en el extremo delimitado por los vectores correspondientes a las variables)
# Posiblemente sea un outlier multivariate debido a la combinación anormal de varias 
# variables.

# Vamos a construir una matriz con los gráficos de dispersión obtenidos al cruzar todas 
# las variables.
# Y vamos a destacar en rojo el dato correspondiente a Ferrari Dino.
# Para ello, obtenemos el índice de Ferrari Dino usando las funciones which y rownames
# y llamamos a la función MiPlot_Univariate_Outliers 
# MiPlot_Univariate_Outliers = function (datos, indices_de_Outliers, titulo)
# El parámetro indices_de_Outliers únicamente contendrá el índice del Ferrari Dino.
# Puede apreciarse que no hay una combinación clara de 2 variables que hagan del Ferrari 
# un outlier.
# Es posible que intervengan más de dos variables.
# Efectivamente, si observamos la tabla data.frame.solo.outliers
# parece ser que consigue una aceleración qsec muy buena -1.3 
# (bastante cercana a la mayor -> Maserati Bora -1.8)
# con una potencia hp normal 0.4 (Maserati 2.7). Tener un peso wt ligero -0.4 seguramente 
# es un factor decisivo (Maserati 0.3).
# La combinación peso, aceleración, hp es lo que hace de Ferrari Dino un outlier 
# multivariate.

# COMPLETAR

indices.de.outliers <- as.data.frame(indices.de.outliers.multivariantes.MCD)
indices.de.outliers.en.Ferrari.Dino <- indices.de.outliers["Ferrari Dino",]
indices.de.outliers.en.Ferrari.Dino

MiPlot_Univariate_Outliers(mydata.numeric, indices.de.outliers.en.Ferrari.Dino, "")
## MiPlot_Univariate_Outliers
```

\newpage

### !MasterIA_GuionPracticas_Outliers_D1_LOF

```{r fig.align='center', out.width='90%'}

###########################################################################
# MULTIVARIATE STATISTICAL OUTLIERS -> LOF 
###########################################################################

# Los outliers son respecto a un conjunto de variables.

#####################################################################
# Lectura de valores y Preprocesamiento
#####################################################################

# Tanto LOF como clustering usan distancias entre registros, por lo que habrá
# que trabajar sobre los datos previamente normalizados.

# Construimos las siguientes variables:

# mis.datos.numericos -> Contendrá las columnas numéricas de iris, es decir, iris [1:4].
# mis.datos.numericos.normalizados -> Contendrá los datos normalizados.
# Asignamos como nombres de filas de mis.datos.numericos.normalizados los mismos nombres 
# de filas que mis.datos.numericos.

# Ampliación: Utilice la función is.numeric y sapply para construir automáticamente un 
# data frame con las columnas numéricas de otro data frame.

mis.datos.originales = iris
mis.datos.numericos  = mis.datos.originales[,1:4]
mis.datos.numericos  = mis.datos.originales[,sapply(mis.datos.originales, is.numeric)]
mis.datos.numericos.normalizados = scale(mis.datos.numericos)
rownames(mis.datos.numericos.normalizados) = rownames(mis.datos.numericos)

###########################################################################

# Transparencia 106

# Para comprobar que el método de Mahalanobis no es aplicable, 
# obtenga las variables is.MCD.outlier y numero.de.outliers.MCD 
# tal y como se hizo en el script anterior (hay que tener cargada la librería mvoutlier)
# Observe que hay un número muy elevado de outliers (50) y además con valores 
# de Petal.Length y Petal.Width muy similares. 
# Realmente no son outliers sino que forman un grupo homogéneo.

# COMPLETAR

alpha.value = 0.05
alpha.value.penalizado = 1 - (1 - alpha.value) ^ (1 / nrow(mis.datos.numericos))

set.seed(12)
X11()

mvoutlier.plot = uni.plot(mis.datos.numericos, symb=FALSE, alpha = alpha.value.penalizado)

is.MCD.outlier = mvoutlier.plot$outliers
numero.de.outliers.MCD = sum(is.MCD.outlier)
is.MCD.outlier
numero.de.outliers.MCD

# Ejecute también lo siguiente:

X11()
corr.plot(mis.datos.numericos[,1], mis.datos.numericos[,3]) 
```


```{r fig.align='center', out.width='90%'}

# El gráfico nos muestra un gráfico de dispersión al cruzar las variables 1 y 3.
# Vemos que hay dos grupos bien definidos de datos.
# Los puntos que hay entre ellos deberían ser marcados como outliers.
# Usando la distancia de Mahalanobis clásica (azul) el elipsoide
# contiene a ambos grupos por lo que los puntos que hubiese entre ellos no serían outliers.
# Usando la distancia de Mahalanobis construida con la estimación robusta de la matriz 
# de covarianzas y las correspondientes medias, 
# el elipsoide (rojo) se construye con el grupo de datos
# más numeroso y todos los datos del otro grupo se marcan como outliers.

# También podemos mostrar un BiPlot llamando a la función MiBiplot sobre 
# mis.datos.numericos.
# El gráfico mostrado es una simplificación ya que ahora estamos mostrando las cuatro 
# variables conjuntamente en un gráfico 2 dimensional (Transparencia 72).
# Podemos apreciar que hay dos nubes de puntos bien separadas.

# Así pues, el método de detección de outliers usando la distancia de Mahalanobis 
# no es adecuado.



MiBiplot(mis.datos.numericos)
## MiBiplot
```


```{r fig.align='center', out.width='90%'}

###########################################################################
# DISTANCE BASED OUTLIERS (LOF)
###########################################################################

# Transparencia 124

numero.de.vecinos.lof = 5

# Establecemos el número de vecinos a considerar numero.de.vecinos.lof = 5 y llamamos a 
# la función lofactor pasándole como primer parámetro el conjunto de datos normalizados 
# y como parámetro k el valor de numero.de.vecinos.lof.
# Esta función devuelve un vector con los scores de LOF de todos los registros.
# Lo llamamos lof.scores
# [1] 1.0036218 1.0244637 1.0198058 1.0394019 ......

# Hacemos un plot de los resultados (basta llamar a la función plot sobre lof.scores) 
# para ver los scores obtenidos por LOF.
# Podemos apreciar que hay 4 valores de lof notablemente míos altos que el resto.
# Así pues, establecemos la variable siguiente:
# numero.de.outliers = 4

# Ordenamos los lof.scores y obtenemos los índices de los registros ordenados según 
# el lof.score indices.de.lof.outliers.ordenados.
# [1]  42 118 132 110 107  16  61  23  ......

# Seleccionamos los 4 primeros y los almacenamos en indices.de.lof.top.outliers.
# [1]  42 118 132 110 

# Construimos un vector is.lof.outlier de TRUE/FALSE que nos dice si cada registro 
# de los datos originales es o no un outlier. Para ello, debemos usar la función 
# rownames sobre el dataset y el operador %in% sobre indices.de.lof.top.outliers.
# is.lof.outlier
# [1] FALSE FALSE FALSE FALSE FALSE ......

# Mostramos un Biplot de los outliers llamando a la función MiBiPlot_Multivariate_Outliers
# MiBiPlot_Multivariate_Outliers = function (datos, vectorTFoutliers, titulo)

# Tal vez, el dato más interesante sea el 42 ya que no parece que sea un outlier 
# univariante (luego lo comprobaremos).

# COMPLETAR

lof.scores = lofactor(mis.datos.numericos.normalizados, numero.de.vecinos.lof)
lof.scores

plot(lof.scores)

numero.de.outliers = 4

indices.de.lof.outliers.ordenados = order(lof.scores, decreasing = TRUE)
indices.de.lof.outliers.ordenados

indices.de.lof.top.outliers = indices.de.lof.outliers.ordenados[1:4]
indices.de.lof.top.outliers

is.lof.outlier = c(1:nrow(mis.datos.originales)) %in% indices.de.lof.top.outliers
is.lof.outlier

MiBiPlot_Multivariate_Outliers(mis.datos.numericos, is.lof.outlier, "")
## MiBiPlot_Multivariate_Outliers
```


```{r fig.align='center', out.width='90%'}

# Comparamos con los outliers en una sola dimensión que habríamos obtenido con 
# el método IQR. 
# Construimos las variables:

# vector.claves.outliers.IQR.en.alguna.columna: Contiene los índices de los que son 
# outliers en alguna columna.
# Hay que llamar a la función vector_claves_outliers_IQR_en_alguna_columna
# vector.es.outlier.IQR.en.alguna.columna: Vector de T/F indicando si cada dato 
# es outlier o no según el criterio IQR.
# Hay que llamar a la función vector_es_outlier_IQR_en_alguna_columna.

# Debe salir lo siguiente:
# vector.claves.outliers.IQR.en.alguna.columna
# [1] 16 33 34 61

# Mostramos el Biplot usando el vector de T/F vector.es.outlier.IQR.en.alguna.columna

# Construimos la variable
# indices.de.outliers.multivariantes.LOF.pero.no.1variantes: Contiene los outliers LOF 
# que no son outliers IQR.
# Para ello, usamos setdiff y vemos que el resultado es el mismo conjunto de outliers LOF
# es decir, que ningún outlier LOF es outlier IQR.

# indices.de.outliers.multivariantes.LOF.pero.no.1variantes
# [1]  42 118 132 110

# COMPLETAR

vector.claves.outliers.IQR.en.alguna.columna = 
  vector_claves_outliers_IQR_en_alguna_columna(mis.datos.numericos, coef = 1.5)
vector.claves.outliers.IQR.en.alguna.columna

MiBoxPlot_juntos(mis.datos.numericos, vector.claves.outliers.IQR.en.alguna.columna)

indices.de.outliers.multivariantes.LOF = which(is.lof.outlier == TRUE)

indices.de.outliers.multivariantes.LOF.pero.no.1variantes = setdiff(
  indices.de.outliers.multivariantes.LOF, vector.claves.outliers.IQR.en.alguna.columna)

indices.de.outliers.multivariantes.LOF.pero.no.1variantes
```

### !MasterIA_GuionPracticas_Outliers_D2_ClusterBasedOutliers

```{r  fig.align='center', out.width='90%'}

###########################################################################
# MULTIVARIATE STATISTICAL OUTLIERS. CLUSTERING OUTLIERS 
###########################################################################

# Los outliers son respecto a un conjunto de variables.

#####################################################################
# Lectura de valores y Preprocesamiento
#####################################################################

# Trabajamos sobre las columnas numéricas de iris [1:4].
# Este conjunto de datos está disponible en R.
# Tanto LOF como clustering usan distancias entre registros, por lo que habrá
# que trabajar sobre los datos previamente normalizados.

# Construimos los siguiente conjuntos:

# mis.datos.numericos -> con las columnas 1:4 de iris.
# mis.datos.numericos.normalizados -> con los valores normalizados.
# a Los rownames de mis.datos.numericos.normalizados les asignamos los rownames de 
# mis.datos.numericos.

# Establecemos la variable numero.de.outliers a 5 y numero.de.clusters a 3.

mis.datos.numericos = iris[,1:4]
mis.datos.numericos.normalizados = scale(mis.datos.numericos)
rownames(mis.datos.numericos.normalizados) = rownames(mis.datos.numericos)

numero.de.outliers = 5
numero.de.clusters = 3

set.seed(2)  # Para establecer la semilla para la primera iteración de kmeans

###########################################################################
# Cómputo de los outliers según la distancia euclídea de cada dato 
# al centroide de su cluster.
# El centroide podrá ser cualquiera (podrá provenir de un k-means 
# o ser un medoide, por ejemplo).
###########################################################################

# k-Means

# Construimos el modelo kmeans (modelo.kmeans) con los datos normalizados. 
# Para ello, usamos la función de R llamada "kmeans".

# A partir del resultado de kmeans, accedemos a:

# a) $cluster para obtener 
# los índices de asignación de cada dato al cluster correspondiente. 
# El resultado lo guardamos en la variable indices.clustering.iris.
# Por ejemplo, si el dato con índice 69 está asignado al tercer cluster,
# en el vector indices.clustering.iris habrá un 3 en la componente número 69.

# b) $centers para obtener los datos de los centroides.
# Los datos están normalizados por lo que los centroides también lo están.
# El resultado lo guardamos en la variable centroides.normalizados.iris

# indices.clustering.iris
# 1   2   3   4   ... 69  70  71 ...
# 1   1   1   1   ... 3   3   2  ...

# centroides.normalizados.iris
#    Sepal.Length Sepal.Width Petal.Length Petal.Width
# 1  -1.01119138  0.85041372   -1.3006301  -1.2507035
# 2   1.13217737  0.08812645    0.9928284   1.0141287
# 3  -0.05005221 -0.88042696    0.3465767   0.2805873

# COMPLETAR

modelo.kmeans = kmeans(mis.datos.numericos.normalizados, numero.de.clusters)
indices.clustering.iris = modelo.kmeans$cluster
centroides.normalizados.iris = modelo.kmeans$centers

indices.clustering.iris
centroides.normalizados.iris

# Calculamos la distancia euclídea de cada dato a su centroide 
# (con los valores normalizados).
# Para ello, usad la siguiente función:

distancias_a_centroides = function (datos.normalizados, 
                                    indices.asignacion.clustering, 
                                    datos.centroides.normalizados) {
  
  sqrt(rowSums((datos.normalizados - 
                  datos.centroides.normalizados[indices.asignacion.clustering,]) ^ 2))
}

# dist.centroides.iris
# 1          2          3             ......
# 0.21224719 0.99271979 0.64980753    ......

# Ordenamos dichas distancias a través de la función order y obtenemos
# los índices correspondientes. Nos quedamos con los primeros
# (tantos como diga la variable numero.de.outliers).

# top.outliers.iris
# [1]  42  16 132 118  61

# COMPLETAR

dist.centroides.iris = distancias_a_centroides(mis.datos.numericos.normalizados,
                     indices.clustering.iris, centroides.normalizados.iris)

dist.centroides.iris.ordered = order(dist.centroides.iris, decreasing = TRUE)
top.outliers.iris = dist.centroides.iris.ordered[1:numero.de.outliers]
 
dist.centroides.iris                   
top.outliers.iris
```

